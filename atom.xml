<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Harry 的个人空间</title>
  
  
  <link href="https://harryzhang.cn/atom.xml" rel="self"/>
  
  <link href="https://harryzhang.cn/"/>
  <updated>2023-08-16T14:50:59.395Z</updated>
  <id>https://harryzhang.cn/</id>
  
  <author>
    <name>harry zhang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Docker 安装 Elasticsearch 和 Kibana 实践</title>
    <link href="https://harryzhang.cn/2023/08/16/Docker-%E5%AE%89%E8%A3%85-Elasticsearch-%E5%92%8C-Kibana-%E5%AE%9E%E8%B7%B5/"/>
    <id>https://harryzhang.cn/2023/08/16/Docker-%E5%AE%89%E8%A3%85-Elasticsearch-%E5%92%8C-Kibana-%E5%AE%9E%E8%B7%B5/</id>
    <published>2023-08-16T14:50:59.000Z</published>
    <updated>2023-08-16T14:50:59.395Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>依赖反转(DIP)原则在整洁架构中的应用</title>
    <link href="https://harryzhang.cn/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"/>
    <id>https://harryzhang.cn/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</id>
    <published>2023-07-19T14:47:52.000Z</published>
    <updated>2023-07-19T15:44:16.233Z</updated>
    
    <content type="html"><![CDATA[<ul><li>整洁架构</li><li>DIP</li></ul><h2 id="整洁架构简介"><a href="#整洁架构简介" class="headerlink" title="整洁架构简介"></a>整洁架构简介</h2><blockquote><p>直接上图</p><p><strong>整洁架构从外到内分为四层，源码中的依赖关系必须只指向同心圆的内侧，即由底层机制指向高层策略</strong></p></blockquote><p><img src="/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/clean-arch.png" class="lazyload" data-srcset="/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/clean-arch.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="业务实体"><a href="#业务实体" class="headerlink" title="业务实体"></a>业务实体</h3><p>这一层封装整个系统的关系业务逻辑，能被系统中的其他不同应用复用。<br>对应领域驱动设计中的概念就是领域模型。</p><h3 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h3><p>用例通常包含的是特定应用场景下的业务逻辑，这一层封装了整个系统所有用例。<br>这些用例引导了数据在业务实体之间的流入&#x2F;流出，通过编排业务实体中的关键方法来实现业务用例的目标。</p><p>这一层发生的改变不应该影响业务实体，同时也不应该受外部因素（比如数据库、UI<br>框架）的影响。该层的变化应该只和应用本身的行为变化有关。</p><h3 id="接口适配器"><a href="#接口适配器" class="headerlink" title="接口适配器"></a>接口适配器</h3><p>接口适配器层通常是一组数据转换器，负责将数据从对用例和业务实体最方便操作的格式转换为外部系统最方便的操作格式。例如这一层应该包含整个 GUI MVC 框架，展示器、视图、控制器都应该属于接口适配层，而模型部分则应该由控制器传给用例，用例再传回展示器和视图。</p><p>同样这一层也会负责将数据从对业务实体与用例方便的格式转换为数据持久化最方便的格式。</p><p>这一层也会负责将来自外部服务的数据转换为系统用例和业务实体所需的格式。</p><h3 id="框架与驱动程序"><a href="#框架与驱动程序" class="headerlink" title="框架与驱动程序"></a>框架与驱动程序</h3><p>这一层一般是由工具、工具、Web 框架等组成，包含了所有的实现细节，Web、数据库都是实现细节。<br>这一层也是最容易和频繁可能改变的，将其放在最外层就很难影响到其他层了。</p><h2 id="依赖反转"><a href="#依赖反转" class="headerlink" title="依赖反转"></a>依赖反转</h2><p>代码如何保证整洁架构所约束的依赖关系原则呢，通常是通过依赖反转来实现。<br>比如需要将业务数据持久化，那直觉上来看肯定用例层需要调用接口适配层提供的数据库持久化方法，这就违反了只允许外层依赖内层的原则。</p><p><img src="/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/dip-demo.png" class="lazyload" data-srcset="/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/dip-demo.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>如上图所示，通过依赖反转，在用例层提供数据持久化需要的接口（Data Access Interface），由适配层提供具体的实现（MySQL Access），这样持久化时用例层不关注具体的实现，只需要调用用例层定义的接口即可。通过这种方法即将业务逻辑和具体的持久化方式解耦，又满足了只能外层依赖内层的原则。</p><h2 id="应用示例"><a href="#应用示例" class="headerlink" title="应用示例"></a>应用示例</h2><blockquote><p>一个简单的文件存储服务，核心功能包括：文件上传、文件下载</p></blockquote><p>组件依赖关系如下所示：</p><p><img src="/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/filesvc-demo.png" class="lazyload" data-srcset="/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/filesvc-demo.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>按照整洁架构的分层，简单分析上述文件存储服务 demo（上图省略了 Web 框架等处于最外层的组件）。</p><h3 id="1-实体层"><a href="#1-实体层" class="headerlink" title="1. 实体层"></a>1. 实体层</h3><p>实体层包含了两个核心实体：文件实体、文件配置实体。</p><ul><li>文件实体：包含增、删、改查文件 DB 记录等方法，以及获取文件存储类型、存储 Key 的方法</li><li>文件配置实体：包含获取上传文件大小限制等配置的方法</li></ul><h3 id="2-用例层"><a href="#2-用例层" class="headerlink" title="2. 用例层"></a>2. 用例层</h3><p>用例层包含了文件服务的两个核心业务用例：上传文件和下载文件，还包括了用于操作配置、数据库、对象存储、消息队列的一系列接口。</p><ul><li>上传用例：调用文件配置实体获取上传配置，通过 StorageAccess 接口将文件内容持久化到对象存储或其他介质，再调用 DBAccess 的方法保存文件记录，最后通过 MQAccess 的方法发送一条上传文件的消息。</li><li>下载用例：调用文件实体的方法查询到文件的存储 Key，再调用 StorageAccess 的方法下载文件内容。</li></ul><h3 id="3-接口适配层"><a href="#3-接口适配层" class="headerlink" title="3. 接口适配层"></a>3. 接口适配层</h3><p>接口适配层则实现了四个适配器。</p><ul><li>ACM: 用于管理动态配置</li><li>OSS: 用于上传、下载文件对象</li><li>MySQL: 用于增删改查文件记录</li><li>RocketMQ: 用于发送文件上传消息</li></ul><p>可以看到通过按照整洁架构的分层方式和依赖反转原则，文件服务的组件依赖关系非常清晰（图中三层只存在从下到上方向的依赖），而且将业务逻辑和存储介质等基础设施解耦，底层组件的替换完全不会影响到业务用例的逻辑。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;整洁架构&lt;/li&gt;
&lt;li&gt;DIP&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;整洁架构简介&quot;&gt;&lt;a href=&quot;#整洁架构简介&quot; class=&quot;headerlink&quot; title=&quot;整洁架构简介&quot;&gt;&lt;/a&gt;整洁架构简介&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;直接上</summary>
      
    
    
    
    <category term="架构设计" scheme="https://harryzhang.cn/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
  </entry>
  
  <entry>
    <title>VSCode 项目多窗口改为多 Tab 样式</title>
    <link href="https://harryzhang.cn/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/"/>
    <id>https://harryzhang.cn/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/</id>
    <published>2023-07-01T04:07:04.000Z</published>
    <updated>2023-08-16T14:36:52.328Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul><li>macOS Ventura 13.4</li><li>VSCode 1.79.2</li></ul><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>当打开多个项目时，每个项目都占一个新的窗口，日常工作经常会打开至少五个以上项目，多窗口切换不方便，个人更习惯只开一个窗口，多个项目分多个 Tab 的模式<br><img src="/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/vscode-multi-window.png" class="lazyload" data-srcset="/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/vscode-multi-window.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>按如下方式可以切换到分 Tab 模式：</p><ol><li><p>打开 Mac 系统偏好设置，找到「桌面与程序坞」选项（低版本系统在「通用」里），将「打开文稿时首选标签页」选项改为 <strong>始终</strong><br><img src="/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/macos-setting.png" class="lazyload" data-srcset="/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/macos-setting.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>打开 VSCode 偏好设置（快捷键 cmd + ,）<br><img src="/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/vscode-setting.png" class="lazyload" data-srcset="/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/vscode-setting.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>搜索 native tab 结果如下，将选项设为开启状态（需要重启 VSCode）<br><img src="/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/vscode-setting-native-tab.png" class="lazyload" data-srcset="/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/vscode-setting-native-tab.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>重启后效果窗口效果变成如下样式<br><img src="/macos-multi-tab.png" class="lazyload" data-srcset="/macos-multi-tab.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li></ol><p>至此即可通过开关「Native Tab」设置切换 VS Code 的窗口样式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;macOS Ventura 13.4&lt;/li&gt;
&lt;li&gt;VSCode 1.79.2&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;问题&quot;</summary>
      
    
    
    
    <category term="工具" scheme="https://harryzhang.cn/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="VSCode" scheme="https://harryzhang.cn/tags/VSCode/"/>
    
  </entry>
  
  <entry>
    <title>Go 语言 Channel 最佳实践</title>
    <link href="https://harryzhang.cn/2023/05/14/Go-%E8%AF%AD%E8%A8%80-Channel-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>https://harryzhang.cn/2023/05/14/Go-%E8%AF%AD%E8%A8%80-Channel-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2023-05-14T09:31:52.000Z</published>
    <updated>2023-06-09T15:21:34.246Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote><p>Channel 基本概念介绍</p><p>基本使用方法参见 <a href="https://tour.go-zh.org/concurrency/2">Go指南</a></p></blockquote><p>Go 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。</p><h3 id="不带缓冲的通道"><a href="#不带缓冲的通道" class="headerlink" title="不带缓冲的通道"></a>不带缓冲的通道</h3><p>创建不带缓冲的通道语法如下</p><pre><code class="go">ch := make(chan int)</code></pre><p>不带缓冲的通道发送和接收操作在另一端准备好之前都会阻塞，可以想象为是直接由发送者将数据传给接收者，没有中间缓冲区。这使得 Go 程可以在没有显式的锁或竞态变量的情况下进行同步。</p><h3 id="带缓冲的通道"><a href="#带缓冲的通道" class="headerlink" title="带缓冲的通道"></a>带缓冲的通道</h3><p>将缓冲长度作为第二个参数提供给 make 来初始化一个带缓冲的信道</p><pre><code class="go">ch := make(chan int, 100)</code></pre><p>仅当信道的缓冲区填满后，向其发送数据时才会阻塞。当缓冲区为空时，接受方会阻塞。</p><h3 id="关闭通道"><a href="#关闭通道" class="headerlink" title="关闭通道"></a>关闭通道</h3><pre><code class="go">close(ch)</code></pre><p>发送者可通过 close 关闭一个信道来表示没有需要发送的值了。接收者可以通过为接收表达式分配第二个参数来测试信道是否被关闭：若没有值可以接收且信道已被关闭，那么在执行完 <code>v, ok := &lt;-ch</code><br>之后 ok 会被设置为 false。</p><p>循环 <code>for i := range ch</code> 会不断从通道接收数据直到它被关闭</p><p><strong>注意：</strong> 信道通常情况无需关闭，只有在必须告诉接收者不在有要发送的数据时才有必要关闭，不合理的关闭反而会带来各种问题，比如往一个已关闭的通道里写入数据导致 panic。因此很多 Channel 的使用教程会建议不要关闭通道，或者说只有发送者才能关闭通道</p><h3 id="select-通道"><a href="#select-通道" class="headerlink" title="select 通道"></a>select 通道</h3><p>select 语句使一个 Go 程可以等待多个通信操作。select 会阻塞到某个分支可以继续执行为止，这时就会执行该分支。当多个分支都准备好时会随机选择一个执行。</p><pre><code class="go">select &#123;case v &lt;- ch1:case v &lt;- ch2:case &lt;-quit:    return&#125;</code></pre><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><blockquote><p>Channel 的几种经典应用场景及示例</p></blockquote><p>Channel 用于 Goroutine 之间的通信，常用于交换数据、并发控制、协程同步、超时控制等场景</p><h3 id="1-生产-消费模型"><a href="#1-生产-消费模型" class="headerlink" title="1. 生产-消费模型"></a>1. 生产-消费模型</h3><p>用来在生产者和消费者之前的数据传输，生产者协程将结果发送到通道，消费者协程从通道读取结果，生产者和消费者是并发进行的</p><pre><code class="go">func producer(ch chan&lt;- int) &#123;    defer close(ch)    for i := 0; i &lt; 5; i++ &#123;        time.Sleep(time.Second)        fmt.Printf(&quot;[%s] Produced: %d\n&quot;, time.Now().Format(time.DateTime), i)        ch &lt;- i    &#125;&#125;func consumer(ch &lt;-chan int) &#123;    for &#123;        if v, ok := &lt;-ch; ok &#123;            time.Sleep(time.Second)            fmt.Printf(&quot;[%s] Consumed: %d\n&quot;, time.Now().Format(time.DateTime), v)        &#125; else &#123;            break        &#125;    &#125;&#125;func TestProdConsume(t *testing.T) &#123;    ch := make(chan int, 5)    go producer(ch)    go consumer(ch)    time.Sleep(10 * time.Second)&#125;</code></pre><p>执行结果如下：</p><pre><code class="md">=== RUN   TestProdConsume[2023-05-15 00:35:58] Produced: 0[2023-05-15 00:35:59] Produced: 1[2023-05-15 00:35:59] Consumed: 0[2023-05-15 00:36:00] Consumed: 1[2023-05-15 00:36:00] Produced: 2[2023-05-15 00:36:01] Consumed: 2[2023-05-15 00:36:01] Produced: 3[2023-05-15 00:36:02] Consumed: 3[2023-05-15 00:36:02] Produced: 4[2023-05-15 00:36:03] Consumed: 4--- PASS: TestProdConsume (10.00s)</code></pre><h3 id="2-限制并发数"><a href="#2-限制并发数" class="headerlink" title="2. 限制并发数"></a>2. 限制并发数</h3><p>当你有大量任务想通过 Goroutine 并发处理，但又不希望同时起太多 Goroutine 导致负载过高，可以通过 Channel 控制并发数量。</p><p>以下代码示例中，TotalNum 表示任务总数，ParallelNum 表示并发数</p><pre><code class="go">func TestConcurrencyNumberLimit(t *testing.T) &#123;    const TotalNum = 10    const ParallelNum = 2    wg := &amp;sync.WaitGroup&#123;&#125;    // 限制并发数，缓冲区大小即为最大并发数    ch := make(chan struct&#123;&#125;, ParallelNum)    for i := 0; i &lt; TotalNum; i++ &#123;        wg.Add(1)        // 通道满时写入操作阻塞在这里，则不会继续起新的协程        ch &lt;- struct&#123;&#125;&#123;&#125;        go func(idx int) &#123;            defer func() &#123;                wg.Done()                &lt;-ch            &#125;()            fmt.Printf(&quot;[%s] process: %d/%d\n&quot;, time.Now().Format(time.DateTime), idx, TotalNum)            time.Sleep(1 * time.Second)        &#125;(i + 1)    &#125;    wg.Wait()&#125;</code></pre><p>执行结果如下，可以看到并发数设置为 2 时每秒完成两个任务，10 个任务总共耗时 5 秒</p><pre><code class="md">=== RUN   TestConcurrencyNumber[2023-05-15 00:07:42] process: 2/10[2023-05-15 00:07:42] process: 1/10[2023-05-15 00:07:43] process: 3/10[2023-05-15 00:07:43] process: 4/10[2023-05-15 00:07:44] process: 5/10[2023-05-15 00:07:44] process: 6/10[2023-05-15 00:07:45] process: 7/10[2023-05-15 00:07:45] process: 8/10[2023-05-15 00:07:46] process: 9/10[2023-05-15 00:07:46] process: 10/10--- PASS: TestConcurrencyNumber (5.00s)</code></pre><h3 id="3-超时控制"><a href="#3-超时控制" class="headerlink" title="3. 超时控制"></a>3. 超时控制</h3><pre><code class="go">func TestTimeout(t *testing.T) &#123;    ch := make(chan int, 1)    // 执行一个耗时的任务    go func() &#123;        time.Sleep(2 * time.Second)        ch &lt;- 1    &#125;()    select &#123;    case res := &lt;-ch:        // 任务执行完毕        fmt.Println(&quot;result: &quot;, res)    case &lt;-time.After(1 * time.Second):        // 任务执行超时        fmt.Println(&quot;timeout&quot;)    &#125;&#125;</code></pre><p>当任务耗时 2 秒，超时时间 1 秒时输出如下：</p><pre><code class="md">=== RUN   TestTimeouttimeout--- PASS: TestTimeout (1.00s)</code></pre><p>当任务耗时 2 秒，超时时间 3 秒时输出如下：</p><pre><code class="md">=== RUN   TestTimeoutresult:  1--- PASS: TestTimeout (2.00s)</code></pre><h2 id="如何优雅关闭通道"><a href="#如何优雅关闭通道" class="headerlink" title="如何优雅关闭通道"></a>如何优雅关闭通道</h2><p>关于 “只能发送者关闭通道” 只是一种口头的约束，你可以在任何地方调用 <code>close</code> 方法来关闭通道，程序也可以编译运行。</p><p>实际上是发送者还是接收者关闭通道并没有太大影响，重点是通道的所有者，通常是创建通道的 Goroutine 做为所有者，负责管理通道的生命周期。</p><p>如果是一个发送者，可以直接由发送者关闭。<br>如果是多个发送者，希望所有发送者发送完毕再关闭通道，则需要有个额外的 Goroutine 来管理所有发送者，并在所有发送者结束后来关闭通道。代码示例如下：</p><pre><code class="go">func TestCh(t *testing.T) &#123;    ch := make(chan int, 10)    // 启动所有发送者协程    wg := &amp;sync.WaitGroup&#123;&#125;    for i := 1; i &lt; 10; i++ &#123;        wg.Add(1)        go func(v int) &#123;            defer wg.Done()            ch &lt;- v            fmt.Println(&quot;send:&quot;, v)        &#125;(i)    &#125;    // 启动接受者协程    quit := make(chan struct&#123;&#125;)    go func() &#123;        // 接收数据直到通道关闭        for v := range ch &#123;            fmt.Println(&quot;receive:&quot;, v)        &#125;        quit &lt;- struct&#123;&#125;&#123;&#125;    &#125;()    // 等待所有发送者协程结束，关闭通道    wg.Wait()    fmt.Println(&quot;send over...&quot;)    close(ch)    // 等待接收者协程结束    &lt;-quit    fmt.Println(&quot;receive over!!!&quot;)&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Channel 基本概念介绍&lt;/p&gt;
&lt;p&gt;基本使用方法参见 &lt;a href=&quot;https://tour.go-z</summary>
      
    
    
    
    <category term="Golang" scheme="https://harryzhang.cn/categories/Golang/"/>
    
    
    <category term="Go" scheme="https://harryzhang.cn/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>Go 语言中的值方法和指针方法</title>
    <link href="https://harryzhang.cn/2023/05/14/Go-%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%80%BC%E6%96%B9%E6%B3%95%E5%92%8C%E6%8C%87%E9%92%88%E6%96%B9%E6%B3%95/"/>
    <id>https://harryzhang.cn/2023/05/14/Go-%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%80%BC%E6%96%B9%E6%B3%95%E5%92%8C%E6%8C%87%E9%92%88%E6%96%B9%E6%B3%95/</id>
    <published>2023-05-14T08:21:05.000Z</published>
    <updated>2023-08-16T14:35:56.126Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="函数和方法"><a href="#函数和方法" class="headerlink" title="函数和方法"></a>函数和方法</h3><p>在 Go 语言中，我们可以为自定义类型定义方法。方法是一个与特定类型关联的函数。方法可以被定义在值类型上或指针类型上。这两种方法分别称为值方法和指针方法。</p><pre><code class="go">// 函数func Hello() &#123;    fmt.Println(&quot;Hello World!&quot;)&#125;type Welcome struct&#123;&#125;// 方法func (w Welcome) Hello() &#123;    fmt.Println(&quot;Hello World!&quot;)&#125;</code></pre><h3 id="接收者"><a href="#接收者" class="headerlink" title="接收者"></a>接收者</h3><ul><li>值方法: 是定义在值类型上的方法，它们使用值作为接收器（即方法调用的目标对象）。</li><li>指针方法: 是定义在指针类型上的方法，它们使用指针作为接收器。</li></ul><pre><code class="go">// 指针方法func (w *Welcome) SetName(name string) &#123;    w.name = name&#125;// 值方法func (w Welcome) Welcome() &#123;    fmt.Printf(&quot;Welcome %s&quot;, w.name)&#125;</code></pre><h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><ul><li>如果你在类型上定义了一个值方法，那么它不会修改接收者的原始值，如果定义了指针方法，则可以修改接收者的原始值</li><li>值方法可以通过指针和值类型的变量调用</li><li>指针方法只能通过指针变量来调用，但是如果某个值是可寻址的（addressable，或者说左值），那么编译器会在值调用指针方法时自动插入取地址符，使得在此情形下看起来像指针方法也可以通过值来调用</li></ul><pre><code class="go">func TestWelcome(t *testing.T) &#123;    // 正确: 值类型调用值类型的方法    NewWelcome().Hello()    // 正确: 指针类型的变量可以调用指针方法和值方法    NewWelcomePtr().SetName(&quot;Harry&quot;)    NewWelcomePtr().Welcome()    // 正常: w 为值类型的变量，但是因为 w 是可寻址的，所以编译器会自动转换    w := NewWelcome()    w.SetName(&quot;Harry&quot;)    w.Welcome()    // 报错: cannot call pointer method SetName on Welcome    // 函数返回值是不可寻址的    NewWelcome().SetName(&quot;Harry&quot;)&#125;</code></pre><h2 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h2><ul><li>如果需要修改接收者的原始值，则必须使用指针方法</li><li>当不希望方法修改接收者的原始值时使用值方法</li><li>当不需要修改原始值且对象比较大时希望避免因值传递带来的性能开销时，使用指针方法。</li><li>当不需要修改原始值且对象比较简单时使用值方法</li></ul><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="自动转换"><a href="#自动转换" class="headerlink" title="自动转换"></a>自动转换</h3><p>Go 语言会自动处理值和指针之间的转换。即使定义了指针方法，也可以通过值调用它（Go 会自动转换为指针）；同样，定义了值方法，也可以通过指针调用它（Go 会自动解引用）。</p><h3 id="左值和右值"><a href="#左值和右值" class="headerlink" title="左值和右值"></a>左值和右值</h3><table><thead><tr><th>值类型</th><th align="left">区别</th></tr></thead><tbody><tr><td>左值</td><td align="left">可寻址，可通过 <code>&amp;</code> 取地址符获取内存地址</td></tr><tr><td>右值</td><td align="left">不可寻址，没有分配内存地址</td></tr></tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>值方法内的修改不会影响接收者原始值，指针方法可以</li><li>指针类型可以调用指针方法和值方法</li><li>值类型只能调用值方法，但是如果该值是可寻址的情况编译器会自动转换，使得看起来像值类型调用了指针方法</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h2&gt;&lt;h3 id=&quot;函数和方法&quot;&gt;&lt;a href=&quot;#函数和方法&quot; class=&quot;headerlink&quot; title=&quot;函数和方法&quot;&gt;&lt;/a&gt;函数和方</summary>
      
    
    
    
    <category term="Golang" scheme="https://harryzhang.cn/categories/Golang/"/>
    
    
    <category term="Go" scheme="https://harryzhang.cn/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>数据结构（6）: 单调栈</title>
    <link href="https://harryzhang.cn/2023/04/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-6-%E5%8D%95%E8%B0%83%E6%A0%88/"/>
    <id>https://harryzhang.cn/2023/04/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-6-%E5%8D%95%E8%B0%83%E6%A0%88/</id>
    <published>2023-04-02T08:29:44.000Z</published>
    <updated>2023-04-22T14:15:12.779Z</updated>
    
    <content type="html"><![CDATA[<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><p>单调栈是一种特殊的栈数据结构，它满足元素的单调性（单调递增或单调递减）。与普通栈相比，单调栈在出栈时有一定的规则，使得出栈后栈中的元素仍然保持单调性。</p><p>单调栈主要有两个操作：入栈和出栈。入栈时，先判断栈顶元素是否符合单调性，如果不符合，则将其弹出，一直重复此过程直到符合单调性后再入栈；出栈时，弹出栈顶元素即可。</p><h2 id="算法应用"><a href="#算法应用" class="headerlink" title="算法应用"></a>算法应用</h2><p>单调栈在算法中有许多应用，例如在求解 Next Greater Element（下一个更大元素）等问题中。</p><p>以求解 Next Greater Element 问题为例，给定一个数组 nums，要求找出每个元素的下一个更大元素（即在数组中右边第一个比它大的数），若不存在则为-1。我们可以使用单调栈来解决这个问题。</p><p>具体的实现步骤如下：</p><ol><li>遍历数组 nums，依次将元素入栈</li><li>当栈顶元素小于当前元素时，弹出栈顶元素，将其下一个更大元素设为当前元素，并继续弹出栈顶元素，直到栈为空或栈顶元素大于等于当前元素</li><li>当遍历完数组后，栈中剩余的元素的下一个更大元素均为-1</li></ol><p>实例代码：</p><pre><code class="go">func nextGreaterElement(nums []int) []int &#123;    stack := []int&#123;&#125;    res := make([]int, len(nums))    for i := range res &#123;        res[i] = -1    &#125;    for i := 0; i &lt; len(nums); i++ &#123;        for len(stack) &gt; 0 &amp;&amp; nums[stack[len(stack)-1]] &lt; nums[i] &#123;            res[stack[len(stack)-1]] = nums[i]            stack = stack[:len(stack)-1]        &#125;        stack = append(stack, i)    &#125;    return res&#125;</code></pre><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><h3 id="1-每日温度"><a href="#1-每日温度" class="headerlink" title="1. 每日温度"></a>1. 每日温度</h3><blockquote><p><a href="https://leetcode.cn/problems/daily-temperatures/">LeetCode 739. 每日温度</a></p><p>给定一个整数数组 temperatures ，表示每天的温度，返回一个数组 answer ，其中 answer[i] 是指对于第 i 天，下一个更高温度出现在几天后。如果气温在这之后都不会升高，请在该位置用 0 来代替。</p></blockquote><p>该问题就是典型的 <strong>Next Greater Element（下一个更大元素）</strong> 问题，题目等价于找出右边第一个比当前元素大的距离。</p><p><code>示例代码:</code></p><pre><code class="go">func dailyTemperatures(temperatures []int) []int &#123;    n := len(temperatures)    ans := make([]int, n)    stk := []int&#123;&#125;    for i := 0; i &lt; n; i++ &#123;        for len(stk) &gt; 0 &amp;&amp; temperatures[i] &gt; temperatures[stk[len(stk)-1]] &#123;            top := stk[len(stk)-1]            stk = stk[:len(stk)-1]            ans[top] = i - top        &#125;        stk = append(stk, i)    &#125;    return ans&#125;</code></pre><h3 id="2-循环数组下一个更大元素"><a href="#2-循环数组下一个更大元素" class="headerlink" title="2. 循环数组下一个更大元素"></a>2. 循环数组下一个更大元素</h3><blockquote><p><a href="https://leetcode.cn/problems/next-greater-element-ii/">LeetCode 503. 下一个更大元素 II</a></p><p>给定一个循环数组 nums （ nums[nums.length - 1] 的下一个元素是 nums[0] ），返回 nums 中每个元素的 下一个更大元素 。<br>数字 x 的 下一个更大的元素 是按数组遍历顺序，这个数字之后的第一个比它更大的数，这意味着你应该循环地搜索它的下一个更大的数。如果不存在，则输出 -1 。</p></blockquote><p>该问题和题目 <code>739. 每日温度</code> 类似，不同点在于该问题是循环数组，遍历到最后一个元素后要循环变量一次，因此只需要将遍历的次数改为 <code>2 * n</code> ，取下标改成 <code>i % n</code> 即可</p><p><code>示例代码:</code></p><pre><code class="go">func nextGreaterElements(nums []int) []int &#123;    n := len(nums)    ans := make([]int, n)    for i := range ans &#123;        ans[i] = -1    &#125;    stk := []int&#123;&#125;    for i := 0; i &lt; 2*n; i++ &#123;        for len(stk) &gt; 0 &amp;&amp; nums[i%n] &gt; nums[stk[len(stk)-1]] &#123;            top := stk[len(stk)-1]            stk = stk[:len(stk)-1]            ans[top] = nums[i%n]        &#125;        stk = append(stk, i%n)    &#125;    return ans&#125;</code></pre><h3 id="3-接雨水"><a href="#3-接雨水" class="headerlink" title="3. 接雨水"></a>3. 接雨水</h3><blockquote><p><a href="https://leetcode.cn/problems/trapping-rain-water/">LeetCode 42. 接雨水</a><br>给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。</p></blockquote><p><code>示例代码：</code></p><pre><code class="go">func trap(height []int) int &#123;    stk := []int&#123;&#125;    ans := 0    for i := 0; i &lt; len(height); i++ &#123;        for len(stk) &gt; 0 &amp;&amp; height[stk[len(stk)-1]] &lt; height[i] &#123;            top := stk[len(stk)-1]            stk = stk[:len(stk)-1]            if len(stk) &gt; 0 &#123;                // 弹出的栈顶元素、当前栈顶元素、当前元素构成凹槽区域                // 高：当前元素和当前栈顶元素的较小值 - 弹出的栈顶元素                // 宽：当前元素下标 - 当前栈顶元素下表 - 1                ans += (min(height[i], height[stk[len(stk)-1]]) - height[top]) * (i - stk[len(stk) - 1] - 1)            &#125;        &#125;        stk = append(stk, i)    &#125;    return ans&#125;func min(x, y int) int &#123;    if x &lt; y &#123;        return x    &#125;    return y&#125;</code></pre><h3 id="4-柱状图中最大矩形"><a href="#4-柱状图中最大矩形" class="headerlink" title="4. 柱状图中最大矩形"></a>4. 柱状图中最大矩形</h3><blockquote><p><a href="https://leetcode.cn/problems/largest-rectangle-in-histogram/">LeetCode 84. 柱状图中最大的矩形</a><br>给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。求在该柱状图中，能够勾勒出来的矩形的最大面积。</p></blockquote><p>该问题比 <code>42. 接雨水</code> 问题难的点在于要注意边界条件，为方便处理输入本身单调递增和单调递减的边界情况，在输入列表头和尾各添加一个 0。</p><p><code>示例代码：</code></p><pre><code class="go">func largestRectangleArea(heights []int) int &#123;    ans := 0    // 头尾各加一个 0 处理边界 case    heights = append([]int&#123;0&#125;, heights...)    heights = append(heights, 0)    stk := []int&#123;0&#125;    for i := 1; i &lt; len(heights); i++ &#123;        for heights[i] &lt; heights[stk[len(stk)-1]] &#123;            top := stk[len(stk)-1]            stk = stk[:len(stk)-1]            // 高：弹出的栈顶元素            // 宽：当前元素下标 - 当前栈顶下标 - 1            h := heights[top]            w := i - stk[len(stk)-1] - 1            ans = max(ans, h*w)        &#125;        stk = append(stk, i)    &#125;    return ans&#125;func max(x, y int) int &#123;    if x &gt; y &#123;        return x    &#125;    return y&#125;</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>使用单调栈解决算法问题的关键点有一下几点：</p><ol><li>找到需要维护单调性的数组。通常是需要找到比当前位置大或小的元素。</li><li>根据需要维护的单调性，选择递增栈或递减栈。</li><li>确定每个元素的入栈和出栈条件。入栈条件通常是当前元素与栈顶元素的比较关系，出栈条件通常是满足当前单调性的元素。</li><li>对于每个入栈的元素，计算其对应的答案。通常是栈顶元素对应的答案，即找到比当前元素大或小的元素。</li><li>根据具体情况，确定栈中存储的是元素的下标还是元素本身。</li><li>单调栈算法通常需要先对数组进行预处理，以便在计算过程中能够快速获取需要的信息。另外，在使用单调栈解决算法问题时，需要特别注意边界条件和特殊情况的处理，以保证算法的正确性和稳定性。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;特性&quot;&gt;&lt;a href=&quot;#特性&quot; class=&quot;headerlink&quot; title=&quot;特性&quot;&gt;&lt;/a&gt;特性&lt;/h2&gt;&lt;p&gt;单调栈是一种特殊的栈数据结构，它满足元素的单调性（单调递增或单调递减）。与普通栈相比，单调栈在出栈时有一定的规则，使得出栈后栈中的元素仍然保</summary>
      
    
    
    
    <category term="数据结构" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="leetcode" scheme="https://harryzhang.cn/tags/leetcode/"/>
    
    <category term="单调栈" scheme="https://harryzhang.cn/tags/%E5%8D%95%E8%B0%83%E6%A0%88/"/>
    
  </entry>
  
  <entry>
    <title>Go 协程调度原理及应用</title>
    <link href="https://harryzhang.cn/2023/03/25/Go-%E5%8D%8F%E7%A8%8B%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://harryzhang.cn/2023/03/25/Go-%E5%8D%8F%E7%A8%8B%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%E5%8F%8A%E5%BA%94%E7%94%A8/</id>
    <published>2023-03-25T07:42:00.000Z</published>
    <updated>2023-03-25T07:48:34.093Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是协程？"><a href="#什么是协程？" class="headerlink" title="什么是协程？"></a>什么是协程？</h2><h3 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h3><p>一个应用程序时运行在操作系统上的一个进程。<strong>进程</strong>是一个运行在自己独立内存空间的独立执行体，是操作系统进行资源分配的最小单位。一个进程则有一个或多个线程组成，这些<strong>线程</strong>是共享进程内存地址空间的执行体，是操作系统进行任务调度的最小单位。而使用多线程进行工作时，由于共享父进程的内存空间等资源，访问同一个数据需要对其进行加锁，保证同一时间只有一个线程操作一个数据。这样不仅会提高编码的复杂度，还会有多个线程抢占锁、线程切换带来的额外开销。</p><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><p>在Go中，应用程序并发处理的部分被称作<strong>goroutines（协程）</strong>，它是一种更轻量级的线程，和操作系统的线程之间并无一对一的关系。<strong>协程</strong>是根据一个或多个线程的可用性，映射（多路复用，执行于）在它们之上的；协程调度器负责在Go运行时调度进行协程的工作。</p><h3 id="通道（Channel）"><a href="#通道（Channel）" class="headerlink" title="通道（Channel）"></a>通道（Channel）</h3><p>协程工作在相同的地址空间中，所以共享内存的方式是同步的，可以使用互斥锁来实现，但是Go中更好的方案是使用Channel来同步协程。<br>通道类型（Chan）就像一个可用于发送类型化数据的管道，由其负责协程之间的通信，在任何时间，一个通道数据被设计为只有一个协程可以对其访问，所以不会发生数据竞争。</p><h4 id="通道阻塞"><a href="#通道阻塞" class="headerlink" title="通道阻塞"></a>通道阻塞</h4><p>默认情况下，Go创建的通道是同步且无缓冲的：在有接受者接受数据之前，发送不会结束，发送者是直接将数据交给接受者的，所以这种通道的发送或接受操作在对方准备好之前都是阻塞的。<br>例如以下代码，执行会报错死锁：<br><code>示例1.1:</code></p><pre><code class="go">func main() &#123;    ch := make(chan int)    ch &lt;- 1    &lt;-ch&#125;</code></pre><p>因为对ch的读写都在main函数的主协程中，执行到<code>ch &lt;-1</code>时由于接收ch的数据还没准备好，发送数据将被阻塞，程序无法继续执行。必须使用关键字<code>go</code>来启动一个新的协程发送数据，另一个协程接收数据，如下所示：<br><code>示例1.2</code></p><pre><code class="go">func main() &#123;    ch := make(chan int)    go func() &#123;        ch &lt;- 1    &#125;()    fmt.Println(&lt;- ch)&#125;</code></pre><p>使用<code>make</code>创建一个通道的时候可以传入第二个参数指定通道缓冲区大小，这种方式在通道写满之前，发送数据不会被阻塞，通道不为空时接收操作不会被阻塞，如果将示例1.1中的创建通道传第二个参数为1，就可以正常运行不会死锁了，代码如下：<br><code>示例1.3</code></p><pre><code class="go">func main() &#123;    ch := make(chan int, 1)    ch &lt;- 1    fmt.Println(&lt;- ch)&#125;</code></pre><h2 id="Go协程调度原理"><a href="#Go协程调度原理" class="headerlink" title="Go协程调度原理"></a>Go协程调度原理</h2><h3 id="调度器架构"><a href="#调度器架构" class="headerlink" title="调度器架构"></a>调度器架构</h3><p>Go的调度器从最开始的单线程经过不断的改进、优化，发展到现在的GMP模型，在GMP模型中有三个重要的结构：</p><ul><li>G(Goroutine)：go协程，一个可执行单元，调度器作用就是对所有G的切换</li><li>M(Thread)：操作系统上的线程，G运行与M上，一个G可能由多个不同的M运行，一个M可以运行多个G</li><li>P(Processor)：处理器，他包含了运行G的资源，如果线程M想运行G，必须先获取P，P还包含了可运行的G队列。一个M一个时刻只拥有一个P，M和P的数量是1：1的。</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/14151453-3c06a96e56ff490b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-3c06a96e56ff490b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="GMP模型架构"></p><p>上图中各个模块的作用如下：</p><ol><li>全局队列：存放等待运行G</li><li>P的本地队列：和全局队列类似，存放的也是等待运行的G，存放数量上限256个。新建G时，G优先加入到P的本地队列，如果队列满了，则会把本地队列中的一半G移动到全局队列</li><li>P列表：所有的P都在程序启动时创建，保存在数组中，最多有<code>GOMAXPROCS</code>个，可通过<code>runtime.GOMAXPROCS(N)</code>修改，N表示设置的个数</li></ol><p>M是Goroutine调度器和操作系统调度器的桥梁，每个M代表一个内核线程，操作系统调度器负责把内核线程分配到CPU的核心上执行。</p><h3 id="调度策略"><a href="#调度策略" class="headerlink" title="调度策略"></a>调度策略</h3><h5 id="复用线程"><a href="#复用线程" class="headerlink" title="复用线程"></a>复用线程</h5><p>调度器核心思想是尽可能避免频繁的创建、销毁线程，对线程进行复用以提高效率。<br><strong>1. work stealing机制（窃取式）</strong><br>当本线程无G可运行时，尝试从其他线程绑定的P窃取G，而不是直接销毁线程。<br><strong>2. hand off机制</strong><br>当本线程M因为G进行的系统调用阻塞是，线程释放绑定的P，把P转移给其他空闲的M’执行。</p><h5 id="利用多核CPU并行"><a href="#利用多核CPU并行" class="headerlink" title="利用多核CPU并行"></a>利用多核CPU并行</h5><p><code>GOMAXPROCS</code>设置P的数量，最多有<code>GOMAXPROCS</code>个线程分布在多个CPU核心上运行。</p><h4 id="抢占"><a href="#抢占" class="headerlink" title="抢占"></a>抢占</h4><p>一个goroutine最多占用CPU10ms，防止其他goroutine等待太久得不到执行被“饿死”。</p><h4 id="全局G队列"><a href="#全局G队列" class="headerlink" title="全局G队列"></a>全局G队列</h4><p>全局G队列是有互斥锁保护的，访问需要竞争锁，新的调度器将其功能弱化了，当M执行work stealing从其他P窃取不到G时，才会去全局G队列获取G。</p><h2 id="Go并发编程实例"><a href="#Go并发编程实例" class="headerlink" title="Go并发编程实例"></a>Go并发编程实例</h2><h3 id="两个协程交替打印1-100"><a href="#两个协程交替打印1-100" class="headerlink" title="两个协程交替打印1-100"></a>两个协程交替打印1-100</h3><blockquote><p>用两个协程顺序打印出1-100，要求一个协程打印1、3、5、7…奇数，另一个协程打印2、4、6、8…偶数，输出必须是顺序的。</p></blockquote><p><code>示例代码：</code></p><pre><code class="go">func main() &#123;    // ch用来同步两个协程交替执行    ch := make(chan int)    // ch_end用来阻塞主程序，让两个协程可以执行完    ch_end := make(chan int)    go func() &#123;        for i := 1; i &lt;= 100; i++ &#123;            ch &lt;- 1            if i % 2 == 0 &#123;                fmt.Println(i)            &#125;        &#125;        ch_end &lt;- 1    &#125;()    go func() &#123;        for i := 1; i &lt;= 100; i++ &#123;            &lt;-ch            if i % 2 != 0 &#123;                fmt.Println(i)            &#125;        &#125;    &#125;()    &lt;-ch_end&#125;</code></pre><h3 id="并行素数筛选"><a href="#并行素数筛选" class="headerlink" title="并行素数筛选"></a>并行素数筛选</h3><blockquote><p>有一个协程不断生2~n的自然数，对每个素数起一个协程，用来筛选素数</p></blockquote><p><code>示例代码:</code></p><pre><code class="go">func generate(ch chan int, n int) &#123;    for i := 2; i &lt;= n ; i++ &#123;        fmt.Println(&quot;generate:&quot;, i)        ch &lt;- i    &#125;    close(ch)&#125;func filter(in, out chan int, prime int) &#123;    for i := range in &#123;        fmt.Printf(&quot;filter(%d): %d\n&quot;, prime, i)        if i % prime != 0 &#123;            out &lt;- i        &#125;    &#125;    close(out)&#125;func main() &#123;    res := []int&#123;&#125;    ch := make(chan int)    go generate(ch, 112)        for &#123;        if prime, ok := &lt;- ch; ok &#123;            res = append(res, prime)            ch_out := make(chan int)            go filter(ch, ch_out, prime)            // 前一个素数过滤协程的输出通道是后一个素数过滤通道的输入通道            ch = ch_out        &#125; else &#123;            break        &#125;    &#125;    fmt.Println(&quot;main:&quot;, res)&#125;</code></pre><h3 id="实现超时机制"><a href="#实现超时机制" class="headerlink" title="实现超时机制"></a>实现超时机制</h3><blockquote><p>当设置的超时时间到达后如果work还不可执行就终止等待，返回超时</p></blockquote><p><code>示例代码</code></p><pre><code class="go">func TimeOut(timeout time.Duration) &#123;    ch_to := make(chan bool, 1)    go func() &#123;        time.Sleep(timeout)        ch_to &lt;- true    &#125;()    ch_do := make(chan int, 1)    go func() &#123;        time.Sleep(3e9)        ch_do &lt;- 1    &#125;()    select &#123;    case i := &lt;- ch_do:        fmt.Println(&quot;do something, id:&quot;, i)    case &lt;-ch_to:        fmt.Println(&quot;timeout&quot;)        break    &#125;&#125;</code></pre><h3 id="实现迭代器"><a href="#实现迭代器" class="headerlink" title="实现迭代器"></a>实现迭代器</h3><blockquote><p>实现一个惰性迭代器，每次调用返回一个列表元素，直到所有的元素被访问完返回nil</p></blockquote><p><code>示例代码：</code></p><pre><code class="go">// 迭代器func iterator(iterable []interface&#123;&#125;) chan interface&#123;&#125;&#123;    yield := make(chan interface&#123;&#125;)    go func() &#123;        for i := 0; i &lt; len(iterable); i++ &#123;            yield &lt;- iterable[i]        &#125;        close(yield)    &#125;()    return yield&#125;// 获取下一个元素func next(iter chan interface&#123;&#125;) interface&#123;&#125; &#123;    for v := range iter &#123;        return v    &#125;    return nil&#125;func main() &#123;    nums := []interface&#123;&#125;&#123;1, 2, 3, 4, 5&#125;    iter := iterator(nums)    for v := next(iter); v != nil; v = next(iter) &#123;        fmt.Println(v)    &#125;&#125;</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://github.com/unknwon/the-way-to-go_ZH_CN/blob/master/eBook/14.1.md">《The Way to Go》：并发、并行和协程</a><br>【2】<a href="https://studygolang.com/articles/26795">Golang的协程调度器原理及GMP设计思想？</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是协程？&quot;&gt;&lt;a href=&quot;#什么是协程？&quot; class=&quot;headerlink&quot; title=&quot;什么是协程？&quot;&gt;&lt;/a&gt;什么是协程？&lt;/h2&gt;&lt;h3 id=&quot;进程和线程&quot;&gt;&lt;a href=&quot;#进程和线程&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="Golang" scheme="https://harryzhang.cn/categories/Golang/"/>
    
    
    <category term="Goroutine" scheme="https://harryzhang.cn/tags/Goroutine/"/>
    
    <category term="GMP" scheme="https://harryzhang.cn/tags/GMP/"/>
    
  </entry>
  
  <entry>
    <title>Go 实战: 基于Thrift框架的 RPC 服务 Demo</title>
    <link href="https://harryzhang.cn/2023/03/25/Go-%E5%AE%9E%E6%88%98-%E5%9F%BA%E4%BA%8EThrift%E6%A1%86%E6%9E%B6%E7%9A%84-RPC-%E6%9C%8D%E5%8A%A1-Demo/"/>
    <id>https://harryzhang.cn/2023/03/25/Go-%E5%AE%9E%E6%88%98-%E5%9F%BA%E4%BA%8EThrift%E6%A1%86%E6%9E%B6%E7%9A%84-RPC-%E6%9C%8D%E5%8A%A1-Demo/</id>
    <published>2023-03-25T07:40:58.000Z</published>
    <updated>2023-03-25T07:44:11.943Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Thrift架构简介"><a href="#Thrift架构简介" class="headerlink" title="Thrift架构简介"></a>Thrift架构简介</h2><p>Thrift自顶向下可分为四层</p><ol><li><p>Server(single-threaded, event-driven)服务器进程调度</p></li><li><p>Processor(compiler generated)RPC接口处理函数分发，IDL定义接口的实现将挂接到这里面</p></li><li><p>Protocol (JSON, compact etc)协议，定义数据传输格式</p><ul><li>TBinaryProtocol（二进制格式）</li><li>TCompactProtocol（压缩格式）</li><li>TJSONProtocol （JSON格式）</li><li>TDebugProtocol （易看的文本格式，方便debug）</li></ul></li><li><p>Transport(raw TCP, HTTP etc)网络传输，定义数据传输方式</p><ul><li>TSocket（阻塞式socket）</li><li>TServerTransport（服务端模式，非阻塞socket）</li><li>TFramedTransport（以帧为单位，非阻塞式）</li><li>TMemoryTransport（内存形式）</li><li>TFileTransport（文件形式）</li><li>TZlibTransport（使用zlib压缩，与其他方式联合使用）</li></ul></li></ol><p>Thrift实际上是实现了C&#x2F;S模式，通过代码生成工具将接口定义文件生成服务器端和客户端代码（可以为不同语言），从而实现服务端和客户端跨语言的支持。</p><h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><p>系统：macOS Big Sur 11.1<br>IDE ：GoLand 2020.3.4<br>Thrift：0.14.1</p><h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h2><h3 id="安装thrift"><a href="#安装thrift" class="headerlink" title="安装thrift"></a>安装thrift</h3><pre><code class="shell">brew install thrift # 安装thrift -version # 查看版本检查是否安装成功</code></pre><h3 id="安装thrift-support插件"><a href="#安装thrift-support插件" class="headerlink" title="安装thrift support插件"></a>安装thrift support插件</h3><p>Plugins-&gt;Marketplace搜索thrift support，安装后重启IDE即可<br>如果搜不到可以去<a href="https://plugins.jetbrains.com/plugin/14004-protocol-buffer-editor/versions">官网</a>下载对应版本的安装包本地安装<br><img src="https://upload-images.jianshu.io/upload_images/14151453-a18237de10e5fbcc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-a18237de10e5fbcc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h2 id="开发"><a href="#开发" class="headerlink" title="开发"></a>开发</h2><h3 id="编写thrift-IDL"><a href="#编写thrift-IDL" class="headerlink" title="编写thrift IDL"></a>编写thrift IDL</h3><p><a href="https://thrift.apache.org/docs/idl.html">IDL语法官方文档</a></p><p>user.thrift</p><pre><code class="thrift">namespace go demostruct User &#123;    1:required i32 id,    2:required string name,    3:required string avatar,    4:required string address,    5:required string mobile,&#125;struct UserList &#123;    1:required list&lt;User&gt; userList,    2:required i32 page,    3:required i32 limit,&#125;</code></pre><p>service.thrift</p><pre><code class="thrift">include &quot;user.thrift&quot;// 标记各语言的命名空间（包名），不同语言需要单独声明namespace go demo// 重新定义类型名称，同c语言typedef map&lt;string, string&gt; Data// 定义响应体结构struct Response &#123;    1:required i32 errcode,    2:required string errmsg,    3:required Data data,&#125;// 定义服务接口，相当于go的interfaceservice Greeter &#123;    Response SayHello(        1:required user.User user    )    Response GetUser(        1:required i32 uid    )&#125;</code></pre><h3 id="生成目标语言代码"><a href="#生成目标语言代码" class="headerlink" title="生成目标语言代码"></a>生成目标语言代码</h3><p>执行命令：<code>thrift -r --gen go service.thrift</code><br>生成以下代码文件：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-309bcc4ed4fb76c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-309bcc4ed4fb76c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="编写golang服务端代码"><a href="#编写golang服务端代码" class="headerlink" title="编写golang服务端代码"></a>编写golang服务端代码</h3><p>服务端：</p><pre><code class="go">package mainimport (    &quot;context&quot;    &quot;encoding/json&quot;    &quot;flag&quot;    &quot;fmt&quot;    &quot;github.com/apache/thrift/lib/go/thrift&quot;    &quot;os&quot;    &quot;thrift_practice/src/gen-go/demo&quot;)func Usage() &#123;    fmt.Fprint(os.Stderr, &quot;Usage of &quot;, os.Args[0], &quot;:\n&quot;)    flag.PrintDefaults()    fmt.Fprint(os.Stderr, &quot;\n&quot;)&#125;//定义服务type Greeter struct &#123;&#125;//实现IDL里定义的接口//SayHellofunc (this *Greeter) SayHello(ctx context.Context, u *demo.User) (r *demo.Response, err error) &#123;    strJson, _ := json.Marshal(u)    return &amp;demo.Response&#123;Errcode: 0, Errmsg: &quot;success&quot;, Data: map[string]string&#123;&quot;User&quot;: string(strJson)&#125;&#125;, nil&#125;//GetUserfunc (this *Greeter) GetUser(ctx context.Context, uid int32) (r *demo.Response, err error) &#123;    return &amp;demo.Response&#123;Errcode: 1, Errmsg: &quot;user not exist.&quot;&#125;, nil&#125;func main() &#123;    //命令行参数    flag.Usage = Usage    addr := flag.String(&quot;addr&quot;, &quot;localhost:9090&quot;, &quot;Address to listen to&quot;)    flag.Parse()    //protocol    var protocolFactory thrift.TProtocolFactory    protocolFactory = thrift.NewTBinaryProtocolFactoryDefault()    //transport    var transportFactory thrift.TTransportFactory    transportFactory = thrift.NewTTransportFactory()    //handler    handler := &amp;Greeter&#123;&#125;    //transport,no secure    var err error    var transport thrift.TServerTransport    transport, err = thrift.NewTServerSocket(*addr)    if err != nil &#123;        fmt.Println(&quot;error running server:&quot;, err)    &#125;    //processor    processor := demo.NewGreeterProcessor(handler)    fmt.Println(&quot;Starting the simple server... on &quot;, *addr)    //start tcp server    server := thrift.NewTSimpleServer4(processor, transport, transportFactory, protocolFactory)    err = server.Serve()    if err != nil &#123;        fmt.Println(&quot;error running server:&quot;, err)    &#125;&#125;</code></pre><p>客户端：（借助go testing）</p><pre><code class="go">package mainimport (    &quot;context&quot;    &quot;fmt&quot;    &quot;github.com/apache/thrift/lib/go/thrift&quot;    &quot;testing&quot;    &quot;thrift_practice/src/gen-go/demo&quot;)var ctx = context.Background()func GetClient() *demo.GreeterClient &#123;    addr := &quot;:9090&quot;    var transport thrift.TTransport    var err error    transport, err = thrift.NewTSocket(addr)    if err != nil &#123;        fmt.Println(&quot;Error opening socket:&quot;, err)    &#125;    //protocol    var protocolFactory thrift.TProtocolFactory    protocolFactory = thrift.NewTBinaryProtocolFactoryDefault()    //no buffered    var transportFactory thrift.TTransportFactory    transportFactory = thrift.NewTTransportFactory()    transport, err = transportFactory.GetTransport(transport)    if err != nil &#123;        fmt.Println(&quot;error running client:&quot;, err)    &#125;    if err := transport.Open(); err != nil &#123;        fmt.Println(&quot;error running client:&quot;, err)    &#125;    iprot := protocolFactory.GetProtocol(transport)    oprot := protocolFactory.GetProtocol(transport)    client := demo.NewGreeterClient(thrift.NewTStandardClient(iprot, oprot))    return client&#125;//GetUserfunc TestGetUser(t *testing.T) &#123;    client := GetClient()    rep, err := client.GetUser(ctx, 100)    if err != nil &#123;        t.Errorf(&quot;thrift err: %v\n&quot;, err)    &#125; else &#123;        t.Logf(&quot;Recevied: %v\n&quot;, rep)    &#125;&#125;//SayHellofunc TestSayHello(t *testing.T) &#123;    client := GetClient()    user := &amp;demo.User&#123;&#125;    user.Name = &quot;thrift&quot;    user.Address = &quot;address&quot;    rep, err := client.SayHello(ctx, user)    if err != nil &#123;        t.Errorf(&quot;thrift err: %v\n&quot;, err)    &#125; else &#123;        t.Logf(&quot;Recevied: %v\n&quot;, rep)    &#125;&#125;</code></pre><h3 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h3><ol><li>运行服务端代码</li><li>运行客户端：<code>go test -v</code><br><img src="https://upload-images.jianshu.io/upload_images/14151453-ea5f1cec834f7b93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-ea5f1cec834f7b93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>【1】<a href="https://www.cnblogs.com/52fhy/p/11146047.html">从零开始基于go-thrift创建一个RPC服务</a><br>【2】<a href="https://thrift.apache.org/tutorial/go.html">Go Tutorial</a><br>【3】<a href="https://www.kancloud.cn/digest/batu-go/153528">Thrift RPC框架指南</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Thrift架构简介&quot;&gt;&lt;a href=&quot;#Thrift架构简介&quot; class=&quot;headerlink&quot; title=&quot;Thrift架构简介&quot;&gt;&lt;/a&gt;Thrift架构简介&lt;/h2&gt;&lt;p&gt;Thrift自顶向下可分为四层&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Server</summary>
      
    
    
    
    <category term="Golang" scheme="https://harryzhang.cn/categories/Golang/"/>
    
    
    <category term="Go" scheme="https://harryzhang.cn/tags/Go/"/>
    
    <category term="Thrift" scheme="https://harryzhang.cn/tags/Thrift/"/>
    
    <category term="RPC" scheme="https://harryzhang.cn/tags/RPC/"/>
    
  </entry>
  
  <entry>
    <title>Go 实战: Socket 编程</title>
    <link href="https://harryzhang.cn/2023/03/25/Go-%E5%AE%9E%E6%88%98-Socket-%E7%BC%96%E7%A8%8B/"/>
    <id>https://harryzhang.cn/2023/03/25/Go-%E5%AE%9E%E6%88%98-Socket-%E7%BC%96%E7%A8%8B/</id>
    <published>2023-03-25T07:40:10.000Z</published>
    <updated>2023-03-25T07:44:03.037Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Socket如何通信"><a href="#Socket如何通信" class="headerlink" title="Socket如何通信"></a>Socket如何通信</h2><p>在网络中要唯一确定一个进程需要用一个三元组（Protocol，IP，Port），IP地址唯一确定一台主机，再通过协议和端口唯一确定一个进程，这里也可以看到TCP和UDP可以绑定同一个端口。能唯一确定网络中的进程了，便可以利用这个标志在他们之间进行数据交互。</p><h2 id="Socket基础"><a href="#Socket基础" class="headerlink" title="Socket基础"></a>Socket基础</h2><h3 id="TCP-x2F-IP"><a href="#TCP-x2F-IP" class="headerlink" title="TCP&#x2F;IP"></a>TCP&#x2F;IP</h3><p>Go支持的IP类型</p><ul><li>IPv4</li><li>IPv6</li></ul><p>Go支持的协议类型</p><ul><li>TCP</li><li>UDP</li></ul><h2 id="Go-Socket编程"><a href="#Go-Socket编程" class="headerlink" title="Go Socket编程"></a>Go Socket编程</h2><p>Go语言的net包对TCP和UDP协议提供了支持，可以借助net改包方便的开发Socket应用</p><h3 id="TCP-Socket"><a href="#TCP-Socket" class="headerlink" title="TCP Socket"></a>TCP Socket</h3><p>TCP客户单和服务端通信时需要建立一个连接，Go语言的net包中<code>TCPConn</code>类型就表示一个TCP连接，主要有以下两个函数，用来读写数据：</p><pre><code class="go">func (c *TCPConn) Write(b []byte) (int, error)func (c *TCPConn) Read(b []byte) (int, error)</code></pre><p>客户端建立连接需要知道服务器的地址，net表中的<code>TCPAddr</code>类型表示一个TCP的地址信息，定义如下：</p><pre><code class="go">type TCPAddr struct &#123;    IP IP    Port int    Zone string // IPv6 scoped addressing zone&#125;</code></pre><p>可以使用<code>ResolveTCPAddr</code>获取一个<code>TCPAddr</code></p><pre><code class="go">func ResolveTCPAddr(net, addr string) (*TCPAddr, os.Error)</code></pre><h4 id="常用的控制TCP连接相关函数"><a href="#常用的控制TCP连接相关函数" class="headerlink" title="常用的控制TCP连接相关函数"></a>常用的控制TCP连接相关函数</h4><ul><li><p><code>func DialTimeout(net, addr string, timeout time.Duration) (Conn, error)</code><br>设置连接超时，客户端和服务端都适用，超过设置时间返回连接失败</p></li><li><p><code>func (c *TCPConn) SetReadDeadline(t time.Time) error</code><br><code>func (c *TCPConn) SetWriteDeadline(t time.Time) error</code><br>设置读写超时</p></li><li><p><code>func (c *TCPConn) SetKeepAlive(keepalive bool) os.Error</code><br>设置keepAlive属性。操作系统层在tcp上没有数据和ACK的时候，会间隔性的发送keepalive包，操作系统可以通过该包来判断一个tcp连接是否已经断开，在windows上默认2个小时没有收到数据和keepalive包的时候认为tcp连接已经断开，这个功能和我们通常在应用层加的心跳包的功能类似。</p></li></ul><h4 id="TCP-Server"><a href="#TCP-Server" class="headerlink" title="TCP Server"></a>TCP Server</h4><p>服务端要做的事如下：</p><ol><li>监听一个地址端口</li><li>调用accept（阻塞）等待连接</li><li>当请求到来时接受请求并读写数据</li><li>数据交互完成后关闭连接</li></ol><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><p>根据客户端发送的数据来返回不同格式的当前时间，使用goroutine支持并发请求。<br>server.go</p><pre><code class="go">package mainimport (    &quot;fmt&quot;    &quot;log&quot;    &quot;net&quot;    &quot;os&quot;    &quot;strconv&quot;    &quot;strings&quot;    &quot;time&quot;)func main() &#123;    service := &quot;localhost:7777&quot;    tcp_addr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, service)    checkError(err)    // 监听本地7777端口    listener, err := net.ListenTCP(&quot;tcp&quot;, tcp_addr)    checkError(err)    for &#123;        log.Println(&quot;[server] listening&quot;, tcp_addr.String())        // 等待客户端连接        conn, err := listener.Accept()        if err != nil &#123;            continue        &#125;        go handleDatetime(conn)    &#125;&#125;// 事件处理func handleDatetime(conn net.Conn)  &#123;    // 设置读超时    conn.SetReadDeadline(time.Now().Add(10 * time.Second))    defer conn.Close()    for &#123;        buffer := make([]byte, 128)        read_len, err := conn.Read(buffer)        if err != nil &#123;            fmt.Println(err)            break        &#125;        // 根据读到的数据返回对应的时间格式        if read_len == 0 &#123;            break        &#125; else if strings.TrimSpace(string(buffer[:read_len])) == &quot;timestamp&quot; &#123;            daytime := strconv.FormatInt(time.Now().Unix(), 10)            conn.Write([]byte(daytime))        &#125; else &#123;            daytime := time.Now().String()            conn.Write([]byte(daytime))        &#125;        log.Println(&quot;[server] response to:&quot;, conn.RemoteAddr().String())    &#125;&#125;func checkError(err error) &#123;    if err != nil &#123;        fmt.Fprintf(os.Stderr, &quot;Fatal error: %s&quot;, err.Error())        os.Exit(1)    &#125;&#125;</code></pre><p>运行结果如下：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-e08a5bf26d08e2c3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-e08a5bf26d08e2c3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="server.png"></p><h4 id="TCP-Client"><a href="#TCP-Client" class="headerlink" title="TCP Client"></a>TCP Client</h4><p>客户端要做的事如下：</p><ol><li>向服务端发起连接请求</li><li>发送数据到服务端，接收来自服务端的响应数据</li><li>数据交互完成后关闭连接</li></ol><h5 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h5><p>client.go</p><pre><code class="go">package mainimport (    &quot;flag&quot;    &quot;fmt&quot;    &quot;net&quot;    &quot;os&quot;)func main() &#123;    service := flag.String(&quot;host&quot;, &quot;127.0.0.1:7777&quot;, &quot;an ip address&quot;)    flag.Usage = func() &#123;        fmt.Fprintf(os.Stdout, &quot;Usage of %s:\n&quot;, &quot;mock http request&quot;)        flag.PrintDefaults()    &#125;    flag.Parse()    tcp_addr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, *service)    checkError(err)    // 发起连接请求    conn, err := net.DialTCP(&quot;tcp&quot;, nil, tcp_addr)    checkError(err)    // 读写数据    _, err = conn.Write([]byte(&quot;timestamp\\r\\n&quot;))    checkError(err)    buffer := make([]byte, 256)    _, err = conn.Read(buffer)    checkError(err)    fmt.Println(&quot;[client] receive from:&quot;, conn.RemoteAddr().String())    fmt.Println(string(buffer))        // 关闭连接    conn.Close()    os.Exit(0)&#125;func checkError(err error) &#123;    if err != nil &#123;        fmt.Fprintf(os.Stderr, &quot;Fatal error: %s&quot;, err.Error())        os.Exit(1)    &#125;&#125;</code></pre><p>在服务端运行的前提下，运行客户端后结果如下：<br>客户端：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-6eeaa68e245bb6d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-6eeaa68e245bb6d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="client.png"></p><p>服务端：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-72e43bfb22b5a3ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-72e43bfb22b5a3ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="server.png"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>【1】<a href="https://github.com/astaxie"><strong>GitHub&#x2F;astaxie</strong></a>&#x2F;<a href="https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/08.1.md">build-web-application-with-golang-8.1 Socket编程</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Socket如何通信&quot;&gt;&lt;a href=&quot;#Socket如何通信&quot; class=&quot;headerlink&quot; title=&quot;Socket如何通信&quot;&gt;&lt;/a&gt;Socket如何通信&lt;/h2&gt;&lt;p&gt;在网络中要唯一确定一个进程需要用一个三元组（Protocol，IP，Port</summary>
      
    
    
    
    <category term="Golang" scheme="https://harryzhang.cn/categories/Golang/"/>
    
    
    <category term="Socket" scheme="https://harryzhang.cn/tags/Socket/"/>
    
    <category term="Go" scheme="https://harryzhang.cn/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>一致性哈希算法原理</title>
    <link href="https://harryzhang.cn/2023/03/25/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"/>
    <id>https://harryzhang.cn/2023/03/25/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/</id>
    <published>2023-03-25T07:25:04.000Z</published>
    <updated>2023-03-25T07:32:08.770Z</updated>
    
    <content type="html"><![CDATA[<h2 id="传统哈希算法的局限性"><a href="#传统哈希算法的局限性" class="headerlink" title="传统哈希算法的局限性"></a>传统哈希算法的局限性</h2><p>在分布式系统中，通常使用多个节点来保存数据，以提高并发能力和容量，那么如果决定数据保存到哪个节点上呢？一般的做法是通过一个哈希函数对数据key进行计算，然后对节点数量取模，从而得到数据分配的节点：<br><code>node_id = hash(key) % N</code><br>但是这种做法在节点数量N变化的时候，大部分key的计算的节点都会重新分配。如果是应用在分布式缓存，就会导致大规模的缓存失效，引起缓存雪崩。</p><h2 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>一致性哈希算法将哈希空间分配到哈希环的数据结构上，取值范围0~2^32-1，并且起点与终点相连。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-3d4ac4aed2d0295d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-3d4ac4aed2d0295d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ol><li>将服务器通过哈希函数（以IP或者主机名作为key）放置到环上</li><li>对数据key使用相同的哈希函数，落到哈希空间上的某个点，如果该点不是服务器节点的位置，则顺时针向前寻找，直到碰到第一个服务器节点，将数据分配到该节点。</li></ol><h4 id="新增节点"><a href="#新增节点" class="headerlink" title="新增节点"></a>新增节点</h4><p><img src="https://upload-images.jianshu.io/upload_images/14151453-889a824feb485b6c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-889a824feb485b6c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>新增了节点S4，那么影响的只是哈希空间S3到S4之间的数据，如原来key4是分配到节点S1，现在分配到了S4。</p><h4 id="下线节点"><a href="#下线节点" class="headerlink" title="下线节点"></a>下线节点</h4><p><img src="https://upload-images.jianshu.io/upload_images/14151453-de338ef1527c2666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-de338ef1527c2666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>节点S2下线，只影响哈希空间S1到S2之间的数据，如原来key2分配到了S2，现在分配到了S3。</p><h3 id="虚拟节点优化"><a href="#虚拟节点优化" class="headerlink" title="虚拟节点优化"></a>虚拟节点优化</h3><p>当服务节点比较少的时候会出现分配不平衡的问题，造成大量数据集中到一个节点上，如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-9197f7ebe16f828a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-9197f7ebe16f828a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>大部分的哈希空间都会分配到S1上，少量分配到S2上。<br>为了解决这种数据倾斜问题，一致性哈希引入了虚拟节点机制：对每一个服务器节点计算多个哈希，每个计算结果都防止一个此服务器对应的虚拟节点。具体做法可以在服务器IP后面加上编号再计算哈希值。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-01a834f729aa04c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-01a834f729aa04c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>如上图所示，对S1和S2分别虚拟出两个节点，形成四个虚拟节点，数据分配方式不变，不过多了先顺时针找到服务器的虚拟节点，再映射到对应的物理服务器节点。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>良好的伸缩性。一致性哈希算法保证了增加或减少服务器时，数据存储的改变最少，比传统的哈希算法大大节省了数据移动的开销。</li><li>更好的适应数据增长。当数据不断增长，部分虚拟节点可能包含很多数据，造成数据分配不平衡，此时可以将包含数据多的虚拟节点分裂，这种分裂仅仅是将原有的虚拟节点一分为二，不需要对全部数据重新哈希划分。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】 <a href="https://segmentfault.com/a/1190000021199728">图解一致性哈希算法</a><br>【2】<a href="https://zhuanlan.zhihu.com/p/98030096">一致性Hash算法详解</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;传统哈希算法的局限性&quot;&gt;&lt;a href=&quot;#传统哈希算法的局限性&quot; class=&quot;headerlink&quot; title=&quot;传统哈希算法的局限性&quot;&gt;&lt;/a&gt;传统哈希算法的局限性&lt;/h2&gt;&lt;p&gt;在分布式系统中，通常使用多个节点来保存数据，以提高并发能力和容量，那么如果决</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="一致性哈希" scheme="https://harryzhang.cn/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"/>
    
  </entry>
  
  <entry>
    <title>数据库和缓存数据一致性问题如何解决?</title>
    <link href="https://harryzhang.cn/2023/03/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/"/>
    <id>https://harryzhang.cn/2023/03/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/</id>
    <published>2023-03-25T07:24:43.000Z</published>
    <updated>2023-03-25T07:31:36.643Z</updated>
    
    <content type="html"><![CDATA[<p>业务使用Redis做缓存，当有数据更新时，如何保证缓存及时更新</p><h2 id="读数据流程"><a href="#读数据流程" class="headerlink" title="读数据流程"></a>读数据流程</h2><p>请求到来，业务代码会先查Redis，查不到再去查DB，并将结果写入Redis</p><h2 id="写数据方案"><a href="#写数据方案" class="headerlink" title="写数据方案"></a>写数据方案</h2><h3 id="1-先删除缓存，再更新DB"><a href="#1-先删除缓存，再更新DB" class="headerlink" title="1. 先删除缓存，再更新DB"></a>1. 先删除缓存，再更新DB</h3><h4 id="可行性"><a href="#可行性" class="headerlink" title="可行性"></a>可行性</h4><p>先删除缓存，再更新DB，下次读请求到来会从数据库查到新的数据更新到缓存中。如果先更新缓存，在更新DB，更新DB失败会导致数据不一致。</p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><h5 id="容灾不足"><a href="#容灾不足" class="headerlink" title="容灾不足"></a>容灾不足</h5><p>如果删除缓存失败的情况，如果业务继续进行，更新DB，那么在缓存过期之前仍然查到的是旧数据。如果业务返回失败，则对Redis变成了强依赖。</p><h5 id="并发不安全"><a href="#并发不安全" class="headerlink" title="并发不安全"></a>并发不安全</h5><p>考虑如下场景：</p><ol><li>A请求删除缓存，A请求更新DB</li><li>B请求查询缓存，不存在</li><li>B请求查询DB，查到旧数据（更新未完成），写入缓存</li><li>A请求更新DB完成</li></ol><p>这就导致缓存中仍存的旧数据，数据不一致。</p><h3 id="2-先更新DB，再删除缓存"><a href="#2-先更新DB，再删除缓存" class="headerlink" title="2. 先更新DB，再删除缓存"></a>2. 先更新DB，再删除缓存</h3><p>这种策略解决了方法1中的并发问题，但是还是有极小可能存在并发问题，考虑如下情况：</p><ol><li>请求A查询缓存，缓存刚好失效</li><li>请求A查询DB，得到一个旧值</li><li>请求B更新数据库</li><li>请求B删除缓存</li><li>请求A将查到的旧值写入缓存</li></ol><p>这种情况确实会产生数据不一致，但是考虑到DB的读操作总是比写操作快的多，这种场景基本不可能出现。</p><h4 id="如何杜绝并发问题"><a href="#如何杜绝并发问题" class="headerlink" title="如何杜绝并发问题"></a>如何杜绝并发问题</h4><p>延迟异步删，保证读操作完成后再删除缓存。</p><h4 id="如何容灾"><a href="#如何容灾" class="headerlink" title="如何容灾"></a>如何容灾</h4><p>上述方案中如果删除缓存失败了怎么办？</p><h5 id="引入消息队列"><a href="#引入消息队列" class="headerlink" title="引入消息队列"></a>引入消息队列</h5><ol><li>更新DB</li><li>删除缓存，如果失败将要删除的key发送至消息队列</li><li>消费消息，获得需要删除的key，删除key缓存直到成功</li></ol><h5 id="订阅binlog"><a href="#订阅binlog" class="headerlink" title="订阅binlog"></a>订阅binlog</h5><p>上述方法对业务代码的侵入性比较大，为此可以启动一个程序订阅MySQL的binlog用来发现数据更新，流程如下：</p><ol><li>业务代码更新数据库，MySQL将更新操作写入binlog</li><li>订阅程序提取中更新的数据以及key，尝试删除key的缓存</li><li>如果删除缓存失败，将key发送至消息队列</li><li>消费者程序从消息队列中获取待删除的key，重试删除直到成功。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://zhuanlan.zhihu.com/p/59167071">Redis与Mysql双写一致性方案解析</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;业务使用Redis做缓存，当有数据更新时，如何保证缓存及时更新&lt;/p&gt;
&lt;h2 id=&quot;读数据流程&quot;&gt;&lt;a href=&quot;#读数据流程&quot; class=&quot;headerlink&quot; title=&quot;读数据流程&quot;&gt;&lt;/a&gt;读数据流程&lt;/h2&gt;&lt;p&gt;请求到来，业务代码会先查Redis，查</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="一致性" scheme="https://harryzhang.cn/tags/%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
    <category term="Cache-Aside" scheme="https://harryzhang.cn/tags/Cache-Aside/"/>
    
  </entry>
  
  <entry>
    <title>限流算法有哪些?</title>
    <link href="https://harryzhang.cn/2023/03/25/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B/"/>
    <id>https://harryzhang.cn/2023/03/25/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B/</id>
    <published>2023-03-25T07:24:13.000Z</published>
    <updated>2023-03-25T07:30:08.084Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么要限流？"><a href="#为什么要限流？" class="headerlink" title="为什么要限流？"></a>为什么要限流？</h2><p>由于Web服务无法控制调用方的行为，当遇到请求并发量超过系统的容量阈值，会导致服务器资源耗尽从而导致服务异常或宕机，而且某个服务的请求量突增还会影响到上游的服务，如DB或者是其他的公共服务，导致整个系统瘫痪。<br>可能导致流量突增的原因有以下几点：</p><ul><li>热点业务的突发请求（如大型活动）</li><li>调用方bug导致的请求量倍增</li><li>恶意攻击的请求</li></ul><p>为了对服务进行保护，就需要对请求进行限流。</p><h2 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h2><h3 id="固定窗口计数器算法"><a href="#固定窗口计数器算法" class="headerlink" title="固定窗口计数器算法"></a>固定窗口计数器算法</h3><p><img src="https://upload-images.jianshu.io/upload_images/14151453-eb82b484202a6797.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-eb82b484202a6797.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br><strong>算法思路</strong>：</p><ul><li>将时间划分为多个窗口</li><li>每个窗口内每有一次请求计数器加1</li><li>如果计数器超过了限制数量，则本窗口内的所有请求都被丢弃，当时间到达下一个窗口时，计数器重置。</li></ul><p><strong>特点</strong>：原理和实现都比较简单，但是这种算法可能会让通过的请求量为阈值的两倍。比如当阈值是100时，第一个窗口在0-0.5秒期间没有请求，0.5-1.0秒期间有100个请求，然后到了第二个窗口计数器已经重置，在1.0-1.5秒期间有100个请求，这样看来在0.5-1.5秒的1秒内通过了200个请求。</p><h3 id="滑动窗口计数器算法"><a href="#滑动窗口计数器算法" class="headerlink" title="滑动窗口计数器算法"></a>滑动窗口计数器算法</h3><p>该方法就是对固定窗口计数算法的窗口时间细分更多的区间，并且按照时间在区间上滑动，如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-6ffb47a5808a8296.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-6ffb47a5808a8296.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br><strong>算法思路</strong>：</p><ul><li>将时间划分多个区间，维护一个包含多个区间的窗口</li><li>每个区间内每有一次请求就将该区间的计数器加1</li><li>每经过一个区间时间，丢弃最老的一个区间，加入最新的一个区间</li><li>如果当前窗口内区间的请求计数总和超过了限制数量则本窗口内所有新的请求都被丢弃。</li></ul><p><strong>特点</strong>：<br>将时间划分为更小单位的区间，按时间滑动，避免了固定窗口计数器会产生双倍请求的问题，但是时间区间的精度越高，算法需要的空间容量就越大。</p><h3 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h3><p><img src="https://upload-images.jianshu.io/upload_images/14151453-c5fa82d0ce096327.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-c5fa82d0ce096327.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong>算法思路</strong>：</p><ul><li>将每个请求视作“水滴”放入“漏桶”进行存储</li><li>漏桶以固定的速率（通常是服务的最大容量）向外漏出请求交给服务器执行</li><li>如果漏桶空了则停止漏水，如果漏桶满了则丢弃新来的请求</li></ul><p><strong>特点</strong>：通常使用消息队列来实现漏桶。该算法能良好的保证瞬时请求量不会超过阈值，但是当短时间内有大量的突发请求时，即使服务器没有负载，每个请求也都需要在队列中等待一段时间才能被响应。</p><h3 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h3><p><img src="https://upload-images.jianshu.io/upload_images/14151453-943e3e218fb56c62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-943e3e218fb56c62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br><strong>算法思路</strong>：</p><ul><li>令牌以固定速录添加到桶中，如果桶满了直接丢弃</li><li>请求到达时从桶中取令牌，取到了令牌的请求交给服务器执行</li><li>如果桶空了，尝试取令牌的请求就会被拒绝</li></ul><p><strong>特点</strong>：令牌桶算法既能将流量均匀的分布，又能接受服务器承受的容量范围内的突发请求，因此是目前使用比较广泛的一种限流算法。缺点是突发流量时第一个周期会多放过一些请求。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://www.infoq.cn/article/qg2tx8fyw5vt-f3hh673">InfoQ：分布式服务限流实战，已经为你排好坑了</a><br>【2】<a href="https://help.aliyun.com/document_detail/149952.html">阿里云：限流算法介绍</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;为什么要限流？&quot;&gt;&lt;a href=&quot;#为什么要限流？&quot; class=&quot;headerlink&quot; title=&quot;为什么要限流？&quot;&gt;&lt;/a&gt;为什么要限流？&lt;/h2&gt;&lt;p&gt;由于Web服务无法控制调用方的行为，当遇到请求并发量超过系统的容量阈值，会导致服务器资源耗尽从而导致</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="限流" scheme="https://harryzhang.cn/tags/%E9%99%90%E6%B5%81/"/>
    
    <category term="漏桶" scheme="https://harryzhang.cn/tags/%E6%BC%8F%E6%A1%B6/"/>
    
    <category term="令牌桶" scheme="https://harryzhang.cn/tags/%E4%BB%A4%E7%89%8C%E6%A1%B6/"/>
    
  </entry>
  
  <entry>
    <title>分布式全局唯一 ID 生成方案有哪些？</title>
    <link href="https://harryzhang.cn/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80-ID-%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F/"/>
    <id>https://harryzhang.cn/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80-ID-%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F/</id>
    <published>2023-03-25T07:23:45.000Z</published>
    <updated>2023-03-25T07:29:23.961Z</updated>
    
    <content type="html"><![CDATA[<h2 id="全局唯一ID要求"><a href="#全局唯一ID要求" class="headerlink" title="全局唯一ID要求"></a>全局唯一ID要求</h2><p>分布式系统中，我们会对一些数据量大的业务进行拆分，如用户表、订单表，当数据量巨大导致数据库性能下降时，通常会进行分库分表，无法利用MySQL的自增ID，那么就需要一个单独的系统来生成全局唯一ID，而且生成的ID要求具有以下特性：</p><ul><li>整个系统全局唯一</li><li>ID趋势递增，提高数据库插入的效率（索引是递增的，避免乱序插入提高索引的维护成本）</li><li>ID简单，占用空间小，查询效率高</li></ul><h2 id="常见方案"><a href="#常见方案" class="headerlink" title="常见方案"></a>常见方案</h2><h3 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h3><p>全局唯一首先可以想到使用UUID，基本各种语言都提供了UUID的库</p><h5 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h5><ul><li>代码实现简单</li><li>本地生成，没有性能问题</li><li>全球唯一的，数据迁移容易</li></ul><h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><ul><li>每次生成的ID是无序的，不满足趋势递增</li><li>UUID是字符串，而且比较长，占用空间大，查询效率低</li><li>ID没有含义，可读性差</li></ul><h3 id="MySQL自增主键"><a href="#MySQL自增主键" class="headerlink" title="MySQL自增主键"></a>MySQL自增主键</h3><p>单表可以使用MySQL的自增ID，多表的情况下其实也可以使用自增ID，只是和单表每次+1不同，分多表的情况下每次需要加N，具体如下图：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-2a5d07950848c303.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-2a5d07950848c303.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>上图中共分成了两个库4个表，那么每个表初始值一次为1~4，之后每次自增时+4，这样保证了每个表的ID不会重复，而且是趋势递增的，解决了单表的问题。</p><h4 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h4><p>一旦步长定好就无法扩容，数据库单机能力有限，不易于横向扩展</p><h3 id="雪花snowflake方案"><a href="#雪花snowflake方案" class="headerlink" title="雪花snowflake方案"></a>雪花snowflake方案</h3><p>雪花算法生成64位二进制正整数，然后转换为10进制的数，具体方案如下图：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-73e41ba1afcd26c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-73e41ba1afcd26c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>最高的一个bit不用，接下来的41个bit表示微秒级的时间（表示范围约69年），再接下来的10个bit机器编号可以分别表示1024台机器，如果对IDC划分，可以将10-bit的高几位表示IDC，最低位的12个字节是一个自增序列，表示范围为2^12&#x3D;4096个，理论上这种方案每秒可以生成的唯一ID数约为4096*1000&#x3D;409.6w个。</p><h4 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a>优点：</h4><ul><li>整个ID满足趋势递增</li><li>不依赖第三方系统，稳定性和性能都比较高</li><li>可以根据自身业务分配bit位，比较灵活</li></ul><h4 id="缺点：-2"><a href="#缺点：-2" class="headerlink" title="缺点："></a>缺点：</h4><ul><li>强依赖系统时钟，如果系统时钟回拨，会导致ID重复或者服务不可用</li></ul><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>利用Redis的incr原子性操作<br><img src="https://upload-images.jianshu.io/upload_images/14151453-00f8962cc2a1ee14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-00f8962cc2a1ee14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>一般方案为年份+月份+小时+Redis自增。</p><h4 id="优点：-2"><a href="#优点：-2" class="headerlink" title="优点："></a>优点：</h4><ul><li>有序递增，可读性强</li><li>性能较高</li></ul><h4 id="缺点：-3"><a href="#缺点：-3" class="headerlink" title="缺点："></a>缺点：</h4><ul><li>占用带宽，依赖Redis</li></ul><h2 id="更优的方案"><a href="#更优的方案" class="headerlink" title="更优的方案"></a>更优的方案</h2><h3 id="美团的Leaf-segment方案"><a href="#美团的Leaf-segment方案" class="headerlink" title="美团的Leaf-segment方案"></a>美团的Leaf-segment方案</h3><p>在之前的数据方案中，利用自增id每次从数据库只取了一个id，由于数据库的IO能力有限，不能支持高并发的场景，那么如果一次取一批id，消耗完再取一批，是不是就可以提高并发能力了？具体的方案架构如下：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-4747be83c08046d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-4747be83c08046d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>抽象出Proxy Server，用于从数据库批量获取，然后在Leaf内部中逐个消耗分发给用户服务。<br>如图中的数据库表结构：biz_tag用来区分业务，业务之间的id号相互隔离互不影响，每次从数据库取出step个id号，将数据操作次数减少到了1&#x2F;step。<br>对于多个Leaf抢占数据库可以利用MySQL的事务和锁机制，先更新再查询，保证多个Leaf请求的id范围不会重复复。</p><pre><code class="sql">BeginUPDATE table SET max_id=max_id+step WHERE biz_tag=xxxSELECT tag, max_id, step FROM table WHERE biz_tag=xxxCommit</code></pre><p>这样返回给业务服务的ID范围应该是[max_id-step+1, max_id]</p><h4 id="优点：-3"><a href="#优点：-3" class="headerlink" title="优点："></a>优点：</h4><ul><li>Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景</li><li>ID是趋势递增的64位数字</li><li>高可用：Leaf内部可以使用缓存，即使数据宕机短时间服务仍可用</li><li>可以自定义max_id和step，便于业务迁移</li></ul><h4 id="缺点：-4"><a href="#缺点：-4" class="headerlink" title="缺点："></a>缺点：</h4><ul><li>ID号码不够随机，可能导致发号数量的信息</li><li>TP999数据波动大，当多个Leaf同时消耗完后，还是会阻塞在数据库更新上，业务可能会出现偶尔的时延毛刺</li><li>强依赖DB，DB宕机会导致系统不可用</li></ul><h4 id="双buffer优化"><a href="#双buffer优化" class="headerlink" title="双buffer优化"></a>双buffer优化</h4><p>对于第一个缺点，由于是这个方案设计上的问题不能优化了，但对于第二个缺点，可以作进一步的优化，具体思路如下：<br>之前的方案Leaf从数据库取号段是在号段消耗完的时候进行的，这导致了需要等待从DB取回号段的时间才能返回下一个ID号码，而数据库的操作是比较耗时的，导致Leaf服务阻塞，该次请求时延会突增。<br>为了解决这个问题，希望两次取号段能尽量做到无缝衔接，那么在号段消耗到某个点（比如100&#x2F;1000）的时候异步的就请求DB取下一个号段然后保存在内存中，而不是等到号段用完再同步请求DB，这样就可以很大程度减少因为DB阻塞带来的业务抖动，具体实现如下图：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-bad0803983eb9b35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-bad0803983eb9b35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>Leaf服务内部采用两个segment buffer，当前号段已下发10%时，如果下一个号段未更新，则启动线程去更新下个号段，这样当buffer1消耗完时buffer2很可能已经更新好了，只需要直接切换当前segment到segment buffer2，然后就可以继续发放号码。两个buffer交替工作，平滑DB带来的I&#x2F;O阻塞。</p><h4 id="数据库高可用容灾"><a href="#数据库高可用容灾" class="headerlink" title="数据库高可用容灾"></a>数据库高可用容灾</h4><p>对于第三个缺点强依赖DB的问题，需要DB高可用，可以采用一主两从的方式，分机房部署（常见的架构有“同城三机房”、“两城三中心”），Master和Slave采用半同步复制同步数据，保证至少有两个节点数据一致且不丢失，同时可以接入中间件来实现主从切换。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://blog.csdn.net/zl1zl2zl3/article/details/89509445">一线大厂的分布式唯一ID生成方案是什么样的？</a><br>【2】<a href="https://tech.meituan.com/2017/04/21/mt-leaf.html">Leaf——美团点评分布式ID生成系统</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;全局唯一ID要求&quot;&gt;&lt;a href=&quot;#全局唯一ID要求&quot; class=&quot;headerlink&quot; title=&quot;全局唯一ID要求&quot;&gt;&lt;/a&gt;全局唯一ID要求&lt;/h2&gt;&lt;p&gt;分布式系统中，我们会对一些数据量大的业务进行拆分，如用户表、订单表，当数据量巨大导致数据库性</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="唯一ID" scheme="https://harryzhang.cn/tags/%E5%94%AF%E4%B8%80ID/"/>
    
    <category term="snowflake" scheme="https://harryzhang.cn/tags/snowflake/"/>
    
    <category term="leaf" scheme="https://harryzhang.cn/tags/leaf/"/>
    
  </entry>
  
  <entry>
    <title>从五个问题出发认识消息队列</title>
    <link href="https://harryzhang.cn/2023/03/25/%E4%BB%8E%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E5%87%BA%E5%8F%91%E8%AE%A4%E8%AF%86%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>https://harryzhang.cn/2023/03/25/%E4%BB%8E%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E5%87%BA%E5%8F%91%E8%AE%A4%E8%AF%86%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</id>
    <published>2023-03-25T07:23:17.000Z</published>
    <updated>2023-03-25T07:28:04.198Z</updated>
    
    <content type="html"><![CDATA[<h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><p>消息队列是分布式系统的一个重要组件，从五个问题来初步认识一下消息队列，基本原理是什么样的，如何正确的使用消息队列。</p><ul><li>Q1: 为什么需要消息队列？</li><li>Q2: 如何保证消息不丢失？</li><li>Q3: 如何处理重复消息？</li><li>Q4: 如何保证消息有序性？</li><li>Q5: 如何处理消息堆积？</li></ul><h2 id="为什么需要"><a href="#为什么需要" class="headerlink" title="为什么需要"></a>为什么需要</h2><h3 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h3><ul><li>随着业务的增长，业务逻辑会不断加重，为了保持较快速的响应，可以在核心逻辑处理完后就返回，其他逻辑放到消息队列之后异步处理</li></ul><h3 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h3><ul><li>业务模块增加，可以通过订阅核心服务的消息主题，不影响核心服务</li></ul><h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><ul><li>后端服务无法支撑大量的并发请求，请求先放到队列，后端服务尽最大的能力消费队列</li></ul><h3 id="日志处理"><a href="#日志处理" class="headerlink" title="日志处理"></a>日志处理</h3><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul><li><p>点对点（队列）模型</p><ul><li><p>同一个消息只能由一个消费者消费一次</p><ul><li>Rabbit MQ</li></ul></li></ul></li><li><p>发布&#x2F;订阅模型</p><ul><li><p>订阅了某个主题的所有消费者都可以消费该主题的消息</p><ul><li>Rocket MQ、Kafka</li></ul></li></ul></li></ul><h3 id="各个组件术语（Kafka）"><a href="#各个组件术语（Kafka）" class="headerlink" title="各个组件术语（Kafka）"></a>各个组件术语（Kafka）</h3><ul><li><p>生产者（Producer）</p></li><li><p>消息队列服务器（Broker）</p><ul><li><p>主服务器（Leader）</p></li><li><p>从服务器（Follower）</p></li><li><p>主题（Topic）</p><ul><li>分区（Partition）</li></ul></li></ul></li><li><p>消费者组（Consumer Group）</p><ul><li>消费者（Consumer）</li></ul></li></ul><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ul><li><p>生产消息（发送数据）</p><ul><li><ol><li>从Kafka Cluster获取分区的Leader，Producer将消息发送给Leader</li></ol></li><li><ol start="2"><li>Leader将消息写入本地文件（此时可以直接到步骤3）</li></ol><ul><li>2.1. Followers从Leader pull消息并写入本地后向Leader发送ACK确认</li></ul></li><li><ol start="3"><li>Leader向Producer响应ACK</li></ol></li></ul></li><li><p>存储数据</p><ul><li><p>单独开辟一块磁盘，顺序写入</p></li><li><p>每个分区相当于一个文件目录</p><ul><li><p>Partition&#x2F;Segment</p><ul><li>.index</li><li>.log</li><li>.timeindex</li></ul></li></ul></li></ul></li><li><p>消费消息（接收数据）</p><ul><li><ol><li>Consumer也是从Leader中拉取数据</li></ol></li><li><ol start="2"><li>一个消费者组内的某个消费者可以消费一个Topic的不同分区，单同一个组内的不同消费者不能同时消费某个Topic的同一个分区，一个组的消费者数量最好和分区数相同</li></ol></li></ul></li></ul><h3 id="分区的好处"><a href="#分区的好处" class="headerlink" title="分区的好处"></a>分区的好处</h3><ul><li>方便扩展</li><li>提高并发</li></ul><h2 id="实际问题"><a href="#实际问题" class="headerlink" title="实际问题"></a>实际问题</h2><h3 id="如何保证消息队列不丢失？"><a href="#如何保证消息队列不丢失？" class="headerlink" title="如何保证消息队列不丢失？"></a>如何保证消息队列不丢失？</h3><ul><li><ol><li>生产消息阶段</li></ol><ul><li>正确处理Broker的响应，做重试机制</li></ul></li><li><ol start="2"><li>数据存储阶段</li></ol><ul><li>数据落盘再响应成功，有多个副本时可以等多副本都落盘再响应成功</li></ul></li><li><ol start="3"><li>消费消息阶段</li></ol><ul><li>业务逻辑处理完再确认消息</li></ul></li><li><p>确保了可靠性的同时会影响性能，根据业务选择合适的方式</p></li></ul><h3 id="如何处理重复消息？"><a href="#如何处理重复消息？" class="headerlink" title="如何处理重复消息？"></a>如何处理重复消息？</h3><ul><li><p>为了保证消息不丢失，消息重复是不可避免的</p></li><li><p>业务逻辑幂等性</p><ul><li>增加version版本号做控制</li><li>数据库唯一索引</li></ul></li></ul><h3 id="如何保证消息有序？"><a href="#如何保证消息有序？" class="headerlink" title="如何保证消息有序？"></a>如何保证消息有序？</h3><ul><li><p>全局有序</p><ul><li>一个生产者、一个分区、一个消费者</li></ul></li><li><p>部分有序</p><ul><li>消息按特定规则分配到不同的分区，分区本身是有序的，每个分区由一个消费者消费</li></ul></li></ul><h3 id="如何处理消息堆积？"><a href="#如何处理消息堆积？" class="headerlink" title="如何处理消息堆积？"></a>如何处理消息堆积？</h3><ul><li><ol><li>定位问题，如果是bug引起，修改bug（实际生产场景如果由于发版导致，先回滚再定位原因）</li></ol></li><li><ol start="2"><li>如果不是bug，看能不能优化消费逻辑</li></ol></li><li><ol start="3"><li>如果不能优化，就要横向扩容，同时增加分区数和消费者数量</li></ol></li></ul><p><a href="https://mp.weixin.qq.com/s/u6_WH-r1bRc4m7CUm21Tew">参考文章1 微信公众号文章</a><br><a href="https://zhuanlan.zhihu.com/p/68052232">参考文章2 知乎</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;消息队列&quot;&gt;&lt;a href=&quot;#消息队列&quot; class=&quot;headerlink&quot; title=&quot;消息队列&quot;&gt;&lt;/a&gt;消息队列&lt;/h1&gt;&lt;p&gt;消息队列是分布式系统的一个重要组件，从五个问题来初步认识一下消息队列，基本原理是什么样的，如何正确的使用消息队列。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="消息队列" scheme="https://harryzhang.cn/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="MQ" scheme="https://harryzhang.cn/tags/MQ/"/>
    
    <category term="RabbitMQ" scheme="https://harryzhang.cn/tags/RabbitMQ/"/>
    
    <category term="RocketMQ" scheme="https://harryzhang.cn/tags/RocketMQ/"/>
    
    <category term="Kafka" scheme="https://harryzhang.cn/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>无处不在的微服务</title>
    <link href="https://harryzhang.cn/2023/03/25/%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    <id>https://harryzhang.cn/2023/03/25/%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1/</id>
    <published>2023-03-25T07:23:00.000Z</published>
    <updated>2023-03-25T07:35:40.565Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><ul><li>微服务就是一些协同工作的小而自治的服务</li></ul><h3 id="服务注册与发现"><a href="#服务注册与发现" class="headerlink" title="服务注册与发现"></a>服务注册与发现</h3><ul><li>微服务之间互相调用，服务发现需要管理各个服务的服务器地址，当进行扩容或摘除时能及时更新</li></ul><h3 id="服务监控"><a href="#服务监控" class="headerlink" title="服务监控"></a>服务监控</h3><ul><li>监控、日志、调用链、告警通知、健康检查</li></ul><h3 id="服务容错"><a href="#服务容错" class="headerlink" title="服务容错"></a>服务容错</h3><ul><li>熔断</li><li>切换</li><li>限流和降级</li><li>重试</li></ul><h3 id="服务安全"><a href="#服务安全" class="headerlink" title="服务安全"></a>服务安全</h3><ul><li><p>敏感服务进行身份验证和授权</p><ul><li>HTTPS传输</li><li>隐私数据加密存储</li></ul></li></ul><h3 id="服务治理"><a href="#服务治理" class="headerlink" title="服务治理"></a>服务治理</h3><ul><li>引入微服务框架</li></ul><h2 id="相比单体架构"><a href="#相比单体架构" class="headerlink" title="相比单体架构"></a>相比单体架构</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li><p>技术异构性</p><ul><li>不同服务内部可以选择不同的语言开发，也可以选择适合各自服务的数据库（MySQL、Redis）</li></ul></li><li><p>隔离性</p><ul><li>一个服务不可用不会导致整个系统或其他服务不可用，各个服务相互独立的</li></ul></li><li><p>可扩展性</p><ul><li>可以只对影响性能的瓶颈资源进行扩展升级</li></ul></li><li><p>简化部署</p><ul><li>单个服务的修改迭代只需要发步自己的改动</li></ul></li><li><p>易优化</p><ul><li>代码量不会很大，重构相对容易且改动带来的影响可控</li></ul></li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>管理复杂</li><li>难定位问题</li></ul><h2 id="微服务框架"><a href="#微服务框架" class="headerlink" title="微服务框架"></a>微服务框架</h2><h3 id="Dubbo"><a href="#Dubbo" class="headerlink" title="Dubbo"></a>Dubbo</h3><ul><li>阿里</li><li>仅支持Java语言</li></ul><h3 id="Tars"><a href="#Tars" class="headerlink" title="Tars"></a>Tars</h3><ul><li>腾讯</li><li>仅支持C++语言</li></ul><h3 id="Motan"><a href="#Motan" class="headerlink" title="Motan"></a>Motan</h3><ul><li>微博</li><li>仅支持Java</li></ul><h3 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h3><ul><li>谷歌</li><li>支持多种语言</li></ul><h3 id="thrift"><a href="#thrift" class="headerlink" title="thrift"></a>thrift</h3><ul><li>Facebook</li><li>支持多种语言</li></ul><h2 id="微服务框架和RPC"><a href="#微服务框架和RPC" class="headerlink" title="微服务框架和RPC"></a>微服务框架和RPC</h2><h3 id="RPC（Remote-Procedure-Call）"><a href="#RPC（Remote-Procedure-Call）" class="headerlink" title="RPC（Remote Procedure Call）"></a>RPC（Remote Procedure Call）</h3><ul><li>允许像调用本地函数一样调用另一个程序的函数（C&#x2F;S模式）</li></ul><h3 id="微服务框架-1"><a href="#微服务框架-1" class="headerlink" title="微服务框架"></a>微服务框架</h3><ul><li>微服务框架一般都包含了RPC的实现和一系列的服务治理能力，是一套软件开发框架，可以基于这个框架实现自己的服务，方便的利用框架提供的服务治理和RPC能力，微服务框架也被某些人称为RPC框架</li></ul><h2 id="下一代微服务架构"><a href="#下一代微服务架构" class="headerlink" title="下一代微服务架构"></a>下一代微服务架构</h2><h3 id="服务网格（Service-Mesh）"><a href="#服务网格（Service-Mesh）" class="headerlink" title="服务网格（Service Mesh）"></a>服务网格（Service Mesh）</h3><ul><li><p>特点</p><ul><li>应用程序间通讯中间层</li><li>轻量级网络代理</li><li>应用程序无感知</li><li>解耦应用程序的重试&#x2F;超时、监控、追踪和服务发现</li></ul></li><li><p>Service Mesh之于微服务，类似TCP&#x2F;IP之于网络通信</p></li></ul><p><a href="https://www.zhihu.com/question/65502802">【参考资料】知乎：微服务架构是什么？</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h2&gt;&lt;h3 id=&quot;基本定义&quot;&gt;&lt;a href=&quot;#基本定义&quot; class=&quot;headerlink&quot; title=&quot;基本定义&quot;&gt;&lt;/a&gt;基本定义&lt;/h</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="微服务" scheme="https://harryzhang.cn/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="微服务" scheme="https://harryzhang.cn/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统基础知识概述</title>
    <link href="https://harryzhang.cn/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/"/>
    <id>https://harryzhang.cn/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/</id>
    <published>2023-03-25T07:21:46.000Z</published>
    <updated>2023-03-25T07:26:36.365Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><ul><li><p>性能指标</p><ul><li>响应时间</li><li>吞吐量（QPS、TPS）</li><li>并发用户数：不是越高越好，如果系统来不及处理就会阻塞，响应时间会大大提高</li></ul></li><li><p>性能优化</p><ul><li>集群</li><li>缓存（Redis、CDN）</li><li>异步</li></ul></li></ul><h3 id="伸缩性"><a href="#伸缩性" class="headerlink" title="伸缩性"></a>伸缩性</h3><ul><li>扩容</li><li>无状态的应用服务器可以通过负载均衡器想集群中添加新的节点</li><li>关系型数据库可以用过Sharding实现</li><li>非关系型数据库对伸缩性支持很好</li></ul><h3 id="扩展性"><a href="#扩展性" class="headerlink" title="扩展性"></a>扩展性</h3><ul><li>添加新的功能对现有系统的其他应用无影响</li><li>使用消息队列进行解耦</li><li>分布式服务奖业务可复用的部分模块化</li></ul><h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><ul><li>冗余（多点备份，异地双活）</li><li>故障切换</li><li>服务降级</li><li>监控</li></ul><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><ul><li><p>应对各种攻击手段</p><ul><li>SQL注入</li><li>XSS攻击</li></ul></li></ul><h2 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h2><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><ul><li><p>数据库唯一索引</p><ul><li>没有失效时间，解锁失败会造成死锁</li><li>只能是非阻塞，插入失败无法重试</li><li>不可重入，已获得锁的进程也必须重新获取锁</li></ul></li><li><p>Redis的SETNX指令</p><ul><li>节点挂了就不可用，造成死锁</li></ul></li><li><p>RedLock</p><ul><li>高可用</li></ul></li><li><p>Zookeeper的有序节点</p></li></ul><h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><ul><li><p>两阶段提交（2PC）</p><ul><li><p>准备阶段</p><ul><li>协调者询问所有参与者事务执行的结果</li></ul></li><li><p>提交阶段</p><ul><li>协调者根据所有参与者返回的结果判断最终是提交还是回滚</li></ul></li><li><p>存在问题</p><ul><li>同步阻塞</li><li>单点故障</li><li>数据不一致</li></ul></li></ul></li><li><p>本地消息表</p><ul><li>1. 分布式事务操作方完成写业务数据后向本地消息表发送一个消息，确保这个消息一定会写入本地消息表</li><li><ol start="2"><li>之后将本地消息表中的消息转发到消息队列，转发成功则从本地消息表删除，否则继续重发</li></ol></li><li><ol start="3"><li>分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作</li></ol></li></ul></li></ul><h3 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h3><ul><li><p>分布式系统不可能同时满足</p><ul><li>一致性（Consistency）</li><li>分区容忍性（Partition Tolerance）</li><li>可用性（Availability）</li></ul></li><li><p>权衡</p><ul><li>分区容忍性必不可少，可用性和一致性的权衡</li><li>为了保证一致性，不能访问未同步完成的节点，就失去了部分可用性</li><li>为了保证可用性，允许读取所有节点的数据，但是数据可能不一致</li></ul></li></ul><h3 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h3><ul><li><p>概念</p><ul><li><p>基本可用（Basically Available）</p><ul><li>分布式系统在故障的时候保证核心可用，允许损失部分可用性</li></ul></li><li><p>软状态（Soft State）</p><ul><li>允许系统中的数据存在中间状态，并认为该中间状态不会影响整体可用性</li></ul></li><li><p>最终一致性（Eventually Consistent）</p><ul><li>系统中的所有数据副本在经过一段时间的同步后，最终能达到一致性的状态</li></ul></li></ul></li></ul><h3 id="竞选协议"><a href="#竞选协议" class="headerlink" title="竞选协议"></a>竞选协议</h3><ul><li><p>Paxos</p><ul><li><p>执行过程</p><ul><li><ol><li>Prepare</li></ol></li><li><ol start="2"><li>Accept</li></ol></li><li><ol start="3"><li>Learn</li></ol></li></ul></li><li><p>约束条件</p><ul><li>正确性</li><li>可终止性</li></ul></li></ul></li><li><p>Raft</p></li></ul><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><ul><li><p>算法</p><ul><li><p>轮询</p><ul><li>服务器性能均衡的场景</li></ul></li><li><p>加权轮询</p><ul><li>轮询的基础上根据权重分配</li></ul></li><li><p>最少连接</p><ul><li>将请求发送给当前最少连接的服务器上</li></ul></li><li><p>加权最少连接</p><ul><li>根据权重结算最少连接</li></ul></li><li><p>随机算法</p></li><li><p>源地址哈希</p><ul><li>对客户端IP计算哈希值取模</li></ul></li></ul></li><li><p>转发实现</p><ul><li><p>HTTP重定向</p><ul><li>返回302重新发起请求</li><li>延迟高，处理能力有限</li></ul></li><li><p>DNS域名解析</p><ul><li>解析域名同时使用负载均衡算法计算服务器IP</li><li>优点：能根据地理位置进行域名解析，可以返回最近的服务器</li><li>缺点：DNS多级缓存，当下线机器需要修改DNS记录，生效时间慢</li></ul></li><li><p>反向代理</p><ul><li>Openresty&#x2F;Nginx</li><li>缺点：所有请求和响应都要经过反向代理服务器，容易成为瓶颈</li></ul></li><li><p>网络层</p></li><li><p>链路层</p><ul><li>LVS</li></ul></li></ul></li></ul><h3 id="Session管理"><a href="#Session管理" class="headerlink" title="Session管理"></a>Session管理</h3><ul><li><p>Sticky Session</p></li><li><p>Session Replication</p></li><li><p>Session Server</p><ul><li>Redis、MySQL</li></ul></li></ul><h2 id="攻击技术"><a href="#攻击技术" class="headerlink" title="攻击技术"></a>攻击技术</h2><h3 id="跨站脚本攻击：XSS（Cross-Site-Scripting）"><a href="#跨站脚本攻击：XSS（Cross-Site-Scripting）" class="headerlink" title="跨站脚本攻击：XSS（Cross-Site Scripting）"></a>跨站脚本攻击：XSS（Cross-Site Scripting）</h3><h3 id="跨站请求伪造：CSRF（Cross-Site-request-forgery）"><a href="#跨站请求伪造：CSRF（Cross-Site-request-forgery）" class="headerlink" title="跨站请求伪造：CSRF（Cross-Site request forgery）"></a>跨站请求伪造：CSRF（Cross-Site request forgery）</h3><ul><li>检查Referer头</li><li>添加token校验</li><li>验证码</li></ul><h3 id="SQL注入"><a href="#SQL注入" class="headerlink" title="SQL注入"></a>SQL注入</h3><ul><li>sql quote预处理</li></ul><h3 id="拒绝服务攻击（DoS、DDoS）"><a href="#拒绝服务攻击（DoS、DDoS）" class="headerlink" title="拒绝服务攻击（DoS、DDoS）"></a>拒绝服务攻击（DoS、DDoS）</h3><h2 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li>将哈希空间看做一个环，每个节点都配置在环上，每个数据对象通过哈希取模得到哈希值后，顺时针向前走，存放在碰到第一个节点上</li></ul><h3 id="分布不均问题"><a href="#分布不均问题" class="headerlink" title="分布不均问题"></a>分布不均问题</h3><ul><li>虚拟节点解决</li></ul><h2 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h2><h2 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h2><h3 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h3><ul><li><p>点对点</p><ul><li>生产者向MQ中发送了一个消息后，只能被一个消费者消费一次</li></ul></li><li><p>发布&#x2F;订阅</p><ul><li>生产者向频道发送了一个消息后，多个消费者可以从该频道订阅这条消息并消费</li></ul></li></ul><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>异步处理</li><li>流量削峰</li><li>应用解耦</li></ul><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><ul><li><p>发送端可靠性</p><ul><li>本地消息表</li></ul></li><li><p>接收端可靠性</p><ul><li>幂等性</li><li>唯一消息ID</li></ul></li></ul><p><a href="https://github.com/CyC2018/CS-Notes">【参考文章】GitHub-CyC2018&#x2F;CS-Notes</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基础&quot;&gt;&lt;a href=&quot;#基础&quot; class=&quot;headerlink&quot; title=&quot;基础&quot;&gt;&lt;/a&gt;基础&lt;/h2&gt;&lt;h3 id=&quot;性能&quot;&gt;&lt;a href=&quot;#性能&quot; class=&quot;headerlink&quot; title=&quot;性能&quot;&gt;&lt;/a&gt;性能&lt;/h3&gt;&lt;ul&gt;
&lt;</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式" scheme="https://harryzhang.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="CAP" scheme="https://harryzhang.cn/tags/CAP/"/>
    
    <category term="BASE" scheme="https://harryzhang.cn/tags/BASE/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 连接错误问题解决</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-%E8%BF%9E%E6%8E%A5%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-%E8%BF%9E%E6%8E%A5%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</id>
    <published>2023-03-25T07:15:48.000Z</published>
    <updated>2023-03-25T07:18:37.329Z</updated>
    
    <content type="html"><![CDATA[<h2 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h2><ul><li>操作系统：Ubuntu16.04-server</li><li>MySQL版本：5.7.25</li></ul><h2 id="故障一"><a href="#故障一" class="headerlink" title="故障一"></a>故障一</h2><p>只能通过localhost登录MySQL</p><ol><li>报错如下<blockquote><p>$mysql -h172.16.0.1 -uroot -p123456<br>mysql: [Warning] Using a password on the command line interface can be insecure.<br>ERROR 1130 (HY000): Host ‘172.16.0.1’ is not allowed to connect to this MySQL server</p></blockquote></li><li>解决方法<br>此处参考自：<a href="https://stackoverflow.com/questions/19101243/error-1130-hy000-host-is-not-allowed-to-connect-to-this-mysql-server">https://stackoverflow.com/questions/19101243/error-1130-hy000-host-is-not-allowed-to-connect-to-this-mysql-server</a></li></ol><ul><li>首先查看你的root用户允许的主机ip<blockquote><p>mysql&gt;SELECT host FROM mysql.user WHERE User &#x3D; ‘root’;<br>+———–+<br>| host      |<br>+———–+<br>| localhost |<br>+———–+<br>1 row in set (0.24 sec)<br>一般结果中只有localhost或同时有localhost和127.0.0.1；</p></blockquote></li><li>然后如果你想指定允许某个ip可访问可执行如下命令<blockquote><p><code>CREATE USER &#39;root&#39;@&#39;ip_address&#39; IDENTIFIED BY &#39;some_pass&#39;;</code><br><code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;ip_address&#39;;</code></p></blockquote></li><li>如果想要允许所有ip执行如下命令<blockquote><p><code>CREATE USER &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;some_pass&#39;;</code><br><code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39;;</code></p></blockquote></li><li>上面两种最后都要flush启用更改<blockquote><p><code> FLUSH PRIVILEGES;</code></p></blockquote></li><li>然后在执行一次查询会发现结果多了一行“%”，说明更改成功<br>+———–+<br>| host      |<br>+———–+<br>| %         |<br>+———–+<br>| localhost |<br>+———–+<br>1 row in set (0.24 sec)<br>再次登录如果仍旧失败，请看故障2</li></ul><h2 id="故障二"><a href="#故障二" class="headerlink" title="故障二"></a>故障二</h2><ol><li>报错如下<blockquote><p>$mysql -h172.16.0.1 -uroot -p123456<br>mysql: [Warning] Using a password on the command line interface can be insecure.<br>ERROR 2003 (HY000): Can’t connect to MySQL server on ‘172.16.0.1’ (111)</p></blockquote></li><li>解决方法</li></ol><ul><li>查看mysql的配置文件<blockquote><p>$vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf</p></blockquote></li><li>将下面一行注释或者修改<blockquote><p><code>注释</code><br><code>#bind-address            = 127.0.0.1</code><br><code>修改</code><br><code>bind-address            = 0.0.0.0</code></p></blockquote></li><li>重启mysql启用更改<blockquote><p>$service mysql restart</p></blockquote></li></ul><p>再次尝试登录即可成功登录！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;软件环境&quot;&gt;&lt;a href=&quot;#软件环境&quot; class=&quot;headerlink&quot; title=&quot;软件环境&quot;&gt;&lt;/a&gt;软件环境&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;操作系统：Ubuntu16.04-server&lt;/li&gt;
&lt;li&gt;MySQL版本：5.7.25&lt;/li&gt;
&lt;/u</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL ORDER BY 如何实现排序的?</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-ORDER-BY-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%8E%92%E5%BA%8F%E7%9A%84/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-ORDER-BY-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%8E%92%E5%BA%8F%E7%9A%84/</id>
    <published>2023-03-25T07:12:42.000Z</published>
    <updated>2023-03-25T07:18:17.890Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MySQL是如何进行排序的？"><a href="#MySQL是如何进行排序的？" class="headerlink" title="MySQL是如何进行排序的？"></a>MySQL是如何进行排序的？</h2><p>假设有一个表t结构如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-c7aec6166a2d984f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-c7aec6166a2d984f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>id为主键，type上建有索引，那么如果要查类型为1，val最小的1000行，那么SQL语句如下：<br><code>SELECT type, val, detail FROM t WHERE type = 1 ORDER BY val LIMIT 1000;</code></p><h3 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h3><p>对上述查询执行explain结果如下：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-b14d9da637a8123d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-b14d9da637a8123d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Using filesort表示需要排序，MySQL会给每个线程分配一块内存用来排序，称为sort buffer，具体的流程如下：</p><ol><li>初始化sort buffer，确定放入type，val，detail三个字段</li><li>从索引type中找到第一个满足type&#x3D;1条件的主键id</li><li>根据id回主键索引查询type和val的值存入sort buffer中，从索引type中继续取下一个id</li><li>重复3的操作直到type不满足条件</li><li>对sort buffer中的数据按照val字段做快速排序</li><li>按照排序结果取前1000行返回</li></ol><p>如果sort buffer够存下所有需要排序的记录，排序在内存中完成，如果内存放不下则需要借助磁盘临时文件进行外部排序。</p><h3 id="rowid排序"><a href="#rowid排序" class="headerlink" title="rowid排序"></a>rowid排序</h3><p>全字段排序过程里只对原表扫描的一遍，剩下的操作都是在sort buffer 和临时文件中执行的，但是如果要查询的字段比较多，sort buffer能存的行数就很少，需要分成多个临时文件进行外部排序，性能比较差，所以在单行数大的情况下这种方式明显不合适。</p><p>MySQL的参数<code>max_length_for_sort_data</code>表示如果单行记录长度超过这个值，就认为单行太大，要换一种排序算法，排序过程中只放要排序的列和主键id，执行流程如下：</p><ol><li>初始化sort buffer，放入val，id字段</li><li>从索引type中找到第一个满足type&#x3D;1条件的主键id</li><li>根据id回主键索引查询val的值，将val和id存入sort buffer中，从索引type中继续取下一个id</li><li>重复3的操作直到type不满足条件</li><li>对sort buffer中的数据按照val字段做快速排序</li><li>按照排序结果依次取1000行，并按照id值回表取出type，val，detail三个字段返回</li></ol><p>可以看到改流程与全字段排序的主要区别在于：</p><ul><li>第1步放入sort buffer的字段不同，rowid排序只放入排序字段和id，全字段排序放入查询的全部字段</li><li>第6步，rowid排序完成后要再回主键索引查一次全部数据返回，全字段排序因为所以要返回的字段内容都在sort buffer中了所以直接返回</li></ul><p><strong>说明</strong>：结果集只是一个逻辑概念，实际上MySQL从排序后的sort buffer中依次取出id，然后到原表查询所有字段的结果不需要在服务端再消耗内存保存，是直接返回的。</p><h3 id="联合索引避免排序"><a href="#联合索引避免排序" class="headerlink" title="联合索引避免排序"></a>联合索引避免排序</h3><p>上面两种方法都是需要建临时表进行排序的，对于MySQL来说都是成本比较高的操作。但并不是所有order by都是需要排序的，因为MySQL索引是天然有序的，如果在type和val字段创建一个联合索引idx_type_val，那么该查询就不需要排序了，这时执行过程就变成了如下流程：</p><ol><li>在索引idx_type_val上找到第一个满足type&#x3D;1条件记录</li><li>根据索引上的主键id回主键索引查询所有字段的值返回，在idx_type_val索引上继续取一下个值</li><li>重复2的操作直到不满足type&#x3D;1或者超过1000行结束。</li></ol><p>使用联合索引，首先不在需要建临时表做排序，其次也不需要扫描出满足type&#x3D;1条件的所有记录，因为索引有序直接扫描前1000行就结束了，大大减少了扫描的行数。</p><h2 id="优先队列排序"><a href="#优先队列排序" class="headerlink" title="优先队列排序"></a>优先队列排序</h2><p>对于MySQL来说并不是所有的排序都是用快速排序实现的，假如之前的查询变成了如下：<br><code>EXPLAIN SELECT type, val FROM t WHERE type = 1 ORDER BY val LIMIT 3;</code><br>假设type&#x3D;1的记录有1万条，只需要去前val最小的前三行。</p><p>对于这种情况，即使sort buffer不能放下1万行记录，会发现MySQL也没有使用到临时文件，这时因为选择了另一种算法：优先队列算法。</p><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ol><li>对于这10000准备排序的记录，先取前三行构造一个最大堆</li><li>取下一行Next记录跟当前堆顶记录Top比较，如果Next.val &lt; Top.val，就把堆顶记录弹出，将Next记录放入堆</li><li>重复2的操作直到取出所有10000行记录，最后堆中的三个记录就是最小的三个</li></ol><h4 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h4><p>快速排序时间复杂度是<code>O(N*logN)</code>，优先队列排序时间复杂度为<code>O((N-K)*logK)</code>，K表示堆的大小，即返回记录的个数，对于该场景下为<code>(N-3)*log3</code>，基本可以看做线性时间复杂度，如果是limit 1的时候就相当于求最小值，该算法就是线性时间复杂度。<br>其次sort buffer中只需要维护堆，内存的消耗也大大减少，空间复杂度为<code>O(K)</code>。</p><h2 id="order-by-rand"><a href="#order-by-rand" class="headerlink" title="order by rand()"></a>order by rand()</h2><p>如果需要随机选1个数，SQL语句可能如下：<br><code>SELECT * FROM t ORDER BY RAND() LIMIT 1</code><br>需要注意到是这种方式会建临时表进行排序，临时表除了查询字段会多加一个排序字段存放rand()生成的值，即对每一行记录使用rand()函数生成一个随机数，然后根据这个数来排序。</p><p>这种写法的成本是比较高的，所以建议尽量避免这种写法，建议先随机一个0~N-1的值（N表示表总行数），然后去查数据库的某行，比如：</p><pre><code class="python">def rand1():    N = mysql.query(&quot;select count(*) from t&quot;)    res = mysql.query(&quot;select * from t limit N, 1&quot;)    return res</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【极客时间】<a href="https://time.geekbang.org/column/article/73479">MySQL实战45讲：16、17</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;MySQL是如何进行排序的？&quot;&gt;&lt;a href=&quot;#MySQL是如何进行排序的？&quot; class=&quot;headerlink&quot; title=&quot;MySQL是如何进行排序的？&quot;&gt;&lt;/a&gt;MySQL是如何进行排序的？&lt;/h2&gt;&lt;p&gt;假设有一个表t结构如下图所示：&lt;br&gt;&lt;im</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
    <category term="排序" scheme="https://harryzhang.cn/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 脏页刷盘</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-%E8%84%8F%E9%A1%B5%E5%88%B7%E7%9B%98/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-%E8%84%8F%E9%A1%B5%E5%88%B7%E7%9B%98/</id>
    <published>2023-03-25T07:12:03.000Z</published>
    <updated>2023-03-25T07:18:02.317Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是脏页？"><a href="#什么是脏页？" class="headerlink" title="什么是脏页？"></a>什么是脏页？</h2><p>InnoDB在处理更新语句时，先写内存再写redo log，并不会立即将数据页的更新落地到磁盘（WAL机制），这就会产生升内存数据页和磁盘数据页的数据不一致的情况，这种数据不一致的数据页称为<strong>脏页</strong>，当脏页写入到磁盘（这个操作称为flush）后，数据一致后称为干净页。</p><h2 id="什么时候会flush脏页？"><a href="#什么时候会flush脏页？" class="headerlink" title="什么时候会flush脏页？"></a>什么时候会flush脏页？</h2><ol><li><p>redo log写满<br>redo log大小是固定的，写完后会循环覆盖写入。当有新的内容要写入时，系统必须停止所有的更新操作，将checkpoint向前推进到新的位置，但是在推进之前必须将覆盖部分的所有脏页都flush到磁盘上。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-05061327e5e6e8fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-05061327e5e6e8fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>内存不足需要淘汰数据页<br>当系统内存不足，又有新的数据页要更新，就需要淘汰一些数据页，如果淘汰的是脏页，就需要flush到磁盘（如果是干净页就直接释放出来复用）。</p></li><li><p>系统空闲的时候后台会定期flush适量的脏页到磁盘</p></li><li><p>MySQL正常关闭（shut down）时会把所有脏页都flush到磁盘</p></li></ol><h2 id="flush对系统性能的影响"><a href="#flush对系统性能的影响" class="headerlink" title="flush对系统性能的影响"></a>flush对系统性能的影响</h2><p>第3种是系统空闲不会有性能问题，第4种是要关闭了不考虑性能问题。第1和2的情况flush脏页会产生系统性能问题。</p><h3 id="redo-log写满"><a href="#redo-log写满" class="headerlink" title="redo log写满"></a>redo log写满</h3><p>此时整个系统不能再更新了，更新数会降为0，所以这种情况要尽量避免。</p><h3 id="内存不够"><a href="#内存不够" class="headerlink" title="内存不够"></a>内存不够</h3><p>InnoDB缓冲池（buffer pool）中的内存页有三种状态：</p><ul><li>未使用的空闲内存</li><li>使用了为脏页</li><li>使用了未干净页</li></ul><p>当一个SQL语句要淘汰的脏页数量太多，会导致语句执行的响应时间显著边长。</p><h2 id="flush速度控制策略"><a href="#flush速度控制策略" class="headerlink" title="flush速度控制策略"></a>flush速度控制策略</h2><p>InnoDB为了避免出现上述两种情况，需要有控制脏页比例的策略，控制的主要参考因素就是：脏页比例和redo log写盘速度。</p><h4 id="磁盘的IO能力"><a href="#磁盘的IO能力" class="headerlink" title="磁盘的IO能力"></a>磁盘的IO能力</h4><p>需要告诉InnoDB的磁盘读写能力（IOPS）让引擎全力flush脏页，磁盘的IOPS可以通过fio工具测试。</p><pre><code class="shell"> fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest </code></pre><p>如果<code>innodb_io_capacity</code>参数设置的不合理，比如远远低于磁盘实际的IOPS，InnoDB会认为IO性能低，刷脏页速度会很慢，甚至低于脏页的生成速度，导致脏页累计影响查询和更新性能。</p><h4 id="速度计算流程"><a href="#速度计算流程" class="headerlink" title="速度计算流程"></a>速度计算流程</h4><p>为了兼顾正常的业务请求，InnoDB引擎控制按照磁盘IOPS的百分比来刷脏页，具体流程如下：</p><ol><li>参数<code>innodb_max_dirty_pages_pct</code>控制脏页比例上限，默认75%。InnoDB根据当前脏页比例（设为M），计算出一个0~100的数字F1(M)，伪代码如下</li></ol><pre><code class="python">def F1(M):    if M &gt;= innodb_max_dirty_pages_pct:        return 100    return 100 * M / innodb_max_dirty_pages_pct</code></pre><ol start="2"><li>InnoDB每次写入的日志都有一个序号，当前写入的序号跟checkpoint对应的需要之间的差值设为N，根据N计算出一个0~100的数值F2(N)，N越大F2(N)越大</li><li>根据前两步计算出的两个值取较大值记为R，然后InnoDB会根据<code>innodb_io_capacity</code>设置的磁盘IOPS能力乘以R%来控制刷脏页的速度</li></ol><p>脏页比例计算:<br><code>Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total</code><br>SQL语句如下：</p><pre><code class="sql">select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = &#39;Innodb_buffer_pool_pages_dirty&#39;;select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = &#39;Innodb_buffer_pool_pages_total&#39;;select @a/@b;</code></pre><h2 id="连锁flush"><a href="#连锁flush" class="headerlink" title="连锁flush"></a>连锁flush</h2><p>在准备flush一个脏页时，如果相邻的数据页也是脏页，会把这个脏页一起flush，而且对这个新的脏页还可能有相邻的脏页导致连锁flush。<br>InnoDB使用<code>innodb_flush_neighbors</code>参数控制这个行为，值为1会产生上述连锁flush的情况，值为0则不会找相邻页。</p><p>找相邻页flush的机制虽然可以减少很多随机IO，但会增加一次flush时间，导致flush时的SQL语句执行时间变慢。</p><p>现在基本都使用的SSD这种IOPS比较高的硬盘，建议将<code>innodb_flush_neighbors</code>参数设为0，提高flush的速度。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>flush会占用IO资源影响了正在执行的SQL语句，本来正常情况下执行很快的一条语句，突然耗时大大增加，造成业务抖动。要尽量避免这种情况，需要合理的设置<code>innodb_io_capacity</code>的值，并且多关注脏页比例，不要让脏页比例经常接近75%。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>【极客时间】<a href="https://time.geekbang.org/column/article/71806">MySQL实战45讲：第12节</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是脏页？&quot;&gt;&lt;a href=&quot;#什么是脏页？&quot; class=&quot;headerlink&quot; title=&quot;什么是脏页？&quot;&gt;&lt;/a&gt;什么是脏页？&lt;/h2&gt;&lt;p&gt;InnoDB在处理更新语句时，先写内存再写redo log，并不会立即将数据页的更新落地到磁盘（WAL机制）</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
    <category term="脏页" scheme="https://harryzhang.cn/tags/%E8%84%8F%E9%A1%B5/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 索引原理详解</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/</id>
    <published>2023-03-25T07:11:48.000Z</published>
    <updated>2023-03-25T07:17:49.471Z</updated>
    
    <content type="html"><![CDATA[<h2 id="索引的底层实现"><a href="#索引的底层实现" class="headerlink" title="索引的底层实现"></a>索引的底层实现</h2><p>InnoDB存储引擎数据结构使用B+树</p><h3 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h3><p>B+数据的基本结构如下图<br><img src="https://upload-images.jianshu.io/upload_images/14151453-8fa2fd1bbc4b7f13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-8fa2fd1bbc4b7f13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="为什么选用B-树"><a href="#为什么选用B-树" class="headerlink" title="为什么选用B+树"></a>为什么选用B+树</h3><p>MySQL为什么要选B+树作为存储结构呢，与B树相比有哪些优点？</p><p><strong>1. 减少磁盘访问，提高查询效率</strong><br>B+树非叶子节点上是不存数据的，仅存键值，而B树节点中不仅存储键值，也会存储数据。因为数据页的大小是固定的（InnoDB中页的默认大小是16KB），如果不存储数据，那么就会存储更多的键值，相应的树的阶数N就会更大，树高就会越低，这样查询数据进行磁盘IO的次数就会大大减少，数据查询的效率也会更快。<br>以InnoDB的一个整数字段索引为例，阶数N大概是1200，这棵树高是4的时候，就可以存1200^3（约17亿）个值，因为根节点总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。</p><p><strong>2. 提高范围查找效率</strong><br>因为B+树的所有数据均存储在叶子节点，而且是有序的，使得B+树范围查找，排序查找，分组查找以及去重查找变的简单，而B树的数据分散在各个节点上，实现起来比较困难。</p><h2 id="普通索引和唯一索引如何选择？"><a href="#普通索引和唯一索引如何选择？" class="headerlink" title="普通索引和唯一索引如何选择？"></a>普通索引和唯一索引如何选择？</h2><p>普通索引不需要保证一条记录的唯一性，查询和更新操作都不需要保证数据页已经读到内存中，相反唯一索引为了保证唯一性，更新时必须要保证数据页在内存中，需要检查是否满足唯一性</p><h3 id="查询操作的区别"><a href="#查询操作的区别" class="headerlink" title="查询操作的区别"></a>查询操作的区别</h3><ul><li>普通索引：查找到满足条件的第一个记录后，需要查找下一条记录，直到碰到不满足的记录</li><li>唯一索引：查找满足条件的第一个记录就会停止检索</li></ul><p>因为是innoDB的读写操作是以数据页为单位的，通常情况目标记录的下一个记录也会在内存中，对于普通索引来说，只是多了一次判断操作，这个CPU成本可以忽略不计，如果是目标记录恰好在某页的最后，下一条记录需要从磁盘中读取，这个I\O成本会大一些，但是这种情况出现的概率很低。<br>所以对于查询操作来说，唯一索引更快，但是性能差异非常小。</p><h3 id="更新操作的区别"><a href="#更新操作的区别" class="headerlink" title="更新操作的区别"></a>更新操作的区别</h3><h4 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change buffer"></a>change buffer</h4><p>当更新一个数据页时，如果数据页在内存中就直接更新，如果数据页还没有在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存再change buffer中，这样就不用从磁盘中读入数据了，大大提高了更新操作的性能。InnoDB会在下次访问这个数据页的时候将数据页读入内存然后执行change buffer中与这个页有关的操作，保证数据的最终一致性。</p><p><strong>change buffer</strong>是可持久化的数据，也会被写到磁盘中，写入change buffer操作也会记录在redo log中。</p><p><strong>merge</strong>：将change buffer中的操作应用到原数据页的过程称为merge，merge除了在查询操作时会触发，系统后台有线程会定期merge，数据库正常关闭（shut down）时也会执行merge操作。</p><p><strong>优点</strong>：</p><ul><li>减少读磁盘，明显提升更新操作的速度</li><li>数据读入内存会占用buffer pool，可以减少内存使用，提高内存利用率</li></ul><p><strong>使用条件</strong>：</p><ul><li>唯一索引的更新操作需要判断唯一性约束，必须将数据读到内存中才能判断，因此唯一索引的更换不能使用</li><li>只有普通索引可使用</li><li>change buffer使用的是buffer pool中的内存，因此不能过大。</li></ul><p><strong>应用场景</strong>：</p><ul><li>写多读少的业务，如账单、日志类的系统</li></ul><p>如果业务更新后马上会做查询，那么merge的操作会被触发，这样随机访问磁盘的次数不会减少还增加了change buffer的维护代价，反而起到了反作用。</p><h3 id="索引的选择"><a href="#索引的选择" class="headerlink" title="索引的选择"></a>索引的选择</h3><ul><li>在业务保证唯一性的前提下，尽量选择普通索引。</li><li>如果更新后面马上伴随这查询，应该关闭change buffer</li></ul><h3 id="change-buffer和redo-log"><a href="#change-buffer和redo-log" class="headerlink" title="change buffer和redo log"></a>change buffer和redo log</h3><p>使用change buffer的更新语句执行的过程：</p><ol><li>如果数据页在内存中，直接更新内存</li><li>如果数据页不在内存中，在change buffer中记录更新操作</li><li>将1或2的动作记录在redo log中</li></ol><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><ul><li>redo log主要是节省随机写磁盘的IO消耗（转为顺序写）</li><li>change buffer主要节省随机读磁盘的IO消耗</li></ul><h2 id="为什么MySQL优化器会选错索引"><a href="#为什么MySQL优化器会选错索引" class="headerlink" title="为什么MySQL优化器会选错索引"></a>为什么MySQL优化器会选错索引</h2><p>优化器选择索引的目的是找一个最优的方案，并用最小的代价去执行语句，扫描行数是影响执行速度的代价之一，扫描行数越少，意味着访问磁盘数据越少，消耗的CPU资源也越少（扫描行数并不是唯一判断标准，还会结合是否使用临时表、是否排序等因素进行综合判断）。<br>在不涉及临时表和排序的情况下，选错索引肯定是在判断扫描行数的时候出错了</p><h3 id="扫描行数如何计算的"><a href="#扫描行数如何计算的" class="headerlink" title="扫描行数如何计算的"></a>扫描行数如何计算的</h3><p>执行语句前MySQL并不能精确的知道这个条件的记录有多少条，只能根据统计信息来估算扫描记录数。</p><h4 id="索引的基数"><a href="#索引的基数" class="headerlink" title="索引的基数"></a>索引的基数</h4><p>一个索引上不同的值越多，这个索引的区分度就越好，而一个索引上不同的值的个数称为基数，基数越大说明区分度越好。</p><h4 id="基数的计算"><a href="#基数的计算" class="headerlink" title="基数的计算"></a>基数的计算</h4><p>MySQL使用采样统计（选择采样而不是全表扫描是为了节省计算成本）：</p><ul><li>InnoDB默认会选择N个数据页，统计这些页面上的不同值得到一个平均值，然后乘以索引的页面数得到基数。</li><li>数据表持续更新的过程中，当变更的数据行占比超过1&#x2F;M的时候，会自动触发做一次索引统计</li></ul><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol><li>当发现explain的结果预估的rows值跟实际差距比较大可以使用<code>analyze table</code>命令解决</li><li>使用<code>force index()</code>强行选择某个索引</li><li>优化SQL语句引导MySQL选择更合适的索引</li><li>新建一个更合适的索引</li></ol><h2 id="字符串前缀索引"><a href="#字符串前缀索引" class="headerlink" title="字符串前缀索引"></a>字符串前缀索引</h2><p>给一个字符串字段上加索引有如下两种选择：</p><ol><li>整个字符串加索引：<code>alter table user add index idx_email(email);</code></li><li>前六个字符索引：<code>alter table user add index idx_email(email(6));</code></li></ol><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>前缀索引的索引结构只保存了前n个字符，索引占用的空间会更小</li><li>使用前缀索引定义合适的长度，即可以节省空间，又不会增加太多查询成本</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>增加了查询额外扫描次数，需要查找到所有前缀匹配的记录，每条记录都要回表查询完整数据进行判断。</li><li>使用前缀索引会破坏覆盖索引（查询字段上都建了索引，不需要回表）对查询性能的优化</li></ul><h3 id="其他方式"><a href="#其他方式" class="headerlink" title="其他方式"></a>其他方式</h3><ul><li>倒序存储加前缀索引：当字符串的前n为重复度高的情况</li><li>hash字段：添加一个hash字段，保存字符串字段的校验码（如crc32）</li></ul><p>这两种方法都不支持范围查找，都会产生额外的cpu计算消耗，hash字段的查询性能更稳定，crc32计算的值冲突概率非常小。</p><h2 id="独立索引"><a href="#独立索引" class="headerlink" title="独立索引"></a>独立索引</h2><p>必须是独立的索引字段才能用到索引，在索引上使用函数、表达式都会导致不能使用索引树搜索，从而导致慢查询。</p><h3 id="CASE1：在索引上使用函数"><a href="#CASE1：在索引上使用函数" class="headerlink" title="CASE1：在索引上使用函数"></a>CASE1：在索引上使用函数</h3><p>建表语句如下：</p><pre><code class="sql">CREATE TABLE `tradelog` (  `id` int(11) NOT NULL,  `tradeid` varchar(32) DEFAULT NULL,  `operator` int(11) DEFAULT NULL,  `t_modified` datetime DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `tradeid` (`tradeid`),  KEY `t_modified` (`t_modified`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</code></pre><p>如果要查询几年内某个月的交易总数，查询语句可能如下：<br><code>select count(*) from tradelog where month(t_modified)=7;</code><br>索引上使用函数可能会导致其失去有序性，从而不能使用树搜索（不代表使用索引，可以在索引上遍历），即使没有改变索引的有序性优化器还是不能用索引快速查找，所以要避免这种写法。</p><h3 id="CASE2：隐式类型转换"><a href="#CASE2：隐式类型转换" class="headerlink" title="CASE2：隐式类型转换"></a>CASE2：隐式类型转换</h3><p>假如有如下语句：<br><code>select * from tradelog where tradeid=110717;</code><br>tradeid字段是varchar类型，如果要和数字作比较会将其转换为数字类型，对于优化器来说上述语句相当于:<br><code>select * from tradelog where  CAST(tradid AS signed int) = 110717;</code><br>可以看到隐式的在索引字段上使用了函数，从而导致不能使用树搜索。</p><h3 id="CASE3：隐式编码转换"><a href="#CASE3：隐式编码转换" class="headerlink" title="CASE3：隐式编码转换"></a>CASE3：隐式编码转换</h3><p>如果在做连表查询是，驱动表和被驱动表的字段编码类型不一致，会导致索引不能使用树搜索。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>【极客时间】<a href="https://time.geekbang.org/column/article/70848">MySQL实战45讲</a>：09、10、11节</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;索引的底层实现&quot;&gt;&lt;a href=&quot;#索引的底层实现&quot; class=&quot;headerlink&quot; title=&quot;索引的底层实现&quot;&gt;&lt;/a&gt;索引的底层实现&lt;/h2&gt;&lt;p&gt;InnoDB存储引擎数据结构使用B+树&lt;/p&gt;
&lt;h3 id=&quot;B-树&quot;&gt;&lt;a href=&quot;#B-树</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
    <category term="索引" scheme="https://harryzhang.cn/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
</feed>
