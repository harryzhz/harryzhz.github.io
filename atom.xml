<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Harry 的个人空间</title>
  
  
  <link href="https://harryzhang.cn/atom.xml" rel="self"/>
  
  <link href="https://harryzhang.cn/"/>
  <updated>2023-03-25T07:32:08.770Z</updated>
  <id>https://harryzhang.cn/</id>
  
  <author>
    <name>harry zhang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一致性哈希算法原理</title>
    <link href="https://harryzhang.cn/2023/03/25/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"/>
    <id>https://harryzhang.cn/2023/03/25/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/</id>
    <published>2023-03-25T07:25:04.000Z</published>
    <updated>2023-03-25T07:32:08.770Z</updated>
    
    <content type="html"><![CDATA[<h2 id="传统哈希算法的局限性"><a href="#传统哈希算法的局限性" class="headerlink" title="传统哈希算法的局限性"></a>传统哈希算法的局限性</h2><p>在分布式系统中，通常使用多个节点来保存数据，以提高并发能力和容量，那么如果决定数据保存到哪个节点上呢？一般的做法是通过一个哈希函数对数据key进行计算，然后对节点数量取模，从而得到数据分配的节点：<br><code>node_id = hash(key) % N</code><br>但是这种做法在节点数量N变化的时候，大部分key的计算的节点都会重新分配。如果是应用在分布式缓存，就会导致大规模的缓存失效，引起缓存雪崩。</p><h2 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>一致性哈希算法将哈希空间分配到哈希环的数据结构上，取值范围0~2^32-1，并且起点与终点相连。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-3d4ac4aed2d0295d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-3d4ac4aed2d0295d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ol><li>将服务器通过哈希函数（以IP或者主机名作为key）放置到环上</li><li>对数据key使用相同的哈希函数，落到哈希空间上的某个点，如果该点不是服务器节点的位置，则顺时针向前寻找，直到碰到第一个服务器节点，将数据分配到该节点。</li></ol><h4 id="新增节点"><a href="#新增节点" class="headerlink" title="新增节点"></a>新增节点</h4><p><img src="https://upload-images.jianshu.io/upload_images/14151453-889a824feb485b6c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-889a824feb485b6c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>新增了节点S4，那么影响的只是哈希空间S3到S4之间的数据，如原来key4是分配到节点S1，现在分配到了S4。</p><h4 id="下线节点"><a href="#下线节点" class="headerlink" title="下线节点"></a>下线节点</h4><p><img src="https://upload-images.jianshu.io/upload_images/14151453-de338ef1527c2666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-de338ef1527c2666.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>节点S2下线，只影响哈希空间S1到S2之间的数据，如原来key2分配到了S2，现在分配到了S3。</p><h3 id="虚拟节点优化"><a href="#虚拟节点优化" class="headerlink" title="虚拟节点优化"></a>虚拟节点优化</h3><p>当服务节点比较少的时候会出现分配不平衡的问题，造成大量数据集中到一个节点上，如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-9197f7ebe16f828a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-9197f7ebe16f828a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>大部分的哈希空间都会分配到S1上，少量分配到S2上。<br>为了解决这种数据倾斜问题，一致性哈希引入了虚拟节点机制：对每一个服务器节点计算多个哈希，每个计算结果都防止一个此服务器对应的虚拟节点。具体做法可以在服务器IP后面加上编号再计算哈希值。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-01a834f729aa04c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-01a834f729aa04c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>如上图所示，对S1和S2分别虚拟出两个节点，形成四个虚拟节点，数据分配方式不变，不过多了先顺时针找到服务器的虚拟节点，再映射到对应的物理服务器节点。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>良好的伸缩性。一致性哈希算法保证了增加或减少服务器时，数据存储的改变最少，比传统的哈希算法大大节省了数据移动的开销。</li><li>更好的适应数据增长。当数据不断增长，部分虚拟节点可能包含很多数据，造成数据分配不平衡，此时可以将包含数据多的虚拟节点分裂，这种分裂仅仅是将原有的虚拟节点一分为二，不需要对全部数据重新哈希划分。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】 <a href="https://segmentfault.com/a/1190000021199728">图解一致性哈希算法</a><br>【2】<a href="https://zhuanlan.zhihu.com/p/98030096">一致性Hash算法详解</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;传统哈希算法的局限性&quot;&gt;&lt;a href=&quot;#传统哈希算法的局限性&quot; class=&quot;headerlink&quot; title=&quot;传统哈希算法的局限性&quot;&gt;&lt;/a&gt;传统哈希算法的局限性&lt;/h2&gt;&lt;p&gt;在分布式系统中，通常使用多个节点来保存数据，以提高并发能力和容量，那么如果决</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="一致性哈希" scheme="https://harryzhang.cn/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"/>
    
  </entry>
  
  <entry>
    <title>数据库和缓存数据一致性问题如何解决?</title>
    <link href="https://harryzhang.cn/2023/03/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/"/>
    <id>https://harryzhang.cn/2023/03/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/</id>
    <published>2023-03-25T07:24:43.000Z</published>
    <updated>2023-03-25T07:31:36.643Z</updated>
    
    <content type="html"><![CDATA[<p>业务使用Redis做缓存，当有数据更新时，如何保证缓存及时更新</p><h2 id="读数据流程"><a href="#读数据流程" class="headerlink" title="读数据流程"></a>读数据流程</h2><p>请求到来，业务代码会先查Redis，查不到再去查DB，并将结果写入Redis</p><h2 id="写数据方案"><a href="#写数据方案" class="headerlink" title="写数据方案"></a>写数据方案</h2><h3 id="1-先删除缓存，再更新DB"><a href="#1-先删除缓存，再更新DB" class="headerlink" title="1. 先删除缓存，再更新DB"></a>1. 先删除缓存，再更新DB</h3><h4 id="可行性"><a href="#可行性" class="headerlink" title="可行性"></a>可行性</h4><p>先删除缓存，再更新DB，下次读请求到来会从数据库查到新的数据更新到缓存中。如果先更新缓存，在更新DB，更新DB失败会导致数据不一致。</p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><h5 id="容灾不足"><a href="#容灾不足" class="headerlink" title="容灾不足"></a>容灾不足</h5><p>如果删除缓存失败的情况，如果业务继续进行，更新DB，那么在缓存过期之前仍然查到的是旧数据。如果业务返回失败，则对Redis变成了强依赖。</p><h5 id="并发不安全"><a href="#并发不安全" class="headerlink" title="并发不安全"></a>并发不安全</h5><p>考虑如下场景：</p><ol><li>A请求删除缓存，A请求更新DB</li><li>B请求查询缓存，不存在</li><li>B请求查询DB，查到旧数据（更新未完成），写入缓存</li><li>A请求更新DB完成</li></ol><p>这就导致缓存中仍存的旧数据，数据不一致。</p><h3 id="2-先更新DB，再删除缓存"><a href="#2-先更新DB，再删除缓存" class="headerlink" title="2. 先更新DB，再删除缓存"></a>2. 先更新DB，再删除缓存</h3><p>这种策略解决了方法1中的并发问题，但是还是有极小可能存在并发问题，考虑如下情况：</p><ol><li>请求A查询缓存，缓存刚好失效</li><li>请求A查询DB，得到一个旧值</li><li>请求B更新数据库</li><li>请求B删除缓存</li><li>请求A将查到的旧值写入缓存</li></ol><p>这种情况确实会产生数据不一致，但是考虑到DB的读操作总是比写操作快的多，这种场景基本不可能出现。</p><h4 id="如何杜绝并发问题"><a href="#如何杜绝并发问题" class="headerlink" title="如何杜绝并发问题"></a>如何杜绝并发问题</h4><p>延迟异步删，保证读操作完成后再删除缓存。</p><h4 id="如何容灾"><a href="#如何容灾" class="headerlink" title="如何容灾"></a>如何容灾</h4><p>上述方案中如果删除缓存失败了怎么办？</p><h5 id="引入消息队列"><a href="#引入消息队列" class="headerlink" title="引入消息队列"></a>引入消息队列</h5><ol><li>更新DB</li><li>删除缓存，如果失败将要删除的key发送至消息队列</li><li>消费消息，获得需要删除的key，删除key缓存直到成功</li></ol><h5 id="订阅binlog"><a href="#订阅binlog" class="headerlink" title="订阅binlog"></a>订阅binlog</h5><p>上述方法对业务代码的侵入性比较大，为此可以启动一个程序订阅MySQL的binlog用来发现数据更新，流程如下：</p><ol><li>业务代码更新数据库，MySQL将更新操作写入binlog</li><li>订阅程序提取中更新的数据以及key，尝试删除key的缓存</li><li>如果删除缓存失败，将key发送至消息队列</li><li>消费者程序从消息队列中获取待删除的key，重试删除直到成功。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://zhuanlan.zhihu.com/p/59167071">Redis与Mysql双写一致性方案解析</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;业务使用Redis做缓存，当有数据更新时，如何保证缓存及时更新&lt;/p&gt;
&lt;h2 id=&quot;读数据流程&quot;&gt;&lt;a href=&quot;#读数据流程&quot; class=&quot;headerlink&quot; title=&quot;读数据流程&quot;&gt;&lt;/a&gt;读数据流程&lt;/h2&gt;&lt;p&gt;请求到来，业务代码会先查Redis，查</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="一致性" scheme="https://harryzhang.cn/tags/%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
    <category term="Cache-Aside" scheme="https://harryzhang.cn/tags/Cache-Aside/"/>
    
  </entry>
  
  <entry>
    <title>限流算法有哪些?</title>
    <link href="https://harryzhang.cn/2023/03/25/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B/"/>
    <id>https://harryzhang.cn/2023/03/25/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B/</id>
    <published>2023-03-25T07:24:13.000Z</published>
    <updated>2023-03-25T07:30:08.084Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么要限流？"><a href="#为什么要限流？" class="headerlink" title="为什么要限流？"></a>为什么要限流？</h2><p>由于Web服务无法控制调用方的行为，当遇到请求并发量超过系统的容量阈值，会导致服务器资源耗尽从而导致服务异常或宕机，而且某个服务的请求量突增还会影响到上游的服务，如DB或者是其他的公共服务，导致整个系统瘫痪。<br>可能导致流量突增的原因有以下几点：</p><ul><li>热点业务的突发请求（如大型活动）</li><li>调用方bug导致的请求量倍增</li><li>恶意攻击的请求</li></ul><p>为了对服务进行保护，就需要对请求进行限流。</p><h2 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h2><h3 id="固定窗口计数器算法"><a href="#固定窗口计数器算法" class="headerlink" title="固定窗口计数器算法"></a>固定窗口计数器算法</h3><p><img src="https://upload-images.jianshu.io/upload_images/14151453-eb82b484202a6797.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-eb82b484202a6797.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br><strong>算法思路</strong>：</p><ul><li>将时间划分为多个窗口</li><li>每个窗口内每有一次请求计数器加1</li><li>如果计数器超过了限制数量，则本窗口内的所有请求都被丢弃，当时间到达下一个窗口时，计数器重置。</li></ul><p><strong>特点</strong>：原理和实现都比较简单，但是这种算法可能会让通过的请求量为阈值的两倍。比如当阈值是100时，第一个窗口在0-0.5秒期间没有请求，0.5-1.0秒期间有100个请求，然后到了第二个窗口计数器已经重置，在1.0-1.5秒期间有100个请求，这样看来在0.5-1.5秒的1秒内通过了200个请求。</p><h3 id="滑动窗口计数器算法"><a href="#滑动窗口计数器算法" class="headerlink" title="滑动窗口计数器算法"></a>滑动窗口计数器算法</h3><p>该方法就是对固定窗口计数算法的窗口时间细分更多的区间，并且按照时间在区间上滑动，如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-6ffb47a5808a8296.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-6ffb47a5808a8296.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br><strong>算法思路</strong>：</p><ul><li>将时间划分多个区间，维护一个包含多个区间的窗口</li><li>每个区间内每有一次请求就将该区间的计数器加1</li><li>每经过一个区间时间，丢弃最老的一个区间，加入最新的一个区间</li><li>如果当前窗口内区间的请求计数总和超过了限制数量则本窗口内所有新的请求都被丢弃。</li></ul><p><strong>特点</strong>：<br>将时间划分为更小单位的区间，按时间滑动，避免了固定窗口计数器会产生双倍请求的问题，但是时间区间的精度越高，算法需要的空间容量就越大。</p><h3 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h3><p><img src="https://upload-images.jianshu.io/upload_images/14151453-c5fa82d0ce096327.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-c5fa82d0ce096327.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong>算法思路</strong>：</p><ul><li>将每个请求视作“水滴”放入“漏桶”进行存储</li><li>漏桶以固定的速率（通常是服务的最大容量）向外漏出请求交给服务器执行</li><li>如果漏桶空了则停止漏水，如果漏桶满了则丢弃新来的请求</li></ul><p><strong>特点</strong>：通常使用消息队列来实现漏桶。该算法能良好的保证瞬时请求量不会超过阈值，但是当短时间内有大量的突发请求时，即使服务器没有负载，每个请求也都需要在队列中等待一段时间才能被响应。</p><h3 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h3><p><img src="https://upload-images.jianshu.io/upload_images/14151453-943e3e218fb56c62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-943e3e218fb56c62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br><strong>算法思路</strong>：</p><ul><li>令牌以固定速录添加到桶中，如果桶满了直接丢弃</li><li>请求到达时从桶中取令牌，取到了令牌的请求交给服务器执行</li><li>如果桶空了，尝试取令牌的请求就会被拒绝</li></ul><p><strong>特点</strong>：令牌桶算法既能将流量均匀的分布，又能接受服务器承受的容量范围内的突发请求，因此是目前使用比较广泛的一种限流算法。缺点是突发流量时第一个周期会多放过一些请求。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://www.infoq.cn/article/qg2tx8fyw5vt-f3hh673">InfoQ：分布式服务限流实战，已经为你排好坑了</a><br>【2】<a href="https://help.aliyun.com/document_detail/149952.html">阿里云：限流算法介绍</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;为什么要限流？&quot;&gt;&lt;a href=&quot;#为什么要限流？&quot; class=&quot;headerlink&quot; title=&quot;为什么要限流？&quot;&gt;&lt;/a&gt;为什么要限流？&lt;/h2&gt;&lt;p&gt;由于Web服务无法控制调用方的行为，当遇到请求并发量超过系统的容量阈值，会导致服务器资源耗尽从而导致</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="限流" scheme="https://harryzhang.cn/tags/%E9%99%90%E6%B5%81/"/>
    
    <category term="漏桶" scheme="https://harryzhang.cn/tags/%E6%BC%8F%E6%A1%B6/"/>
    
    <category term="令牌桶" scheme="https://harryzhang.cn/tags/%E4%BB%A4%E7%89%8C%E6%A1%B6/"/>
    
  </entry>
  
  <entry>
    <title>分布式全局唯一 ID 生成方案有哪些？</title>
    <link href="https://harryzhang.cn/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80-ID-%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F/"/>
    <id>https://harryzhang.cn/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80-ID-%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F/</id>
    <published>2023-03-25T07:23:45.000Z</published>
    <updated>2023-03-25T07:29:23.961Z</updated>
    
    <content type="html"><![CDATA[<h2 id="全局唯一ID要求"><a href="#全局唯一ID要求" class="headerlink" title="全局唯一ID要求"></a>全局唯一ID要求</h2><p>分布式系统中，我们会对一些数据量大的业务进行拆分，如用户表、订单表，当数据量巨大导致数据库性能下降时，通常会进行分库分表，无法利用MySQL的自增ID，那么就需要一个单独的系统来生成全局唯一ID，而且生成的ID要求具有以下特性：</p><ul><li>整个系统全局唯一</li><li>ID趋势递增，提高数据库插入的效率（索引是递增的，避免乱序插入提高索引的维护成本）</li><li>ID简单，占用空间小，查询效率高</li></ul><h2 id="常见方案"><a href="#常见方案" class="headerlink" title="常见方案"></a>常见方案</h2><h3 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h3><p>全局唯一首先可以想到使用UUID，基本各种语言都提供了UUID的库</p><h5 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h5><ul><li>代码实现简单</li><li>本地生成，没有性能问题</li><li>全球唯一的，数据迁移容易</li></ul><h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><ul><li>每次生成的ID是无序的，不满足趋势递增</li><li>UUID是字符串，而且比较长，占用空间大，查询效率低</li><li>ID没有含义，可读性差</li></ul><h3 id="MySQL自增主键"><a href="#MySQL自增主键" class="headerlink" title="MySQL自增主键"></a>MySQL自增主键</h3><p>单表可以使用MySQL的自增ID，多表的情况下其实也可以使用自增ID，只是和单表每次+1不同，分多表的情况下每次需要加N，具体如下图：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-2a5d07950848c303.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-2a5d07950848c303.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>上图中共分成了两个库4个表，那么每个表初始值一次为1~4，之后每次自增时+4，这样保证了每个表的ID不会重复，而且是趋势递增的，解决了单表的问题。</p><h4 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h4><p>一旦步长定好就无法扩容，数据库单机能力有限，不易于横向扩展</p><h3 id="雪花snowflake方案"><a href="#雪花snowflake方案" class="headerlink" title="雪花snowflake方案"></a>雪花snowflake方案</h3><p>雪花算法生成64位二进制正整数，然后转换为10进制的数，具体方案如下图：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-73e41ba1afcd26c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-73e41ba1afcd26c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>最高的一个bit不用，接下来的41个bit表示微秒级的时间（表示范围约69年），再接下来的10个bit机器编号可以分别表示1024台机器，如果对IDC划分，可以将10-bit的高几位表示IDC，最低位的12个字节是一个自增序列，表示范围为2^12&#x3D;4096个，理论上这种方案每秒可以生成的唯一ID数约为4096*1000&#x3D;409.6w个。</p><h4 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a>优点：</h4><ul><li>整个ID满足趋势递增</li><li>不依赖第三方系统，稳定性和性能都比较高</li><li>可以根据自身业务分配bit位，比较灵活</li></ul><h4 id="缺点：-2"><a href="#缺点：-2" class="headerlink" title="缺点："></a>缺点：</h4><ul><li>强依赖系统时钟，如果系统时钟回拨，会导致ID重复或者服务不可用</li></ul><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>利用Redis的incr原子性操作<br><img src="https://upload-images.jianshu.io/upload_images/14151453-00f8962cc2a1ee14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-00f8962cc2a1ee14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>一般方案为年份+月份+小时+Redis自增。</p><h4 id="优点：-2"><a href="#优点：-2" class="headerlink" title="优点："></a>优点：</h4><ul><li>有序递增，可读性强</li><li>性能较高</li></ul><h4 id="缺点：-3"><a href="#缺点：-3" class="headerlink" title="缺点："></a>缺点：</h4><ul><li>占用带宽，依赖Redis</li></ul><h2 id="更优的方案"><a href="#更优的方案" class="headerlink" title="更优的方案"></a>更优的方案</h2><h3 id="美团的Leaf-segment方案"><a href="#美团的Leaf-segment方案" class="headerlink" title="美团的Leaf-segment方案"></a>美团的Leaf-segment方案</h3><p>在之前的数据方案中，利用自增id每次从数据库只取了一个id，由于数据库的IO能力有限，不能支持高并发的场景，那么如果一次取一批id，消耗完再取一批，是不是就可以提高并发能力了？具体的方案架构如下：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-4747be83c08046d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-4747be83c08046d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>抽象出Proxy Server，用于从数据库批量获取，然后在Leaf内部中逐个消耗分发给用户服务。<br>如图中的数据库表结构：biz_tag用来区分业务，业务之间的id号相互隔离互不影响，每次从数据库取出step个id号，将数据操作次数减少到了1&#x2F;step。<br>对于多个Leaf抢占数据库可以利用MySQL的事务和锁机制，先更新再查询，保证多个Leaf请求的id范围不会重复复。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Begin</span></span><br><span class="line"><span class="keyword">UPDATE</span> <span class="keyword">table</span> <span class="keyword">SET</span> max_id<span class="operator">=</span>max_id<span class="operator">+</span>step <span class="keyword">WHERE</span> biz_tag<span class="operator">=</span>xxx</span><br><span class="line"><span class="keyword">SELECT</span> tag, max_id, step <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> biz_tag<span class="operator">=</span>xxx</span><br><span class="line"><span class="keyword">Commit</span></span><br></pre></td></tr></table></figure><p>这样返回给业务服务的ID范围应该是[max_id-step+1, max_id]</p><h4 id="优点：-3"><a href="#优点：-3" class="headerlink" title="优点："></a>优点：</h4><ul><li>Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景</li><li>ID是趋势递增的64位数字</li><li>高可用：Leaf内部可以使用缓存，即使数据宕机短时间服务仍可用</li><li>可以自定义max_id和step，便于业务迁移</li></ul><h4 id="缺点：-4"><a href="#缺点：-4" class="headerlink" title="缺点："></a>缺点：</h4><ul><li>ID号码不够随机，可能导致发号数量的信息</li><li>TP999数据波动大，当多个Leaf同时消耗完后，还是会阻塞在数据库更新上，业务可能会出现偶尔的时延毛刺</li><li>强依赖DB，DB宕机会导致系统不可用</li></ul><h4 id="双buffer优化"><a href="#双buffer优化" class="headerlink" title="双buffer优化"></a>双buffer优化</h4><p>对于第一个缺点，由于是这个方案设计上的问题不能优化了，但对于第二个缺点，可以作进一步的优化，具体思路如下：<br>之前的方案Leaf从数据库取号段是在号段消耗完的时候进行的，这导致了需要等待从DB取回号段的时间才能返回下一个ID号码，而数据库的操作是比较耗时的，导致Leaf服务阻塞，该次请求时延会突增。<br>为了解决这个问题，希望两次取号段能尽量做到无缝衔接，那么在号段消耗到某个点（比如100&#x2F;1000）的时候异步的就请求DB取下一个号段然后保存在内存中，而不是等到号段用完再同步请求DB，这样就可以很大程度减少因为DB阻塞带来的业务抖动，具体实现如下图：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-bad0803983eb9b35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-bad0803983eb9b35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>Leaf服务内部采用两个segment buffer，当前号段已下发10%时，如果下一个号段未更新，则启动线程去更新下个号段，这样当buffer1消耗完时buffer2很可能已经更新好了，只需要直接切换当前segment到segment buffer2，然后就可以继续发放号码。两个buffer交替工作，平滑DB带来的I&#x2F;O阻塞。</p><h4 id="数据库高可用容灾"><a href="#数据库高可用容灾" class="headerlink" title="数据库高可用容灾"></a>数据库高可用容灾</h4><p>对于第三个缺点强依赖DB的问题，需要DB高可用，可以采用一主两从的方式，分机房部署（常见的架构有“同城三机房”、“两城三中心”），Master和Slave采用半同步复制同步数据，保证至少有两个节点数据一致且不丢失，同时可以接入中间件来实现主从切换。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://blog.csdn.net/zl1zl2zl3/article/details/89509445">一线大厂的分布式唯一ID生成方案是什么样的？</a><br>【2】<a href="https://tech.meituan.com/2017/04/21/mt-leaf.html">Leaf——美团点评分布式ID生成系统</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;全局唯一ID要求&quot;&gt;&lt;a href=&quot;#全局唯一ID要求&quot; class=&quot;headerlink&quot; title=&quot;全局唯一ID要求&quot;&gt;&lt;/a&gt;全局唯一ID要求&lt;/h2&gt;&lt;p&gt;分布式系统中，我们会对一些数据量大的业务进行拆分，如用户表、订单表，当数据量巨大导致数据库性</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="唯一ID" scheme="https://harryzhang.cn/tags/%E5%94%AF%E4%B8%80ID/"/>
    
    <category term="snowflake" scheme="https://harryzhang.cn/tags/snowflake/"/>
    
    <category term="leaf" scheme="https://harryzhang.cn/tags/leaf/"/>
    
  </entry>
  
  <entry>
    <title>从五个问题出发认识消息队列</title>
    <link href="https://harryzhang.cn/2023/03/25/%E4%BB%8E%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E5%87%BA%E5%8F%91%E8%AE%A4%E8%AF%86%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>https://harryzhang.cn/2023/03/25/%E4%BB%8E%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E5%87%BA%E5%8F%91%E8%AE%A4%E8%AF%86%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</id>
    <published>2023-03-25T07:23:17.000Z</published>
    <updated>2023-03-25T07:28:04.198Z</updated>
    
    <content type="html"><![CDATA[<h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><p>消息队列是分布式系统的一个重要组件，从五个问题来初步认识一下消息队列，基本原理是什么样的，如何正确的使用消息队列。</p><ul><li>Q1: 为什么需要消息队列？</li><li>Q2: 如何保证消息不丢失？</li><li>Q3: 如何处理重复消息？</li><li>Q4: 如何保证消息有序性？</li><li>Q5: 如何处理消息堆积？</li></ul><h2 id="为什么需要"><a href="#为什么需要" class="headerlink" title="为什么需要"></a>为什么需要</h2><h3 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h3><ul><li>随着业务的增长，业务逻辑会不断加重，为了保持较快速的响应，可以在核心逻辑处理完后就返回，其他逻辑放到消息队列之后异步处理</li></ul><h3 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h3><ul><li>业务模块增加，可以通过订阅核心服务的消息主题，不影响核心服务</li></ul><h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><ul><li>后端服务无法支撑大量的并发请求，请求先放到队列，后端服务尽最大的能力消费队列</li></ul><h3 id="日志处理"><a href="#日志处理" class="headerlink" title="日志处理"></a>日志处理</h3><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul><li><p>点对点（队列）模型</p><ul><li><p>同一个消息只能由一个消费者消费一次</p><ul><li>Rabbit MQ</li></ul></li></ul></li><li><p>发布&#x2F;订阅模型</p><ul><li><p>订阅了某个主题的所有消费者都可以消费该主题的消息</p><ul><li>Rocket MQ、Kafka</li></ul></li></ul></li></ul><h3 id="各个组件术语（Kafka）"><a href="#各个组件术语（Kafka）" class="headerlink" title="各个组件术语（Kafka）"></a>各个组件术语（Kafka）</h3><ul><li><p>生产者（Producer）</p></li><li><p>消息队列服务器（Broker）</p><ul><li><p>主服务器（Leader）</p></li><li><p>从服务器（Follower）</p></li><li><p>主题（Topic）</p><ul><li>分区（Partition）</li></ul></li></ul></li><li><p>消费者组（Consumer Group）</p><ul><li>消费者（Consumer）</li></ul></li></ul><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ul><li><p>生产消息（发送数据）</p><ul><li><ol><li>从Kafka Cluster获取分区的Leader，Producer将消息发送给Leader</li></ol></li><li><ol start="2"><li>Leader将消息写入本地文件（此时可以直接到步骤3）</li></ol><ul><li>2.1. Followers从Leader pull消息并写入本地后向Leader发送ACK确认</li></ul></li><li><ol start="3"><li>Leader向Producer响应ACK</li></ol></li></ul></li><li><p>存储数据</p><ul><li><p>单独开辟一块磁盘，顺序写入</p></li><li><p>每个分区相当于一个文件目录</p><ul><li><p>Partition&#x2F;Segment</p><ul><li>.index</li><li>.log</li><li>.timeindex</li></ul></li></ul></li></ul></li><li><p>消费消息（接收数据）</p><ul><li><ol><li>Consumer也是从Leader中拉取数据</li></ol></li><li><ol start="2"><li>一个消费者组内的某个消费者可以消费一个Topic的不同分区，单同一个组内的不同消费者不能同时消费某个Topic的同一个分区，一个组的消费者数量最好和分区数相同</li></ol></li></ul></li></ul><h3 id="分区的好处"><a href="#分区的好处" class="headerlink" title="分区的好处"></a>分区的好处</h3><ul><li>方便扩展</li><li>提高并发</li></ul><h2 id="实际问题"><a href="#实际问题" class="headerlink" title="实际问题"></a>实际问题</h2><h3 id="如何保证消息队列不丢失？"><a href="#如何保证消息队列不丢失？" class="headerlink" title="如何保证消息队列不丢失？"></a>如何保证消息队列不丢失？</h3><ul><li><ol><li>生产消息阶段</li></ol><ul><li>正确处理Broker的响应，做重试机制</li></ul></li><li><ol start="2"><li>数据存储阶段</li></ol><ul><li>数据落盘再响应成功，有多个副本时可以等多副本都落盘再响应成功</li></ul></li><li><ol start="3"><li>消费消息阶段</li></ol><ul><li>业务逻辑处理完再确认消息</li></ul></li><li><p>确保了可靠性的同时会影响性能，根据业务选择合适的方式</p></li></ul><h3 id="如何处理重复消息？"><a href="#如何处理重复消息？" class="headerlink" title="如何处理重复消息？"></a>如何处理重复消息？</h3><ul><li><p>为了保证消息不丢失，消息重复是不可避免的</p></li><li><p>业务逻辑幂等性</p><ul><li>增加version版本号做控制</li><li>数据库唯一索引</li></ul></li></ul><h3 id="如何保证消息有序？"><a href="#如何保证消息有序？" class="headerlink" title="如何保证消息有序？"></a>如何保证消息有序？</h3><ul><li><p>全局有序</p><ul><li>一个生产者、一个分区、一个消费者</li></ul></li><li><p>部分有序</p><ul><li>消息按特定规则分配到不同的分区，分区本身是有序的，每个分区由一个消费者消费</li></ul></li></ul><h3 id="如何处理消息堆积？"><a href="#如何处理消息堆积？" class="headerlink" title="如何处理消息堆积？"></a>如何处理消息堆积？</h3><ul><li><ol><li>定位问题，如果是bug引起，修改bug（实际生产场景如果由于发版导致，先回滚再定位原因）</li></ol></li><li><ol start="2"><li>如果不是bug，看能不能优化消费逻辑</li></ol></li><li><ol start="3"><li>如果不能优化，就要横向扩容，同时增加分区数和消费者数量</li></ol></li></ul><p><a href="https://mp.weixin.qq.com/s/u6_WH-r1bRc4m7CUm21Tew">参考文章1 微信公众号文章</a><br><a href="https://zhuanlan.zhihu.com/p/68052232">参考文章2 知乎</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;消息队列&quot;&gt;&lt;a href=&quot;#消息队列&quot; class=&quot;headerlink&quot; title=&quot;消息队列&quot;&gt;&lt;/a&gt;消息队列&lt;/h1&gt;&lt;p&gt;消息队列是分布式系统的一个重要组件，从五个问题来初步认识一下消息队列，基本原理是什么样的，如何正确的使用消息队列。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="消息队列" scheme="https://harryzhang.cn/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="MQ" scheme="https://harryzhang.cn/tags/MQ/"/>
    
    <category term="RabbitMQ" scheme="https://harryzhang.cn/tags/RabbitMQ/"/>
    
    <category term="RocketMQ" scheme="https://harryzhang.cn/tags/RocketMQ/"/>
    
    <category term="Kafka" scheme="https://harryzhang.cn/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>无处不在的微服务</title>
    <link href="https://harryzhang.cn/2023/03/25/%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    <id>https://harryzhang.cn/2023/03/25/%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1/</id>
    <published>2023-03-25T07:23:00.000Z</published>
    <updated>2023-03-25T07:35:40.565Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><ul><li>微服务就是一些协同工作的小而自治的服务</li></ul><h3 id="服务注册与发现"><a href="#服务注册与发现" class="headerlink" title="服务注册与发现"></a>服务注册与发现</h3><ul><li>微服务之间互相调用，服务发现需要管理各个服务的服务器地址，当进行扩容或摘除时能及时更新</li></ul><h3 id="服务监控"><a href="#服务监控" class="headerlink" title="服务监控"></a>服务监控</h3><ul><li>监控、日志、调用链、告警通知、健康检查</li></ul><h3 id="服务容错"><a href="#服务容错" class="headerlink" title="服务容错"></a>服务容错</h3><ul><li>熔断</li><li>切换</li><li>限流和降级</li><li>重试</li></ul><h3 id="服务安全"><a href="#服务安全" class="headerlink" title="服务安全"></a>服务安全</h3><ul><li><p>敏感服务进行身份验证和授权</p><ul><li>HTTPS传输</li><li>隐私数据加密存储</li></ul></li></ul><h3 id="服务治理"><a href="#服务治理" class="headerlink" title="服务治理"></a>服务治理</h3><ul><li>引入微服务框架</li></ul><h2 id="相比单体架构"><a href="#相比单体架构" class="headerlink" title="相比单体架构"></a>相比单体架构</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li><p>技术异构性</p><ul><li>不同服务内部可以选择不同的语言开发，也可以选择适合各自服务的数据库（MySQL、Redis）</li></ul></li><li><p>隔离性</p><ul><li>一个服务不可用不会导致整个系统或其他服务不可用，各个服务相互独立的</li></ul></li><li><p>可扩展性</p><ul><li>可以只对影响性能的瓶颈资源进行扩展升级</li></ul></li><li><p>简化部署</p><ul><li>单个服务的修改迭代只需要发步自己的改动</li></ul></li><li><p>易优化</p><ul><li>代码量不会很大，重构相对容易且改动带来的影响可控</li></ul></li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>管理复杂</li><li>难定位问题</li></ul><h2 id="微服务框架"><a href="#微服务框架" class="headerlink" title="微服务框架"></a>微服务框架</h2><h3 id="Dubbo"><a href="#Dubbo" class="headerlink" title="Dubbo"></a>Dubbo</h3><ul><li>阿里</li><li>仅支持Java语言</li></ul><h3 id="Tars"><a href="#Tars" class="headerlink" title="Tars"></a>Tars</h3><ul><li>腾讯</li><li>仅支持C++语言</li></ul><h3 id="Motan"><a href="#Motan" class="headerlink" title="Motan"></a>Motan</h3><ul><li>微博</li><li>仅支持Java</li></ul><h3 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h3><ul><li>谷歌</li><li>支持多种语言</li></ul><h3 id="thrift"><a href="#thrift" class="headerlink" title="thrift"></a>thrift</h3><ul><li>Facebook</li><li>支持多种语言</li></ul><h2 id="微服务框架和RPC"><a href="#微服务框架和RPC" class="headerlink" title="微服务框架和RPC"></a>微服务框架和RPC</h2><h3 id="RPC（Remote-Procedure-Call）"><a href="#RPC（Remote-Procedure-Call）" class="headerlink" title="RPC（Remote Procedure Call）"></a>RPC（Remote Procedure Call）</h3><ul><li>允许像调用本地函数一样调用另一个程序的函数（C&#x2F;S模式）</li></ul><h3 id="微服务框架-1"><a href="#微服务框架-1" class="headerlink" title="微服务框架"></a>微服务框架</h3><ul><li>微服务框架一般都包含了RPC的实现和一系列的服务治理能力，是一套软件开发框架，可以基于这个框架实现自己的服务，方便的利用框架提供的服务治理和RPC能力，微服务框架也被某些人称为RPC框架</li></ul><h2 id="下一代微服务架构"><a href="#下一代微服务架构" class="headerlink" title="下一代微服务架构"></a>下一代微服务架构</h2><h3 id="服务网格（Service-Mesh）"><a href="#服务网格（Service-Mesh）" class="headerlink" title="服务网格（Service Mesh）"></a>服务网格（Service Mesh）</h3><ul><li><p>特点</p><ul><li>应用程序间通讯中间层</li><li>轻量级网络代理</li><li>应用程序无感知</li><li>解耦应用程序的重试&#x2F;超时、监控、追踪和服务发现</li></ul></li><li><p>Service Mesh之于微服务，类似TCP&#x2F;IP之于网络通信</p></li></ul><p><a href="https://www.zhihu.com/question/65502802">【参考资料】知乎：微服务架构是什么？</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h2&gt;&lt;h3 id=&quot;基本定义&quot;&gt;&lt;a href=&quot;#基本定义&quot; class=&quot;headerlink&quot; title=&quot;基本定义&quot;&gt;&lt;/a&gt;基本定义&lt;/h</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="微服务" scheme="https://harryzhang.cn/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="微服务" scheme="https://harryzhang.cn/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统基础知识概述</title>
    <link href="https://harryzhang.cn/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/"/>
    <id>https://harryzhang.cn/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/</id>
    <published>2023-03-25T07:21:46.000Z</published>
    <updated>2023-03-25T07:26:36.365Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><ul><li><p>性能指标</p><ul><li>响应时间</li><li>吞吐量（QPS、TPS）</li><li>并发用户数：不是越高越好，如果系统来不及处理就会阻塞，响应时间会大大提高</li></ul></li><li><p>性能优化</p><ul><li>集群</li><li>缓存（Redis、CDN）</li><li>异步</li></ul></li></ul><h3 id="伸缩性"><a href="#伸缩性" class="headerlink" title="伸缩性"></a>伸缩性</h3><ul><li>扩容</li><li>无状态的应用服务器可以通过负载均衡器想集群中添加新的节点</li><li>关系型数据库可以用过Sharding实现</li><li>非关系型数据库对伸缩性支持很好</li></ul><h3 id="扩展性"><a href="#扩展性" class="headerlink" title="扩展性"></a>扩展性</h3><ul><li>添加新的功能对现有系统的其他应用无影响</li><li>使用消息队列进行解耦</li><li>分布式服务奖业务可复用的部分模块化</li></ul><h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><ul><li>冗余（多点备份，异地双活）</li><li>故障切换</li><li>服务降级</li><li>监控</li></ul><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><ul><li><p>应对各种攻击手段</p><ul><li>SQL注入</li><li>XSS攻击</li></ul></li></ul><h2 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h2><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><ul><li><p>数据库唯一索引</p><ul><li>没有失效时间，解锁失败会造成死锁</li><li>只能是非阻塞，插入失败无法重试</li><li>不可重入，已获得锁的进程也必须重新获取锁</li></ul></li><li><p>Redis的SETNX指令</p><ul><li>节点挂了就不可用，造成死锁</li></ul></li><li><p>RedLock</p><ul><li>高可用</li></ul></li><li><p>Zookeeper的有序节点</p></li></ul><h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><ul><li><p>两阶段提交（2PC）</p><ul><li><p>准备阶段</p><ul><li>协调者询问所有参与者事务执行的结果</li></ul></li><li><p>提交阶段</p><ul><li>协调者根据所有参与者返回的结果判断最终是提交还是回滚</li></ul></li><li><p>存在问题</p><ul><li>同步阻塞</li><li>单点故障</li><li>数据不一致</li></ul></li></ul></li><li><p>本地消息表</p><ul><li>1. 分布式事务操作方完成写业务数据后向本地消息表发送一个消息，确保这个消息一定会写入本地消息表</li><li><ol start="2"><li>之后将本地消息表中的消息转发到消息队列，转发成功则从本地消息表删除，否则继续重发</li></ol></li><li><ol start="3"><li>分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作</li></ol></li></ul></li></ul><h3 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h3><ul><li><p>分布式系统不可能同时满足</p><ul><li>一致性（Consistency）</li><li>分区容忍性（Partition Tolerance）</li><li>可用性（Availability）</li></ul></li><li><p>权衡</p><ul><li>分区容忍性必不可少，可用性和一致性的权衡</li><li>为了保证一致性，不能访问未同步完成的节点，就失去了部分可用性</li><li>为了保证可用性，允许读取所有节点的数据，但是数据可能不一致</li></ul></li></ul><h3 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h3><ul><li><p>概念</p><ul><li><p>基本可用（Basically Available）</p><ul><li>分布式系统在故障的时候保证核心可用，允许损失部分可用性</li></ul></li><li><p>软状态（Soft State）</p><ul><li>允许系统中的数据存在中间状态，并认为该中间状态不会影响整体可用性</li></ul></li><li><p>最终一致性（Eventually Consistent）</p><ul><li>系统中的所有数据副本在经过一段时间的同步后，最终能达到一致性的状态</li></ul></li></ul></li></ul><h3 id="竞选协议"><a href="#竞选协议" class="headerlink" title="竞选协议"></a>竞选协议</h3><ul><li><p>Paxos</p><ul><li><p>执行过程</p><ul><li><ol><li>Prepare</li></ol></li><li><ol start="2"><li>Accept</li></ol></li><li><ol start="3"><li>Learn</li></ol></li></ul></li><li><p>约束条件</p><ul><li>正确性</li><li>可终止性</li></ul></li></ul></li><li><p>Raft</p></li></ul><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><ul><li><p>算法</p><ul><li><p>轮询</p><ul><li>服务器性能均衡的场景</li></ul></li><li><p>加权轮询</p><ul><li>轮询的基础上根据权重分配</li></ul></li><li><p>最少连接</p><ul><li>将请求发送给当前最少连接的服务器上</li></ul></li><li><p>加权最少连接</p><ul><li>根据权重结算最少连接</li></ul></li><li><p>随机算法</p></li><li><p>源地址哈希</p><ul><li>对客户端IP计算哈希值取模</li></ul></li></ul></li><li><p>转发实现</p><ul><li><p>HTTP重定向</p><ul><li>返回302重新发起请求</li><li>延迟高，处理能力有限</li></ul></li><li><p>DNS域名解析</p><ul><li>解析域名同时使用负载均衡算法计算服务器IP</li><li>优点：能根据地理位置进行域名解析，可以返回最近的服务器</li><li>缺点：DNS多级缓存，当下线机器需要修改DNS记录，生效时间慢</li></ul></li><li><p>反向代理</p><ul><li>Openresty&#x2F;Nginx</li><li>缺点：所有请求和响应都要经过反向代理服务器，容易成为瓶颈</li></ul></li><li><p>网络层</p></li><li><p>链路层</p><ul><li>LVS</li></ul></li></ul></li></ul><h3 id="Session管理"><a href="#Session管理" class="headerlink" title="Session管理"></a>Session管理</h3><ul><li><p>Sticky Session</p></li><li><p>Session Replication</p></li><li><p>Session Server</p><ul><li>Redis、MySQL</li></ul></li></ul><h2 id="攻击技术"><a href="#攻击技术" class="headerlink" title="攻击技术"></a>攻击技术</h2><h3 id="跨站脚本攻击：XSS（Cross-Site-Scripting）"><a href="#跨站脚本攻击：XSS（Cross-Site-Scripting）" class="headerlink" title="跨站脚本攻击：XSS（Cross-Site Scripting）"></a>跨站脚本攻击：XSS（Cross-Site Scripting）</h3><h3 id="跨站请求伪造：CSRF（Cross-Site-request-forgery）"><a href="#跨站请求伪造：CSRF（Cross-Site-request-forgery）" class="headerlink" title="跨站请求伪造：CSRF（Cross-Site request forgery）"></a>跨站请求伪造：CSRF（Cross-Site request forgery）</h3><ul><li>检查Referer头</li><li>添加token校验</li><li>验证码</li></ul><h3 id="SQL注入"><a href="#SQL注入" class="headerlink" title="SQL注入"></a>SQL注入</h3><ul><li>sql quote预处理</li></ul><h3 id="拒绝服务攻击（DoS、DDoS）"><a href="#拒绝服务攻击（DoS、DDoS）" class="headerlink" title="拒绝服务攻击（DoS、DDoS）"></a>拒绝服务攻击（DoS、DDoS）</h3><h2 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><ul><li>将哈希空间看做一个环，每个节点都配置在环上，每个数据对象通过哈希取模得到哈希值后，顺时针向前走，存放在碰到第一个节点上</li></ul><h3 id="分布不均问题"><a href="#分布不均问题" class="headerlink" title="分布不均问题"></a>分布不均问题</h3><ul><li>虚拟节点解决</li></ul><h2 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h2><h2 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h2><h3 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h3><ul><li><p>点对点</p><ul><li>生产者向MQ中发送了一个消息后，只能被一个消费者消费一次</li></ul></li><li><p>发布&#x2F;订阅</p><ul><li>生产者向频道发送了一个消息后，多个消费者可以从该频道订阅这条消息并消费</li></ul></li></ul><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li>异步处理</li><li>流量削峰</li><li>应用解耦</li></ul><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><ul><li><p>发送端可靠性</p><ul><li>本地消息表</li></ul></li><li><p>接收端可靠性</p><ul><li>幂等性</li><li>唯一消息ID</li></ul></li></ul><p><a href="https://github.com/CyC2018/CS-Notes">【参考文章】GitHub-CyC2018&#x2F;CS-Notes</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基础&quot;&gt;&lt;a href=&quot;#基础&quot; class=&quot;headerlink&quot; title=&quot;基础&quot;&gt;&lt;/a&gt;基础&lt;/h2&gt;&lt;h3 id=&quot;性能&quot;&gt;&lt;a href=&quot;#性能&quot; class=&quot;headerlink&quot; title=&quot;性能&quot;&gt;&lt;/a&gt;性能&lt;/h3&gt;&lt;ul&gt;
&lt;</summary>
      
    
    
    
    <category term="分布式系统" scheme="https://harryzhang.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="分布式" scheme="https://harryzhang.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="CAP" scheme="https://harryzhang.cn/tags/CAP/"/>
    
    <category term="BASE" scheme="https://harryzhang.cn/tags/BASE/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 连接错误问题解决</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-%E8%BF%9E%E6%8E%A5%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-%E8%BF%9E%E6%8E%A5%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</id>
    <published>2023-03-25T07:15:48.000Z</published>
    <updated>2023-03-25T07:18:37.329Z</updated>
    
    <content type="html"><![CDATA[<h2 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h2><ul><li>操作系统：Ubuntu16.04-server</li><li>MySQL版本：5.7.25</li></ul><h2 id="故障一"><a href="#故障一" class="headerlink" title="故障一"></a>故障一</h2><p>只能通过localhost登录MySQL</p><ol><li>报错如下<blockquote><p>$mysql -h172.16.0.1 -uroot -p123456<br>mysql: [Warning] Using a password on the command line interface can be insecure.<br>ERROR 1130 (HY000): Host ‘172.16.0.1’ is not allowed to connect to this MySQL server</p></blockquote></li><li>解决方法<br>此处参考自：<a href="https://stackoverflow.com/questions/19101243/error-1130-hy000-host-is-not-allowed-to-connect-to-this-mysql-server">https://stackoverflow.com/questions/19101243/error-1130-hy000-host-is-not-allowed-to-connect-to-this-mysql-server</a></li></ol><ul><li>首先查看你的root用户允许的主机ip<blockquote><p>mysql&gt;SELECT host FROM mysql.user WHERE User &#x3D; ‘root’;<br>+———–+<br>| host      |<br>+———–+<br>| localhost |<br>+———–+<br>1 row in set (0.24 sec)<br>一般结果中只有localhost或同时有localhost和127.0.0.1；</p></blockquote></li><li>然后如果你想指定允许某个ip可访问可执行如下命令<blockquote><p><code>CREATE USER &#39;root&#39;@&#39;ip_address&#39; IDENTIFIED BY &#39;some_pass&#39;;</code><br><code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;ip_address&#39;;</code></p></blockquote></li><li>如果想要允许所有ip执行如下命令<blockquote><p><code>CREATE USER &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;some_pass&#39;;</code><br><code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39;;</code></p></blockquote></li><li>上面两种最后都要flush启用更改<blockquote><p><code> FLUSH PRIVILEGES;</code></p></blockquote></li><li>然后在执行一次查询会发现结果多了一行“%”，说明更改成功<br>+———–+<br>| host      |<br>+———–+<br>| %         |<br>+———–+<br>| localhost |<br>+———–+<br>1 row in set (0.24 sec)<br>再次登录如果仍旧失败，请看故障2</li></ul><h2 id="故障二"><a href="#故障二" class="headerlink" title="故障二"></a>故障二</h2><ol><li>报错如下<blockquote><p>$mysql -h172.16.0.1 -uroot -p123456<br>mysql: [Warning] Using a password on the command line interface can be insecure.<br>ERROR 2003 (HY000): Can’t connect to MySQL server on ‘172.16.0.1’ (111)</p></blockquote></li><li>解决方法</li></ol><ul><li>查看mysql的配置文件<blockquote><p>$vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf</p></blockquote></li><li>将下面一行注释或者修改<blockquote><p><code>注释</code><br><code>#bind-address            = 127.0.0.1</code><br><code>修改</code><br><code>bind-address            = 0.0.0.0</code></p></blockquote></li><li>重启mysql启用更改<blockquote><p>$service mysql restart</p></blockquote></li></ul><p>再次尝试登录即可成功登录！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;软件环境&quot;&gt;&lt;a href=&quot;#软件环境&quot; class=&quot;headerlink&quot; title=&quot;软件环境&quot;&gt;&lt;/a&gt;软件环境&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;操作系统：Ubuntu16.04-server&lt;/li&gt;
&lt;li&gt;MySQL版本：5.7.25&lt;/li&gt;
&lt;/u</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL ORDER BY 如何实现排序的?</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-ORDER-BY-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%8E%92%E5%BA%8F%E7%9A%84/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-ORDER-BY-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%8E%92%E5%BA%8F%E7%9A%84/</id>
    <published>2023-03-25T07:12:42.000Z</published>
    <updated>2023-03-25T07:18:17.890Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MySQL是如何进行排序的？"><a href="#MySQL是如何进行排序的？" class="headerlink" title="MySQL是如何进行排序的？"></a>MySQL是如何进行排序的？</h2><p>假设有一个表t结构如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-c7aec6166a2d984f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-c7aec6166a2d984f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>id为主键，type上建有索引，那么如果要查类型为1，val最小的1000行，那么SQL语句如下：<br><code>SELECT type, val, detail FROM t WHERE type = 1 ORDER BY val LIMIT 1000;</code></p><h3 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h3><p>对上述查询执行explain结果如下：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-b14d9da637a8123d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-b14d9da637a8123d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Using filesort表示需要排序，MySQL会给每个线程分配一块内存用来排序，称为sort buffer，具体的流程如下：</p><ol><li>初始化sort buffer，确定放入type，val，detail三个字段</li><li>从索引type中找到第一个满足type&#x3D;1条件的主键id</li><li>根据id回主键索引查询type和val的值存入sort buffer中，从索引type中继续取下一个id</li><li>重复3的操作直到type不满足条件</li><li>对sort buffer中的数据按照val字段做快速排序</li><li>按照排序结果取前1000行返回</li></ol><p>如果sort buffer够存下所有需要排序的记录，排序在内存中完成，如果内存放不下则需要借助磁盘临时文件进行外部排序。</p><h3 id="rowid排序"><a href="#rowid排序" class="headerlink" title="rowid排序"></a>rowid排序</h3><p>全字段排序过程里只对原表扫描的一遍，剩下的操作都是在sort buffer 和临时文件中执行的，但是如果要查询的字段比较多，sort buffer能存的行数就很少，需要分成多个临时文件进行外部排序，性能比较差，所以在单行数大的情况下这种方式明显不合适。</p><p>MySQL的参数<code>max_length_for_sort_data</code>表示如果单行记录长度超过这个值，就认为单行太大，要换一种排序算法，排序过程中只放要排序的列和主键id，执行流程如下：</p><ol><li>初始化sort buffer，放入val，id字段</li><li>从索引type中找到第一个满足type&#x3D;1条件的主键id</li><li>根据id回主键索引查询val的值，将val和id存入sort buffer中，从索引type中继续取下一个id</li><li>重复3的操作直到type不满足条件</li><li>对sort buffer中的数据按照val字段做快速排序</li><li>按照排序结果依次取1000行，并按照id值回表取出type，val，detail三个字段返回</li></ol><p>可以看到改流程与全字段排序的主要区别在于：</p><ul><li>第1步放入sort buffer的字段不同，rowid排序只放入排序字段和id，全字段排序放入查询的全部字段</li><li>第6步，rowid排序完成后要再回主键索引查一次全部数据返回，全字段排序因为所以要返回的字段内容都在sort buffer中了所以直接返回</li></ul><p><strong>说明</strong>：结果集只是一个逻辑概念，实际上MySQL从排序后的sort buffer中依次取出id，然后到原表查询所有字段的结果不需要在服务端再消耗内存保存，是直接返回的。</p><h3 id="联合索引避免排序"><a href="#联合索引避免排序" class="headerlink" title="联合索引避免排序"></a>联合索引避免排序</h3><p>上面两种方法都是需要建临时表进行排序的，对于MySQL来说都是成本比较高的操作。但并不是所有order by都是需要排序的，因为MySQL索引是天然有序的，如果在type和val字段创建一个联合索引idx_type_val，那么该查询就不需要排序了，这时执行过程就变成了如下流程：</p><ol><li>在索引idx_type_val上找到第一个满足type&#x3D;1条件记录</li><li>根据索引上的主键id回主键索引查询所有字段的值返回，在idx_type_val索引上继续取一下个值</li><li>重复2的操作直到不满足type&#x3D;1或者超过1000行结束。</li></ol><p>使用联合索引，首先不在需要建临时表做排序，其次也不需要扫描出满足type&#x3D;1条件的所有记录，因为索引有序直接扫描前1000行就结束了，大大减少了扫描的行数。</p><h2 id="优先队列排序"><a href="#优先队列排序" class="headerlink" title="优先队列排序"></a>优先队列排序</h2><p>对于MySQL来说并不是所有的排序都是用快速排序实现的，假如之前的查询变成了如下：<br><code>EXPLAIN SELECT type, val FROM t WHERE type = 1 ORDER BY val LIMIT 3;</code><br>假设type&#x3D;1的记录有1万条，只需要去前val最小的前三行。</p><p>对于这种情况，即使sort buffer不能放下1万行记录，会发现MySQL也没有使用到临时文件，这时因为选择了另一种算法：优先队列算法。</p><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ol><li>对于这10000准备排序的记录，先取前三行构造一个最大堆</li><li>取下一行Next记录跟当前堆顶记录Top比较，如果Next.val &lt; Top.val，就把堆顶记录弹出，将Next记录放入堆</li><li>重复2的操作直到取出所有10000行记录，最后堆中的三个记录就是最小的三个</li></ol><h4 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h4><p>快速排序时间复杂度是<code>O(N*logN)</code>，优先队列排序时间复杂度为<code>O((N-K)*logK)</code>，K表示堆的大小，即返回记录的个数，对于该场景下为<code>(N-3)*log3</code>，基本可以看做线性时间复杂度，如果是limit 1的时候就相当于求最小值，该算法就是线性时间复杂度。<br>其次sort buffer中只需要维护堆，内存的消耗也大大减少，空间复杂度为<code>O(K)</code>。</p><h2 id="order-by-rand"><a href="#order-by-rand" class="headerlink" title="order by rand()"></a>order by rand()</h2><p>如果需要随机选1个数，SQL语句可能如下：<br><code>SELECT * FROM t ORDER BY RAND() LIMIT 1</code><br>需要注意到是这种方式会建临时表进行排序，临时表除了查询字段会多加一个排序字段存放rand()生成的值，即对每一行记录使用rand()函数生成一个随机数，然后根据这个数来排序。</p><p>这种写法的成本是比较高的，所以建议尽量避免这种写法，建议先随机一个0~N-1的值（N表示表总行数），然后去查数据库的某行，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">rand1</span>():</span><br><span class="line">    N = mysql.query(<span class="string">&quot;select count(*) from t&quot;</span>)</span><br><span class="line">    res = mysql.query(<span class="string">&quot;select * from t limit N, 1&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【极客时间】<a href="https://time.geekbang.org/column/article/73479">MySQL实战45讲：16、17</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;MySQL是如何进行排序的？&quot;&gt;&lt;a href=&quot;#MySQL是如何进行排序的？&quot; class=&quot;headerlink&quot; title=&quot;MySQL是如何进行排序的？&quot;&gt;&lt;/a&gt;MySQL是如何进行排序的？&lt;/h2&gt;&lt;p&gt;假设有一个表t结构如下图所示：&lt;br&gt;&lt;im</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
    <category term="排序" scheme="https://harryzhang.cn/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 脏页刷盘</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-%E8%84%8F%E9%A1%B5%E5%88%B7%E7%9B%98/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-%E8%84%8F%E9%A1%B5%E5%88%B7%E7%9B%98/</id>
    <published>2023-03-25T07:12:03.000Z</published>
    <updated>2023-03-25T07:18:02.317Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是脏页？"><a href="#什么是脏页？" class="headerlink" title="什么是脏页？"></a>什么是脏页？</h2><p>InnoDB在处理更新语句时，先写内存再写redo log，并不会立即将数据页的更新落地到磁盘（WAL机制），这就会产生升内存数据页和磁盘数据页的数据不一致的情况，这种数据不一致的数据页称为<strong>脏页</strong>，当脏页写入到磁盘（这个操作称为flush）后，数据一致后称为干净页。</p><h2 id="什么时候会flush脏页？"><a href="#什么时候会flush脏页？" class="headerlink" title="什么时候会flush脏页？"></a>什么时候会flush脏页？</h2><ol><li><p>redo log写满<br>redo log大小是固定的，写完后会循环覆盖写入。当有新的内容要写入时，系统必须停止所有的更新操作，将checkpoint向前推进到新的位置，但是在推进之前必须将覆盖部分的所有脏页都flush到磁盘上。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-05061327e5e6e8fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-05061327e5e6e8fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></li><li><p>内存不足需要淘汰数据页<br>当系统内存不足，又有新的数据页要更新，就需要淘汰一些数据页，如果淘汰的是脏页，就需要flush到磁盘（如果是干净页就直接释放出来复用）。</p></li><li><p>系统空闲的时候后台会定期flush适量的脏页到磁盘</p></li><li><p>MySQL正常关闭（shut down）时会把所有脏页都flush到磁盘</p></li></ol><h2 id="flush对系统性能的影响"><a href="#flush对系统性能的影响" class="headerlink" title="flush对系统性能的影响"></a>flush对系统性能的影响</h2><p>第3种是系统空闲不会有性能问题，第4种是要关闭了不考虑性能问题。第1和2的情况flush脏页会产生系统性能问题。</p><h3 id="redo-log写满"><a href="#redo-log写满" class="headerlink" title="redo log写满"></a>redo log写满</h3><p>此时整个系统不能再更新了，更新数会降为0，所以这种情况要尽量避免。</p><h3 id="内存不够"><a href="#内存不够" class="headerlink" title="内存不够"></a>内存不够</h3><p>InnoDB缓冲池（buffer pool）中的内存页有三种状态：</p><ul><li>未使用的空闲内存</li><li>使用了为脏页</li><li>使用了未干净页</li></ul><p>当一个SQL语句要淘汰的脏页数量太多，会导致语句执行的响应时间显著边长。</p><h2 id="flush速度控制策略"><a href="#flush速度控制策略" class="headerlink" title="flush速度控制策略"></a>flush速度控制策略</h2><p>InnoDB为了避免出现上述两种情况，需要有控制脏页比例的策略，控制的主要参考因素就是：脏页比例和redo log写盘速度。</p><h4 id="磁盘的IO能力"><a href="#磁盘的IO能力" class="headerlink" title="磁盘的IO能力"></a>磁盘的IO能力</h4><p>需要告诉InnoDB的磁盘读写能力（IOPS）让引擎全力flush脏页，磁盘的IOPS可以通过fio工具测试。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest </span><br></pre></td></tr></table></figure><p>如果<code>innodb_io_capacity</code>参数设置的不合理，比如远远低于磁盘实际的IOPS，InnoDB会认为IO性能低，刷脏页速度会很慢，甚至低于脏页的生成速度，导致脏页累计影响查询和更新性能。</p><h4 id="速度计算流程"><a href="#速度计算流程" class="headerlink" title="速度计算流程"></a>速度计算流程</h4><p>为了兼顾正常的业务请求，InnoDB引擎控制按照磁盘IOPS的百分比来刷脏页，具体流程如下：</p><ol><li>参数<code>innodb_max_dirty_pages_pct</code>控制脏页比例上限，默认75%。InnoDB根据当前脏页比例（设为M），计算出一个0~100的数字F1(M)，伪代码如下<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">F1</span>(<span class="params">M</span>):</span><br><span class="line">    <span class="keyword">if</span> M &gt;= innodb_max_dirty_pages_pct:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">100</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">100</span> * M / innodb_max_dirty_pages_pct</span><br></pre></td></tr></table></figure></li><li>InnoDB每次写入的日志都有一个序号，当前写入的序号跟checkpoint对应的需要之间的差值设为N，根据N计算出一个0~100的数值F2(N)，N越大F2(N)越大</li><li>根据前两步计算出的两个值取较大值记为R，然后InnoDB会根据<code>innodb_io_capacity</code>设置的磁盘IOPS能力乘以R%来控制刷脏页的速度</li></ol><p>脏页比例计算:<br><code>Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total</code><br>SQL语句如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> VARIABLE_VALUE <span class="keyword">into</span> <span class="variable">@a</span> <span class="keyword">from</span> global_status <span class="keyword">where</span> VARIABLE_NAME <span class="operator">=</span> <span class="string">&#x27;Innodb_buffer_pool_pages_dirty&#x27;</span>;</span><br><span class="line"><span class="keyword">select</span> VARIABLE_VALUE <span class="keyword">into</span> <span class="variable">@b</span> <span class="keyword">from</span> global_status <span class="keyword">where</span> VARIABLE_NAME <span class="operator">=</span> <span class="string">&#x27;Innodb_buffer_pool_pages_total&#x27;</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="variable">@a</span><span class="operator">/</span><span class="variable">@b</span>;</span><br></pre></td></tr></table></figure><h2 id="连锁flush"><a href="#连锁flush" class="headerlink" title="连锁flush"></a>连锁flush</h2><p>在准备flush一个脏页时，如果相邻的数据页也是脏页，会把这个脏页一起flush，而且对这个新的脏页还可能有相邻的脏页导致连锁flush。<br>InnoDB使用<code>innodb_flush_neighbors</code>参数控制这个行为，值为1会产生上述连锁flush的情况，值为0则不会找相邻页。</p><p>找相邻页flush的机制虽然可以减少很多随机IO，但会增加一次flush时间，导致flush时的SQL语句执行时间变慢。</p><p>现在基本都使用的SSD这种IOPS比较高的硬盘，建议将<code>innodb_flush_neighbors</code>参数设为0，提高flush的速度。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>flush会占用IO资源影响了正在执行的SQL语句，本来正常情况下执行很快的一条语句，突然耗时大大增加，造成业务抖动。要尽量避免这种情况，需要合理的设置<code>innodb_io_capacity</code>的值，并且多关注脏页比例，不要让脏页比例经常接近75%。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>【极客时间】<a href="https://time.geekbang.org/column/article/71806">MySQL实战45讲：第12节</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是脏页？&quot;&gt;&lt;a href=&quot;#什么是脏页？&quot; class=&quot;headerlink&quot; title=&quot;什么是脏页？&quot;&gt;&lt;/a&gt;什么是脏页？&lt;/h2&gt;&lt;p&gt;InnoDB在处理更新语句时，先写内存再写redo log，并不会立即将数据页的更新落地到磁盘（WAL机制）</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
    <category term="脏页" scheme="https://harryzhang.cn/tags/%E8%84%8F%E9%A1%B5/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 索引原理详解</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/</id>
    <published>2023-03-25T07:11:48.000Z</published>
    <updated>2023-03-25T07:17:49.471Z</updated>
    
    <content type="html"><![CDATA[<h2 id="索引的底层实现"><a href="#索引的底层实现" class="headerlink" title="索引的底层实现"></a>索引的底层实现</h2><p>InnoDB存储引擎数据结构使用B+树</p><h3 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h3><p>B+数据的基本结构如下图<br><img src="https://upload-images.jianshu.io/upload_images/14151453-8fa2fd1bbc4b7f13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-8fa2fd1bbc4b7f13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="为什么选用B-树"><a href="#为什么选用B-树" class="headerlink" title="为什么选用B+树"></a>为什么选用B+树</h3><p>MySQL为什么要选B+树作为存储结构呢，与B树相比有哪些优点？</p><p><strong>1. 减少磁盘访问，提高查询效率</strong><br>B+树非叶子节点上是不存数据的，仅存键值，而B树节点中不仅存储键值，也会存储数据。因为数据页的大小是固定的（InnoDB中页的默认大小是16KB），如果不存储数据，那么就会存储更多的键值，相应的树的阶数N就会更大，树高就会越低，这样查询数据进行磁盘IO的次数就会大大减少，数据查询的效率也会更快。<br>以InnoDB的一个整数字段索引为例，阶数N大概是1200，这棵树高是4的时候，就可以存1200^3（约17亿）个值，因为根节点总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。</p><p><strong>2. 提高范围查找效率</strong><br>因为B+树的所有数据均存储在叶子节点，而且是有序的，使得B+树范围查找，排序查找，分组查找以及去重查找变的简单，而B树的数据分散在各个节点上，实现起来比较困难。</p><h2 id="普通索引和唯一索引如何选择？"><a href="#普通索引和唯一索引如何选择？" class="headerlink" title="普通索引和唯一索引如何选择？"></a>普通索引和唯一索引如何选择？</h2><p>普通索引不需要保证一条记录的唯一性，查询和更新操作都不需要保证数据页已经读到内存中，相反唯一索引为了保证唯一性，更新时必须要保证数据页在内存中，需要检查是否满足唯一性</p><h3 id="查询操作的区别"><a href="#查询操作的区别" class="headerlink" title="查询操作的区别"></a>查询操作的区别</h3><ul><li>普通索引：查找到满足条件的第一个记录后，需要查找下一条记录，直到碰到不满足的记录</li><li>唯一索引：查找满足条件的第一个记录就会停止检索</li></ul><p>因为是innoDB的读写操作是以数据页为单位的，通常情况目标记录的下一个记录也会在内存中，对于普通索引来说，只是多了一次判断操作，这个CPU成本可以忽略不计，如果是目标记录恰好在某页的最后，下一条记录需要从磁盘中读取，这个I\O成本会大一些，但是这种情况出现的概率很低。<br>所以对于查询操作来说，唯一索引更快，但是性能差异非常小。</p><h3 id="更新操作的区别"><a href="#更新操作的区别" class="headerlink" title="更新操作的区别"></a>更新操作的区别</h3><h4 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change buffer"></a>change buffer</h4><p>当更新一个数据页时，如果数据页在内存中就直接更新，如果数据页还没有在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存再change buffer中，这样就不用从磁盘中读入数据了，大大提高了更新操作的性能。InnoDB会在下次访问这个数据页的时候将数据页读入内存然后执行change buffer中与这个页有关的操作，保证数据的最终一致性。</p><p><strong>change buffer</strong>是可持久化的数据，也会被写到磁盘中，写入change buffer操作也会记录在redo log中。</p><p><strong>merge</strong>：将change buffer中的操作应用到原数据页的过程称为merge，merge除了在查询操作时会触发，系统后台有线程会定期merge，数据库正常关闭（shut down）时也会执行merge操作。</p><p><strong>优点</strong>：</p><ul><li>减少读磁盘，明显提升更新操作的速度</li><li>数据读入内存会占用buffer pool，可以减少内存使用，提高内存利用率</li></ul><p><strong>使用条件</strong>：</p><ul><li>唯一索引的更新操作需要判断唯一性约束，必须将数据读到内存中才能判断，因此唯一索引的更换不能使用</li><li>只有普通索引可使用</li><li>change buffer使用的是buffer pool中的内存，因此不能过大。</li></ul><p><strong>应用场景</strong>：</p><ul><li>写多读少的业务，如账单、日志类的系统</li></ul><p>如果业务更新后马上会做查询，那么merge的操作会被触发，这样随机访问磁盘的次数不会减少还增加了change buffer的维护代价，反而起到了反作用。</p><h3 id="索引的选择"><a href="#索引的选择" class="headerlink" title="索引的选择"></a>索引的选择</h3><ul><li>在业务保证唯一性的前提下，尽量选择普通索引。</li><li>如果更新后面马上伴随这查询，应该关闭change buffer</li></ul><h3 id="change-buffer和redo-log"><a href="#change-buffer和redo-log" class="headerlink" title="change buffer和redo log"></a>change buffer和redo log</h3><p>使用change buffer的更新语句执行的过程：</p><ol><li>如果数据页在内存中，直接更新内存</li><li>如果数据页不在内存中，在change buffer中记录更新操作</li><li>将1或2的动作记录在redo log中</li></ol><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><ul><li>redo log主要是节省随机写磁盘的IO消耗（转为顺序写）</li><li>change buffer主要节省随机读磁盘的IO消耗</li></ul><h2 id="为什么MySQL优化器会选错索引"><a href="#为什么MySQL优化器会选错索引" class="headerlink" title="为什么MySQL优化器会选错索引"></a>为什么MySQL优化器会选错索引</h2><p>优化器选择索引的目的是找一个最优的方案，并用最小的代价去执行语句，扫描行数是影响执行速度的代价之一，扫描行数越少，意味着访问磁盘数据越少，消耗的CPU资源也越少（扫描行数并不是唯一判断标准，还会结合是否使用临时表、是否排序等因素进行综合判断）。<br>在不涉及临时表和排序的情况下，选错索引肯定是在判断扫描行数的时候出错了</p><h3 id="扫描行数如何计算的"><a href="#扫描行数如何计算的" class="headerlink" title="扫描行数如何计算的"></a>扫描行数如何计算的</h3><p>执行语句前MySQL并不能精确的知道这个条件的记录有多少条，只能根据统计信息来估算扫描记录数。</p><h4 id="索引的基数"><a href="#索引的基数" class="headerlink" title="索引的基数"></a>索引的基数</h4><p>一个索引上不同的值越多，这个索引的区分度就越好，而一个索引上不同的值的个数称为基数，基数越大说明区分度越好。</p><h4 id="基数的计算"><a href="#基数的计算" class="headerlink" title="基数的计算"></a>基数的计算</h4><p>MySQL使用采样统计（选择采样而不是全表扫描是为了节省计算成本）：</p><ul><li>InnoDB默认会选择N个数据页，统计这些页面上的不同值得到一个平均值，然后乘以索引的页面数得到基数。</li><li>数据表持续更新的过程中，当变更的数据行占比超过1&#x2F;M的时候，会自动触发做一次索引统计</li></ul><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol><li>当发现explain的结果预估的rows值跟实际差距比较大可以使用<code>analyze table</code>命令解决</li><li>使用<code>force index()</code>强行选择某个索引</li><li>优化SQL语句引导MySQL选择更合适的索引</li><li>新建一个更合适的索引</li></ol><h2 id="字符串前缀索引"><a href="#字符串前缀索引" class="headerlink" title="字符串前缀索引"></a>字符串前缀索引</h2><p>给一个字符串字段上加索引有如下两种选择：</p><ol><li>整个字符串加索引：<code>alter table user add index idx_email(email);</code></li><li>前六个字符索引：<code>alter table user add index idx_email(email(6));</code></li></ol><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>前缀索引的索引结构只保存了前n个字符，索引占用的空间会更小</li><li>使用前缀索引定义合适的长度，即可以节省空间，又不会增加太多查询成本</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>增加了查询额外扫描次数，需要查找到所有前缀匹配的记录，每条记录都要回表查询完整数据进行判断。</li><li>使用前缀索引会破坏覆盖索引（查询字段上都建了索引，不需要回表）对查询性能的优化</li></ul><h3 id="其他方式"><a href="#其他方式" class="headerlink" title="其他方式"></a>其他方式</h3><ul><li>倒序存储加前缀索引：当字符串的前n为重复度高的情况</li><li>hash字段：添加一个hash字段，保存字符串字段的校验码（如crc32）</li></ul><p>这两种方法都不支持范围查找，都会产生额外的cpu计算消耗，hash字段的查询性能更稳定，crc32计算的值冲突概率非常小。</p><h2 id="独立索引"><a href="#独立索引" class="headerlink" title="独立索引"></a>独立索引</h2><p>必须是独立的索引字段才能用到索引，在索引上使用函数、表达式都会导致不能使用索引树搜索，从而导致慢查询。</p><h3 id="CASE1：在索引上使用函数"><a href="#CASE1：在索引上使用函数" class="headerlink" title="CASE1：在索引上使用函数"></a>CASE1：在索引上使用函数</h3><p>建表语句如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `tradelog` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `tradeid` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `operator` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `t_modified` datetime <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  KEY `tradeid` (`tradeid`),</span><br><span class="line">  KEY `t_modified` (`t_modified`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4;</span><br></pre></td></tr></table></figure><p>如果要查询几年内某个月的交易总数，查询语句可能如下：<br><code>select count(*) from tradelog where month(t_modified)=7;</code><br>索引上使用函数可能会导致其失去有序性，从而不能使用树搜索（不代表使用索引，可以在索引上遍历），即使没有改变索引的有序性优化器还是不能用索引快速查找，所以要避免这种写法。</p><h3 id="CASE2：隐式类型转换"><a href="#CASE2：隐式类型转换" class="headerlink" title="CASE2：隐式类型转换"></a>CASE2：隐式类型转换</h3><p>假如有如下语句：<br><code>select * from tradelog where tradeid=110717;</code><br>tradeid字段是varchar类型，如果要和数字作比较会将其转换为数字类型，对于优化器来说上述语句相当于:<br><code>select * from tradelog where  CAST(tradid AS signed int) = 110717;</code><br>可以看到隐式的在索引字段上使用了函数，从而导致不能使用树搜索。</p><h3 id="CASE3：隐式编码转换"><a href="#CASE3：隐式编码转换" class="headerlink" title="CASE3：隐式编码转换"></a>CASE3：隐式编码转换</h3><p>如果在做连表查询是，驱动表和被驱动表的字段编码类型不一致，会导致索引不能使用树搜索。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>【极客时间】<a href="https://time.geekbang.org/column/article/70848">MySQL实战45讲</a>：09、10、11节</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;索引的底层实现&quot;&gt;&lt;a href=&quot;#索引的底层实现&quot; class=&quot;headerlink&quot; title=&quot;索引的底层实现&quot;&gt;&lt;/a&gt;索引的底层实现&lt;/h2&gt;&lt;p&gt;InnoDB存储引擎数据结构使用B+树&lt;/p&gt;
&lt;h3 id=&quot;B-树&quot;&gt;&lt;a href=&quot;#B-树</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
    <category term="索引" scheme="https://harryzhang.cn/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 中一条 SQL 语句是如何执行的？</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-%E4%B8%AD%E4%B8%80%E6%9D%A1-SQL-%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-%E4%B8%AD%E4%B8%80%E6%9D%A1-SQL-%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/</id>
    <published>2023-03-25T07:11:22.000Z</published>
    <updated>2023-03-25T07:18:09.590Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SQL语句执行的经过"><a href="#SQL语句执行的经过" class="headerlink" title="SQL语句执行的经过"></a>SQL语句执行的经过</h2><p>从用户发起请求，到服务接口调用MySQL驱动，MySQL服务器执行完SQL语句返回结果中间发生了什么？首先放一张图来看整个过程使用到的各个组件，然后再对各个过程进行分析。</p><p><img src="https://upload-images.jianshu.io/upload_images/14151453-bfe61aa3f5d1fcad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-bfe61aa3f5d1fcad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="SQL语句执行链路"></p><h3 id="1-连接过程"><a href="#1-连接过程" class="headerlink" title="1. 连接过程"></a>1. 连接过程</h3><p>以Openresty服务器为例，Openresty是多进程+I&#x2F;O多路复用结构（Nginx的I&#x2F;O模型），可以支撑高的并发，一个Worker就是一个进程，一个进程可以处理多条请求。<br>我们知道当需要执行SQL语句时需要先于MySQL服务器建立连接，如果每个一个请求都建立一个连接，使用完再关闭连接，如果频繁的创建和销毁连接显然是不合理的，浪费系统资源造成性能下降，这时连接池就出现了。</p><h4 id="连接池"><a href="#连接池" class="headerlink" title="连接池"></a>连接池</h4><p>连接池会维护多个（长）连接，一个SQL语句执行时分配一个连接，使用完不会销毁连接，而是放到空闲队列中等待下次使用，这样可以在高并发的场景大大减少创建、销毁连接带来的性能问题。</p><h4 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h4><p>类似Web服务器通过连接池维护与数据库服务器的连接，MySQL的连接器提供了同样的功能，也维护了一个连接池，不同的是MySQL连接器同时还有权限验证的功能。</p><ul><li>修改密码不会影响已经建立的链接。</li><li>连接完成后如果没有操作，改连接就会处于空闲状态，可以使用<code>show processlist</code>命令查看，如果长时间没有操作连接器会在到达超时时间后断开它。</li></ul><h4 id="长连接"><a href="#长连接" class="headerlink" title="长连接"></a>长连接</h4><p>长连接是客户端持续有请求，使用的是同一个连接，建立连接的过程通常是比较慢的，建议尽量使用长连接。但是长连接累计较多时可能会导致内存过大（内存管理在连接对象里），比系统强行kill，引起MySQL异常重启，可以使用以下两种方法解决：</p><ul><li>定期断开长连接。</li><li>如果是MySQL5.7及以上的版本，可以在每次执行一个比较大的操作后执行<code>mysql_reset_connection</code>重新初始化连接资源（不会重新建立连接）。</li></ul><h3 id="2-执行过程"><a href="#2-执行过程" class="headerlink" title="2. 执行过程"></a>2. 执行过程</h3><h4 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h4><p>如果是查询语句，而且开启了查询缓存，连接器拿到一个查询请求后，会先查看查询缓存是否有（之前执行过这条语句）。缓存key为sql语句，value是查询结果。</p><ul><li>不建议开启查询缓存，除非是基本不会变的数据表。因为只要对表有更新，该表上的所有查询缓存都会清空，导致查询命中率很低。</li></ul><h4 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h4><p>分析器的功能就是对SQL语句做词法分析和语法分析，解析这条语句要干什么，语法错误会返回错误提醒。</p><h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><p>优化器是在表中有多个索引的时候决定使用哪个索引，或者有多表关联（join）的时候决定各个表的连接顺序。</p><h4 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h4><p>通过分析器知道了要做什么，优化器知道了改怎么做，执行器就是真正的语句执行阶段。开始执行的时候要先判断对表是否有权限（在优化器之前也会做预检查）。执行器会调用存储引擎提供的接口进行读写操作。</p><h3 id="3-更新语句执行过程"><a href="#3-更新语句执行过程" class="headerlink" title="3. 更新语句执行过程"></a>3. 更新语句执行过程</h3><p>查询语句是只读的，比较简单，经过一系列组件最终查询到结果返回。但是更新语句就相对复杂一些，涉及到两个日志模块：redo log和binlog。</p><h4 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a>redo log（重做日志）</h4><p>如果每次更新都要刷盘，整个过程磁盘IO成本、查询成本都比较高，为了提升更新效率，InnoDB引擎提供了redo log（顺序写入速度很快）。</p><p><strong>WAL（Write-Ahead Logging）</strong>：先写日志，再写磁盘。当有一条记录需要更新的时候，InnoDB引擎会先将记录写入redo log并更新内存，这时候更新就算完成了，再需要的时候再将这个操作更新到磁盘里。</p><p><strong>日志结构</strong>：redo log大小是固定的，比如配置一组4个文件，每个文件1G，<br>就可以记录总共4G的记录。从头开始写，写完后又回到开头循环写入。</p><p><strong>crash-safe</strong>：故障安全，redo log除了能提高更新操作的效率，同时还保证了故障安全，在数据库异常时不会导致数据丢失。</p><h4 id="binlog（归档日志）"><a href="#binlog（归档日志）" class="headerlink" title="binlog（归档日志）"></a>binlog（归档日志）</h4><p>MySQL最开始没有InnoDB引擎，binlog日志只用于归档和复制，只依靠binlog没有crash-safe能力。</p><ul><li>redo log是InnoDB引擎独有的，属于存储层；binlog是MySQL提供的，属于server层</li><li>redo log是物理日志，记录在某个数据页上做了什么修改；binlog是逻辑日志，记录SQL语句的原始逻辑</li><li>redo log是循环写的，空间固定，用完会从头开始写；binlog是追加写的，一定大小后切换到下一个文件，不会覆盖</li></ul><h4 id="Buffer-Pool缓冲池"><a href="#Buffer-Pool缓冲池" class="headerlink" title="Buffer Pool缓冲池"></a>Buffer Pool缓冲池</h4><p>InnoDB重要的内存结构，数据的操作都是在Buffer Pool中操作的，如果数据不在缓冲内存中，会先从磁盘中读取到数据页到缓冲池，然后再执行相关操作。</p><h4 id="update执行过程"><a href="#update执行过程" class="headerlink" title="update执行过程"></a>update执行过程</h4><p><code>update T set k = k + 2 where id = &#39;1&#39; limit 1</code></p><ol><li>执行器调引擎读接口找id&#x3D;2这一行，如果数据页本来在内存就直接返回，否则先从磁盘load到内存中再返回。</li><li>然后执行器将k值加上2，得到新的一行数据，在调用引擎的写接口写入这行新数据。</li><li>引擎将这行数据更新到内存中，同时将更新操作记录到redo log，此时redo log处于prepare状态，然后告知执行器执行完成，可以提交事务。</li><li>执行器生成这个操作的binlog并写入磁盘。</li><li>执行器调用存储引擎的事务提交接口，引擎把刚写入redo log改为commit状态，更新完成。</li></ol><h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h2><p>保证了crash-safe能力，如果不使用两阶段提交，使用binlog恢复数据库时会导致与原数据库状态不一致。</p><p>假如不使用两阶段提交，在写日志时机器发生故障：</p><ol><li>redo log写入（比如k，本来为0，执行更新后<br>k &#x3D; 2）后发生故障，binlog未写入。由于redo log写完之后即使系统崩溃，也会能将数据恢复，恢复后这一行数据k&#x3D;2。但是binlog没写完就crash，binlog没有记录这条语句，如果使用binlog来恢复时会少一个事务，恢复后的k&#x3D;0，原数据库k&#x3D;2。</li><li>binlog写入后发生故障，redo log未写入。redo log为写入，崩溃后这个事务无效，k&#x3D;0。但是binlog已经记录了更新语句，之后恢复时会多出一个事务，恢复后k&#x3D;2，原数据库k&#x3D;0。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>MySQL连接器使用连接池维护连接，并进行检查权限，接收一个SQL语句</li><li>然后通过分析器、优化器知道如何执行SQL语句</li><li>通过执行器与存储引擎交互，完成数据的读写。</li><li>数据更新同时会写入两个重要的日志文件：redo log和binlog，并通过两阶段提交保证了crash-safe能力。</li></ol><p><strong>参考资料</strong><br><a href="https://mp.weixin.qq.com/s/J_ng048H4eHBm_4VBjFiWw">【码农有道】详解一条 SQL 的执行过程</a><br><a href="https://time.geekbang.org/column/article/68319">【极客时间】MySQL实战45讲01、02讲</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;SQL语句执行的经过&quot;&gt;&lt;a href=&quot;#SQL语句执行的经过&quot; class=&quot;headerlink&quot; title=&quot;SQL语句执行的经过&quot;&gt;&lt;/a&gt;SQL语句执行的经过&lt;/h2&gt;&lt;p&gt;从用户发起请求，到服务接口调用MySQL驱动，MySQL服务器执行完SQL语</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
    <category term="SQL语句" scheme="https://harryzhang.cn/tags/SQL%E8%AF%AD%E5%8F%A5/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 和 NoSQL基础知识概述</title>
    <link href="https://harryzhang.cn/2023/03/25/MySQL-%E5%92%8C-NoSQL%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/"/>
    <id>https://harryzhang.cn/2023/03/25/MySQL-%E5%92%8C-NoSQL%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/</id>
    <published>2023-03-25T07:10:58.000Z</published>
    <updated>2023-03-25T07:18:51.284Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ul><li><p>B+Tree</p><ul><li><p>平衡树，查找树，所有叶子节点位于同一层</p></li><li><p>进行查找时首先再根节点进行二分查找，找到一个key所在的指针，然后递归的在指针所指向的节点进行查找，直到查到叶子节点，然后在叶子节点二分查找，找出key所对应的data</p></li><li><p>插入删除操作会破坏数的平衡性，需要进行分裂、合并、旋转等操作来维护平衡性</p></li><li><p>与红黑树相比</p><ul><li>B+树的高度更低</li><li>更适合磁盘访问，节点大小设置和磁盘页大小一致</li><li>磁盘预读，减少I&#x2F;O</li></ul></li></ul></li><li><p>MySQL索引</p><ul><li><p>索引类型</p><ul><li><p>B+Tree索引</p><ul><li><p>大多数MySQL存储引擎的默认索引类型</p></li><li><p>有序性保证查找、排序、分组效率更高</p></li><li><p>可以指定多个列为索引列，多个索引列共同组成键</p></li><li><p>适用于全键值、键值范围和键前缀（只支持最左前缀）查找</p></li><li><p>主索引和辅助索引</p><ul><li>主索引的叶子节点data域记录着完整的数据记录，称为聚簇索引，一个表只能有一个聚簇索引</li><li>辅助索引的叶子节点域记录着主键的值，因此使用辅助索引要先查到主键的值，再到主索引查数据</li></ul></li></ul></li><li><p>哈希索引</p><ul><li><p>O(1)查找，但失去了有序性</p><ul><li>无法用于排序和分组</li><li>只支持精确查找，不能用于部分查找和范围查找</li></ul></li><li><p>InnoDB自适应哈希索引，当某个索引值被使用的非常频繁时，会在B+Tree索引只上再建一个哈希索引，以实现快速的哈希查找</p></li></ul></li><li><p>全文索引</p><ul><li>查找文本中的关键字而不是等值比较</li></ul></li><li><p>空间数据索引</p></li></ul></li><li><p>索引优化</p><ul><li><p>独立的列：索引列不能是表达式的一部分，也不能是函数的参数，否则不会使用索引</p></li><li><p>多列索引：需要使用多个列作为条件查询时，使用多列索引比使用单列索引性能更好</p></li><li><p>索引列的顺序：选择性强的索引列放在前面</p></li><li><p>前缀索引：对于BLOB、TEXT、VARCHAR类型的数据，必须使用前缀索引，只索引开始的部分字符</p></li><li><p>覆盖索引：索引包含所有需要查询的字段的值</p><ul><li>索引通常远小于数据行的大小，只读取索引能减少数据访问量</li><li>一些存储引擎（MyISAM）在内存中只缓存索引，只访问索引可以不使用系统调用</li><li>对于InnoDB引擎，若辅助索引能够覆盖查询，则无需访问主索引</li></ul></li></ul></li><li><p>优点</p><ul><li>大大减少需要扫描的数据行数</li><li>帮助服务器避免进行排序和分组，以及避免创建临时表</li><li>将随机I&#x2F;O变为顺序I&#x2F;O</li></ul></li><li><p>使用条件</p><ul><li><p>对于非常小的表大部分情况下全表扫描更高效（如用来保存配置信息的表）</p></li><li><p>对于中型大型的表，使用索引的效果非常明显</p></li><li><p>对于特大型的表，建立和维护索引的代价会随之增长</p><ul><li>分区</li><li>分库分表</li></ul></li></ul></li></ul></li></ul><h3 id="查询性能优化"><a href="#查询性能优化" class="headerlink" title="查询性能优化"></a>查询性能优化</h3><ul><li><p>使用Explain进行分析</p><ul><li>Select_type：查询类型，如简单查询，联合查询、子查询</li><li>key：使用的索引</li><li>Rows：扫描的行数</li></ul></li><li><p>优化数据访问</p><ul><li><p>减少请求的数据量</p><ul><li>只返回必要的列，拒绝无脑select * from…</li><li>只返回必要的行，使用limit限制返回的数据数量</li><li>缓存重复查询的数据</li></ul></li><li><p>减少扫描的行数</p><ul><li>用索引覆盖查询</li></ul></li></ul></li><li><p>重构查询方式</p><ul><li>切分大查询</li><li>分解大连接查询（将一个大连接查询分解成对每个表进行</li></ul></li></ul><p>一次单表查询，然后在应用程序中进行关联）<br>      - 让缓存更高效，分解后多个查询，即使一个表发生改变，其他表的缓存仍然可以使用<br>      - 单表查询的结果可能被其他查询用到，减少冗余记录的查询<br>      - 减少锁竞争<br>      - 应用层进行连接，更容易对数据库进行拆分，从而更容易做到高性能和可伸缩<br>      - 查询本身效率提升</p><h3 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h3><ul><li><p>InnoDB</p><ul><li>MySQL默认的事务型存储引擎</li><li>实现了四个标准的事务隔离级别</li><li>主索引是聚簇索引，在索引中保存了数据，对查询性能很大提升</li><li>内部做了优化，比如磁盘读取数据时采用可预测性读，自动创建自适应哈希索引，能加快插入操作的插入缓冲区</li><li>支持真正的在线热备份</li></ul></li><li><p>MyISAM</p><ul><li>设计简单，提供了很多特性，如压缩表、空间数据索引</li><li>不支持事务、不支持行级锁</li></ul></li><li><p>如果不是特殊特性需要，建议都使用InnoDB引擎</p></li></ul><h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><ul><li><p>主从复制</p><ul><li><p>binlog线程：负责将主服务器上的数据更改写入二进制日志中</p></li><li><p>I&#x2F;O线程：负责从主服务器上读取binlog，并写入从服务器的中继日志（Relay Log）</p></li><li><p>SQL线程：负责读取中继日志，解析出SQL更改并在从服务器中重放（Replay）</p></li><li><p>主从复制不是强一致性，只能保证最终一致性</p></li><li><p>复制模式</p><ul><li><p>异步模式</p><ul><li>主节点不会主动push binlog，同步不及时</li></ul></li><li><p>半同步复制</p><ul><li>主节点只需要接收到一台从节点的返回信息就会commit，否则会等到超时然后切换成异步模式再提交，不保证从节点写入db。减少了数据延迟，响应时间会变长</li></ul></li><li><p>全同步复制</p><ul><li>全同步模式是主节点和从节点全部执行了commit并确认才会想客户端返回成功。响应时间最长</li></ul></li></ul></li></ul></li><li><p>读写分离</p><ul><li><p>优点</p><ul><li>主从服务器负责各自的读写，减少锁竞争</li><li>增加冗余，提高可用性</li></ul></li><li><p>中间件</p><ul><li>MySQL-Proxy</li><li>MySQL-Router</li><li>MyCat</li></ul></li></ul></li></ul><h3 id="binlog的业务应用"><a href="#binlog的业务应用" class="headerlink" title="binlog的业务应用"></a>binlog的业务应用</h3><ul><li><p>数据异构</p><ul><li>随着业务发展，一些表各个业务都关注，但是对字段的使用场景不同。如订单表，可以通过binlog解析成用户维度的订单信息供用户中心查询、商户维度的订单表供运营管理、审计等</li></ul></li><li><p>缓存更新</p><ul><li>客户端更新了数据，缓存还未过期，可以通过binlog获取数据变更，并同步到缓存中</li></ul></li><li><p>任务分发</p><ul><li>多个系统依赖同一块重要数据，当数据发生变化需要通知其他系统。可以由调度系统订阅binlog进行相应的任务分发、消息发送</li></ul></li></ul><h2 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h2><h3 id="not-only-sql"><a href="#not-only-sql" class="headerlink" title="not only sql"></a>not only sql</h3><h3 id="KV型"><a href="#KV型" class="headerlink" title="KV型"></a>KV型</h3><ul><li>Redis</li></ul><h3 id="搜索型"><a href="#搜索型" class="headerlink" title="搜索型"></a>搜索型</h3><ul><li>ElasticSearch</li></ul><h3 id="列式"><a href="#列式" class="headerlink" title="列式"></a>列式</h3><ul><li><p>HBase</p><ul><li>海量数据存储，数据持久化</li><li>读写性能好</li><li>横向扩展再关系型数据库中最方便的之一</li><li>本身没有单点故障，高可用</li><li>可存储结构化或半结构化的数据</li><li>比较重，依赖Hadoop组件，运维成本高</li><li>KV式，条件查询弱</li><li>不支持分页查询</li></ul></li></ul><h3 id="文档型"><a href="#文档型" class="headerlink" title="文档型"></a>文档型</h3><ul><li>MongoDB</li></ul><p><a href="https://github.com/CyC2018/CS-Notes">【参考资料】GitHub-CyC2018&#x2F;CS-Notes</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;MySQL&quot;&gt;&lt;a href=&quot;#MySQL&quot; class=&quot;headerlink&quot; title=&quot;MySQL&quot;&gt;&lt;/a&gt;MySQL&lt;/h2&gt;&lt;h3 id=&quot;索引&quot;&gt;&lt;a href=&quot;#索引&quot; class=&quot;headerlink&quot; title=&quot;索引&quot;&gt;&lt;/a&gt;索</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
    <category term="NoSQL" scheme="https://harryzhang.cn/tags/NoSQL/"/>
    
  </entry>
  
  <entry>
    <title>数据库基础知识概述</title>
    <link href="https://harryzhang.cn/2023/03/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/"/>
    <id>https://harryzhang.cn/2023/03/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/</id>
    <published>2023-03-25T07:10:28.000Z</published>
    <updated>2023-03-25T07:25:00.729Z</updated>
    
    <content type="html"><![CDATA[<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><ul><li><p>ACID</p><ul><li><p>原子性</p></li><li><p>隔离性</p></li><li><p>一致性</p></li><li><p>持久性</p><ul><li>应对系统崩溃，可以用Redo Log恢复</li></ul></li></ul></li><li><p>AUTOCOMMIT：MySQL默认采用自动提交，不显示start transaction，每个查询都会被当成一个事务执行并自动提交</p></li></ul><h3 id="并发一致性问题"><a href="#并发一致性问题" class="headerlink" title="并发一致性问题"></a>并发一致性问题</h3><ul><li><p>丢失修改</p></li><li><p>脏读</p></li><li><p>不可重复读</p></li><li><p>幻读</p><ul><li>insert操作引起</li></ul></li></ul><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><ul><li><p>锁粒度</p><ul><li>行锁</li><li>表锁</li></ul></li><li><p>锁类型</p><ul><li><p>读写锁</p><ul><li>互斥锁（X锁、写锁）</li><li>共享锁（S锁、读锁）</li><li>一个事务对数据A加了X锁，期间其他事务不能对A加任何锁</li></ul></li></ul></li></ul><p>一个事务对数据A加了S锁，其他事务可以对A加S锁，但是不能加X锁</p><pre><code>- 意向锁    - 可以更容易支持多粒度加锁    - IX/IS锁，表示一个事务想要再表中的某个数据行上加X/S锁        - 一个事务再获得某个数据行的S锁之前，必须先获得表的IS锁或更强的锁        - 一个事务在获得某个数据行的X锁之前，必须先获得表的IX锁        - 任意IS/IX锁之间都是兼容的</code></pre><ul><li><p>封锁协议</p><ul><li>一级：事务T要修改A时必须加X锁，直到T结束才释放（解决丢失修改问题）</li><li>二级：在一级基础上事务T要读取A时必须加S锁，读取完立即释放锁（解决脏读问题）</li><li>三级：在二级的基础上，要求读取A时必须加S锁，直到事务结束才释放（解决不可重复读问题）</li><li>两段锁协议：加锁和解锁分两个阶段进行，保证可串行化调度</li></ul></li></ul><h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h3><ul><li>读未提交（RU）</li><li>读提交（RC）</li><li>可重复度（RR）</li><li>可串行化（Serializable）</li></ul><h3 id="多版本并发控制（MVCC）"><a href="#多版本并发控制（MVCC）" class="headerlink" title="多版本并发控制（MVCC）"></a>多版本并发控制（MVCC）</h3><ul><li><p>版本号</p><ul><li>系统版本号SYS_ID:每开启一个新事务时递增</li><li>事务版本号TRX_ID:事务开启时的系统版本号</li></ul></li><li><p>ReadView</p><ul><li>当前系统未提交的事务列表，以及最大ID和最小ID</li></ul></li><li><p>快照读：SELECT，不需要进行加锁</p></li><li><p>当前读：INSERT、UPDATE、DELETE，需要加锁</p></li><li><p>SELECT时可以显式指定加锁</p><ul><li>select * from table where ? lock in share mode;(S锁)</li><li>select * from table where ? for update;(X锁)</li></ul></li></ul><h3 id="Next-Key-Locks"><a href="#Next-Key-Locks" class="headerlink" title="Next-Key Locks"></a>Next-Key Locks</h3><ul><li>可重复读级别下，使用MVCC+Next-Key Lock可以解决幻读</li><li>Record Locks: 锁定一个记录上的索引</li><li>Gap Locks：锁定索引之间的间隙，但是不包括索引本身</li></ul><h3 id="关系数据库"><a href="#关系数据库" class="headerlink" title="关系数据库"></a>关系数据库</h3><ul><li><p>异常</p><ul><li>冗余数据、修改异常、删除异常、插入异常</li></ul></li><li><p>范式</p><ul><li>为了解决异常</li><li>第一范式：属性不可分割</li><li>第二范式：非主属性完全依赖于键码</li><li>第三范式：非主属性不传递函数依赖于键码</li></ul></li></ul><p><a href="https://github.com/CyC2018/CS-Notes">【参考文章】GitHub-CyC2018&#x2F;CS-Notes</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;事务&quot;&gt;&lt;a href=&quot;#事务&quot; class=&quot;headerlink&quot; title=&quot;事务&quot;&gt;&lt;/a&gt;事务&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ACID&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;原子性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;隔离性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;</summary>
      
    
    
    
    <category term="数据库" scheme="https://harryzhang.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="https://harryzhang.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Redis 集群架构</title>
    <link href="https://harryzhang.cn/2023/03/25/Redis-%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84/"/>
    <id>https://harryzhang.cn/2023/03/25/Redis-%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84/</id>
    <published>2023-03-25T07:04:57.000Z</published>
    <updated>2023-03-25T07:07:54.828Z</updated>
    
    <content type="html"><![CDATA[<p>单实例往往不能满足生产环境的需求，需要引入Redis集群，比较常见的Redis集群方案有主从复制、哨兵模式、官网的Redis Cluster，另外还有一些Proxy模式，各大厂商也有自己的方案。</p><h2 id="主从复制模式"><a href="#主从复制模式" class="headerlink" title="主从复制模式"></a>主从复制模式</h2><h4 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h4><p><img src="https://upload-images.jianshu.io/upload_images/14151453-e32695d0c4b0efc5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-e32695d0c4b0efc5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><ol><li>slave向master发送SYNC命令，master接收到命令后通过bgsave保存快照（RDB持久化），并使用缓冲区记录保存快照期间执行的写命令</li><li>master将快照文件发送给slave，继续往缓冲区记录写命令</li><li>slave收到快照文件后载入数据</li><li>master快照发送完成后想slave发送缓冲去的写命令，slave接收命令并执行，完成复制初始化</li><li>此后每次执行一个写命令都会同步发送给slave，保持master于slave之间的数据一致性</li></ol><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>最简单的一种集群方案，本质上写入还是单实例（Master节点），读可以在主节点或从节点，能够实现读写分离。缺点是容量依赖单节点，无法实现分区，不具备自动容错与恢复。</p><h2 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h2><p>为了解决主从复制模式不能自动进行故障恢复的不足，引入特殊的哨兵节点（Sentinel），用来监控Redis节点，在发生故障时选举出领头哨兵，由领头哨兵从所有的Slave节点中选一个作为新的Master节点，完成故障转移。</p><h4 id="基本架构-1"><a href="#基本架构-1" class="headerlink" title="基本架构"></a>基本架构</h4><p><img src="https://upload-images.jianshu.io/upload_images/14151453-85d5f5a9c7b7a142.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-85d5f5a9c7b7a142.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Sentinel内部互相有连接，用于监控其他Sentinel和通信，同时每个Sentinel和每个Redis节点之间有两条连接，一个连接用来发送命令通信，一个连接用来订阅Redis节点的<code>_sentinel_:hello</code>频道和获取监控该节点其他Sentinel的信息。</p><h4 id="工作原理-1"><a href="#工作原理-1" class="headerlink" title="工作原理"></a>工作原理</h4><p>与Master建立连接后，Sentinel会执行以下操作：</p><ol><li>定期向Master和Slave发送INFO命令，发送INFO命令可以获取当前数据库节点信息，如果当前是Master节点，能自动发现Master的Slave节点。</li><li>定期向Master和Slave的<code>_sentinel_:hello</code>频道发送自己的信息</li><li>定期向Master、Slave和其他Sentinel发送PING命令</li></ol><h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><p>如果Sentinel向数据库节点发送的PING命令超时，Sentinel认为其主管下线，如果该节点是主节点，Sentinel会向其他Sentinel发送命令询问他们是否也认为改Master主观下线，如果达到一定数量的投票，Sentinel会认为改Master客观下线，并开启选举领头节点进行故障恢复，选举采用Raft算法：</p><ol><li>认为Master客观下线的Sentinel-1向每个Sentinel发送命令，要求对方选自己为领头哨兵。</li><li>如果目标Sentinel节点没有选过其他人，则会同意选举Sentinel-1为领头哨兵</li><li>如果有超过一半的Sentinel统一Sentinel-1当选领头，则Sentinel-1成为领头。</li><li>如果有多个Sentinel同时竞选，导致一轮投票没有选出领头，则开启下一轮竞选，直到选出领头。</li></ol><p>领头哨兵从故障Master的Slave节点选出一个当选新的Master，选择的规则如下：</p><ol><li>所有在线的Slave选优先级最高的，优先级通过slave-priority配置</li><li>如果有多个高优先级的Slave，则选取复制偏移量最大的（数据最完整的）</li><li>如果以上条件都一样，选取id最小的</li></ol><p>挑选出要升级的Slave后，领头Sentinel向该节点发送命令使其成为Master，然后再向其他Slave发送命令接收新的Master，其他Slave收到命令后向新的Master节点发送命令进行数据同步，将故障的Master更新为新的Master的Slave节点。</p><h4 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h4><p>能够自动故障转移，提高了可用性，但是同样还是存在主从复制模式的难以扩容，受限于Redis单机能力的缺点。</p><h2 id="Redis-Cluster"><a href="#Redis-Cluster" class="headerlink" title="Redis Cluster"></a>Redis Cluster</h2><h4 id="基本架构-2"><a href="#基本架构-2" class="headerlink" title="基本架构"></a>基本架构</h4><p><img src="https://upload-images.jianshu.io/upload_images/14151453-2f8e053a25c9dd4d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-2f8e053a25c9dd4d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Cluster采用无中心架构</p><ol><li>所有Redis节点彼此互联，内部使用二进制协议优化传输速度和带宽</li><li>节点的fail是通过集群中半数以上节点检测失效判定的</li><li>客户端与key所在的Redis节点不需要直连，内部会做重定向；不需要中间代理层，客户端连接集群任意一个节点即可。</li></ol><h4 id="工作原理-2"><a href="#工作原理-2" class="headerlink" title="工作原理"></a>工作原理</h4><ol><li>Redis Cluster引入了槽位slot的概念（取值0-16383），每个节点均分这些slot</li><li>当对某个key操作的时候，Redis会计算key的crc16值，然后对16384取模，这样每个key都会对应一个0-16383范围的哈希槽，根据哈希槽找到负责对应槽位的节点，然后自动跳转到这个槽位上进行存取操作</li><li>为了提高可用性，Cluster同时支持主从复制，每个Master对应一个或多个Slave节点，当主节点宕机的时候启动从节点</li><li>如果一个集群半数以上的Master节点认为某个Master节点疑似下线，那么这个Master将被标记为已下线。</li></ol><p>故障转移的方法和Sentinel模式类似：</p><ol><li>从复制故障Master节点的所有Slave节点选一个作为新的Master</li><li>被选中的Slave节点执行<code>SLAVEOF no one</code>命令，成为新的Master节点</li><li>新的Master节点会撤销所有对已下线Master节点的槽指派，将这些槽指派给自己</li><li>新的Master节点向集群广播一条PONG消息，让集群中的其他节点知道这个节点已经由Slave变成了Master节点，并且已接管了槽位</li><li>新的主节点开始接受和自己负责处理的slot有关的命令请求，故障转移完成。</li></ol><h4 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h4><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ul><li>无中心架构，不存在单点故障</li><li>不需要中间代理，减少依赖</li><li>支持横向扩展，伸缩性更好，能提供的并发能力更高</li><li>能自动故障转移，高可用</li></ul><h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul><li>客户端实现复杂</li><li>数据异步复制，不保证数据强一致性</li><li>Slave作为冷备不提供服务</li><li>批量操作限制</li><li>事务支持有限，只支持多key在同一节点的事务操作</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】书籍：Redis设计与实现<br>【2】 <a href="https://segmentfault.com/a/1190000022028642">一文掌握Redis的三种集群方案</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;单实例往往不能满足生产环境的需求，需要引入Redis集群，比较常见的Redis集群方案有主从复制、哨兵模式、官网的Redis Cluster，另外还有一些Proxy模式，各大厂商也有自己的方案。&lt;/p&gt;
&lt;h2 id=&quot;主从复制模式&quot;&gt;&lt;a href=&quot;#主从复制模式&quot; c</summary>
      
    
    
    
    <category term="缓存" scheme="https://harryzhang.cn/categories/%E7%BC%93%E5%AD%98/"/>
    
    
    <category term="Redis" scheme="https://harryzhang.cn/tags/Redis/"/>
    
    <category term="Redis 集群" scheme="https://harryzhang.cn/tags/Redis-%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Redis 热点 key 问题如何解决?</title>
    <link href="https://harryzhang.cn/2023/03/25/Redis-%E7%83%AD%E7%82%B9-key-%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/"/>
    <id>https://harryzhang.cn/2023/03/25/Redis-%E7%83%AD%E7%82%B9-key-%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/</id>
    <published>2023-03-25T07:04:18.000Z</published>
    <updated>2023-03-25T07:08:22.815Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是热点key？"><a href="#什么是热点key？" class="headerlink" title="什么是热点key？"></a>什么是热点key？</h2><p>对于web应用来说，用户消费的数据远远大于生产的数据，大多人使用都只是进行浏览，少数的人才会进行评论。对于web服务来说，某些热门的内容，读请求的量级可能是非常大的，数据库无法支持这么高并发的请求，基本都会使用Redis集群做缓存，但是如果如果热点数据的请求量过大，导致热点key所在Redis节点无法支撑，这种情况就需要采用额外的措施解决。当然Redis的性能还是非常好的，大多数业务量级都可以撑住，除非业务体量很大。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="服务端缓存"><a href="#服务端缓存" class="headerlink" title="服务端缓存"></a>服务端缓存</h3><p>这种方式就是将热点数据同时缓存在服务器的内存中，增加一级缓存，如果数据在内存缓存中，就直接读，不用去请求Redis。如果数据没有再请求Redis，获取到数据再写入内存缓存中。这样就大大减少了Redis的压力，而且直接读内存的速度会更快。</p><h3 id="备份热点key"><a href="#备份热点key" class="headerlink" title="备份热点key"></a>备份热点key</h3><p>为了不让热点key只请求到某一个redis节点，可以在热点key后面加一个随机数，这样热点数据可能就hash到不同的槽位，从而请求到不同的Redis节点，相当于一个key有了多个不同的备份，分散在多个Redis节点上。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://juejin.cn/post/6844903886667382798">关于Redis热点key的一些思考</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是热点key？&quot;&gt;&lt;a href=&quot;#什么是热点key？&quot; class=&quot;headerlink&quot; title=&quot;什么是热点key？&quot;&gt;&lt;/a&gt;什么是热点key？&lt;/h2&gt;&lt;p&gt;对于web应用来说，用户消费的数据远远大于生产的数据，大多人使用都只是进行浏览，少数</summary>
      
    
    
    
    <category term="缓存" scheme="https://harryzhang.cn/categories/%E7%BC%93%E5%AD%98/"/>
    
    
    <category term="Redis" scheme="https://harryzhang.cn/tags/Redis/"/>
    
    <category term="热点 key" scheme="https://harryzhang.cn/tags/%E7%83%AD%E7%82%B9-key/"/>
    
  </entry>
  
  <entry>
    <title>Redis 基础知识概述</title>
    <link href="https://harryzhang.cn/2023/03/25/Redis-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/"/>
    <id>https://harryzhang.cn/2023/03/25/Redis-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/</id>
    <published>2023-03-25T07:03:37.000Z</published>
    <updated>2023-03-25T07:17:13.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="STRING"><a href="#STRING" class="headerlink" title="STRING"></a>STRING</h3><ul><li>字符串、整数、浮点数</li></ul><h3 id="LIST"><a href="#LIST" class="headerlink" title="LIST"></a>LIST</h3><ul><li>列表</li></ul><h3 id="SET"><a href="#SET" class="headerlink" title="SET"></a>SET</h3><ul><li>集合</li></ul><h3 id="ZSET"><a href="#ZSET" class="headerlink" title="ZSET"></a>ZSET</h3><ul><li>有序集合</li></ul><h3 id="HASH"><a href="#HASH" class="headerlink" title="HASH"></a>HASH</h3><ul><li>哈希表</li></ul><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h3><ul><li>链地址法解决冲突</li><li>rehash、渐进式rehash</li></ul><h3 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a>跳跃表</h3><ul><li><p>基于有序链表建多级索引</p></li><li><p>相比红黑树的优点</p><ul><li>实现起来更简单</li><li>范围查找更快</li><li>支持无锁操作</li></ul></li></ul><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><h3 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h3><ul><li>string可以进行自增自减运算，适合频繁读写的计数器</li></ul><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><h3 id="查找表"><a href="#查找表" class="headerlink" title="查找表"></a>查找表</h3><ul><li>类似缓存，利用快速查找特性。DNS记录</li></ul><h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><ul><li>List类型可以模拟消息队列</li></ul><h3 id="会话缓存"><a href="#会话缓存" class="headerlink" title="会话缓存"></a>会话缓存</h3><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><ul><li><p>RedLock</p><ul><li>多个redis节点，申请锁，当超过N&#x2F;2个节点能获得锁则认为可以获得锁</li><li>互斥：任何时刻只能有一个client获取锁</li><li>避免死锁</li><li>只要大部分redis节点存活就可以正常提供服务</li></ul></li><li><p>SETNX命令自行实现</p></li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>Set可以实现交集、并集实现共同关注等功能</li><li>ZSet有序性实现排行榜</li></ul><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="MUTI、EXEC将多个命令包围"><a href="#MUTI、EXEC将多个命令包围" class="headerlink" title="MUTI、EXEC将多个命令包围"></a>MUTI、EXEC将多个命令包围</h3><h3 id="不支持回滚，当一个命令出错会继续执行剩下的命令"><a href="#不支持回滚，当一个命令出错会继续执行剩下的命令" class="headerlink" title="不支持回滚，当一个命令出错会继续执行剩下的命令"></a>不支持回滚，当一个命令出错会继续执行剩下的命令</h3><h3 id="WATCH命令"><a href="#WATCH命令" class="headerlink" title="WATCH命令"></a>WATCH命令</h3><ul><li>乐观锁，可以监控一个或多个键，一旦被监控的某个键被修改，之后的事务就不会执行</li></ul><h3 id="具有ACID的一致性和隔离性，当appendfsync选项设置为always时也具有持久性"><a href="#具有ACID的一致性和隔离性，当appendfsync选项设置为always时也具有持久性" class="headerlink" title="具有ACID的一致性和隔离性，当appendfsync选项设置为always时也具有持久性"></a>具有ACID的一致性和隔离性，当appendfsync选项设置为always时也具有持久性</h3><h3 id="流水线方式，减少通信次数"><a href="#流水线方式，减少通信次数" class="headerlink" title="流水线方式，减少通信次数"></a>流水线方式，减少通信次数</h3><h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><h3 id="文件事件"><a href="#文件事件" class="headerlink" title="文件事件"></a>文件事件</h3><ul><li>基于Reactor模式开发了自己的网络事件处理器，使用I&#x2F;O多路复用同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会调用对应事件类型的事件处理器</li></ul><h3 id="时间事件"><a href="#时间事件" class="headerlink" title="时间事件"></a>时间事件</h3><ul><li>定时事件</li><li>周期性事件</li></ul><h2 id="集群方案"><a href="#集群方案" class="headerlink" title="集群方案"></a>集群方案</h2><h3 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h3><ul><li><p>Sentinel</p><ul><li>集群监控：定期ping集群中的其他服务器和哨兵，检查是否在线</li><li>消息通知：如果某个redis实例故障，哨兵负责发消息给管理员</li><li>故障转移：如果主节点挂了，会在从节点中选举出新的主节点</li><li>配置中心：发生故障转移后通知客户端新的master地址</li></ul></li><li><p>至少要3个哨兵，保证自身的健壮性</p></li></ul><h3 id="Redis-Cluster"><a href="#Redis-Cluster" class="headerlink" title="Redis-Cluster"></a>Redis-Cluster</h3><ul><li><p>一共分配16383个槽位（slot）</p></li><li><p>方案说明</p><ul><li>通过哈希方式将数据分片，每个节点均分存储一定哈希槽区间的数据</li><li>每份数据分片会存在多个互为主从的多节点上</li><li>数据写入主节点，在同步从节点，同一分片的多个节点间的数据不保持一致性</li><li>读取数据时如果key没有分配在该节点会返回转向指令，指向正确的节点</li><li>每个redis需要额外开放一个加1w的端口来进行节点间通信（gossip协议）</li></ul></li></ul><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>无中心架构，支持动态扩容，对业务透明</li><li>具备Sentinel的监控和自动故障转移能力</li><li>客户端不需要连接所有节点（会自动转向）</li><li>高性能，客户端直连redis服务器，免去proxy代理的损耗</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>运维复杂，数据迁移需要人工干预</li><li>不支持批量操作（pipeline）</li></ul><h2 id="缓存异常"><a href="#缓存异常" class="headerlink" title="缓存异常"></a>缓存异常</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><ul><li><p>大面积缓存失效</p></li><li><p>解决方案</p><ul><li>设置随机的过期时间</li><li>并发不多的时候加锁排队</li></ul></li></ul><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><ul><li><p>缓存和DB都不存在的数据</p></li><li><p>解决方案</p><ul><li>接口层拦截</li><li>设置空缓存，过期时间要短</li><li>布隆过滤器</li></ul></li></ul><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><ul><li><p>缓存中没有，但是并发用户很多</p></li><li><p>解决方案</p><ul><li><p>设置热点数据永不过期</p><ul><li>persist key</li></ul></li><li><p>加互斥锁</p></li><li><p>缓存预热</p></li><li><p>缓存降级</p></li></ul></li></ul><h2 id="对比Memcached"><a href="#对比Memcached" class="headerlink" title="对比Memcached"></a>对比Memcached</h2><h3 id="Memcached"><a href="#Memcached" class="headerlink" title="Memcached"></a>Memcached</h3><ul><li>仅支持字符串类型</li><li>不支持持久化</li><li>不支持分布式</li></ul><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><ul><li>读写性能优异，Read：11w&#x2F;s、Write：8.1w&#x2F;s</li><li>支持RDB和AOF两种持久化方式</li><li>支持事务，具有原子性</li><li>数据结构丰富</li><li>支持主从复制</li></ul><h3 id="Redis缺点"><a href="#Redis缺点" class="headerlink" title="Redis缺点"></a>Redis缺点</h3><ul><li>内存通常比较小且贵，不适用海量数据</li><li>比较难支持在线扩容</li></ul><h2 id="键的过期时间"><a href="#键的过期时间" class="headerlink" title="键的过期时间"></a>键的过期时间</h2><h3 id="每个键设置过期时间，过期后会自动删除"><a href="#每个键设置过期时间，过期后会自动删除" class="headerlink" title="每个键设置过期时间，过期后会自动删除"></a>每个键设置过期时间，过期后会自动删除</h3><h3 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h3><h3 id="定期删除"><a href="#定期删除" class="headerlink" title="定期删除"></a>定期删除</h3><h3 id="定时删除"><a href="#定时删除" class="headerlink" title="定时删除"></a>定时删除</h3><h2 id="数据淘汰策略"><a href="#数据淘汰策略" class="headerlink" title="数据淘汰策略"></a>数据淘汰策略</h2><h3 id="当内存超出容量，会施行淘汰策略"><a href="#当内存超出容量，会施行淘汰策略" class="headerlink" title="当内存超出容量，会施行淘汰策略"></a>当内存超出容量，会施行淘汰策略</h3><h3 id="全局键空间选择性删除"><a href="#全局键空间选择性删除" class="headerlink" title="全局键空间选择性删除"></a>全局键空间选择性删除</h3><ul><li>noevication</li><li>allkeys-lru</li><li>allkeys-random</li></ul><h3 id="设置过期时间的键空间选择性移除"><a href="#设置过期时间的键空间选择性移除" class="headerlink" title="设置过期时间的键空间选择性移除"></a>设置过期时间的键空间选择性移除</h3><ul><li>volatile-lru</li><li>volatile-random</li><li>volatile-ttl</li></ul><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="RDB（默认方式）"><a href="#RDB（默认方式）" class="headerlink" title="RDB（默认方式）"></a>RDB（默认方式）</h3><ul><li><p>数据快照</p></li><li><p>优点</p><ul><li>只有一个dump.rdb文件，方便持久化</li><li>容灾兴好，一个文件可以安全的保存到磁盘</li><li>单独进程处理，不会影响主进程的IO操作</li><li>数据集大时比AOF启动更快</li></ul></li><li><p>缺点</p><ul><li>定期执行持久化操作，故障会丢失数据</li></ul></li></ul><h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><ul><li><p>写命令追加到AOF文件</p><ul><li>always：每个写命令都同步</li><li>everysec：每秒同步一次</li><li>no：让操作系统决定何时同步</li></ul></li><li><p>优点</p><ul><li>数据安全，always模式每进行一次写命令就记录到aof文件一次</li><li>append模式写文件，即使中途宕机可以redis-check-aof工具解决数据一致性问题</li><li>AOF重写机制，减少冗余命令</li></ul></li><li><p>缺点</p><ul><li>文件大，恢复速度慢</li></ul></li></ul><h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><p><code>slaveof  $&#123;host&#125;  $&#123;port&#125;</code></p><h3 id="连接过程"><a href="#连接过程" class="headerlink" title="连接过程"></a>连接过程</h3><ul><li>主服务器创建快照文件（rdb）发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完再向从服务器发送存储在缓冲区的写命令</li><li>从服务器丢弃所有旧数据，载入快照文件，接收主服务器发来的写命令</li><li>主服务器每执行一次写命令，就向所有从服务器发送相同的写命令</li></ul><h3 id="主从链"><a href="#主从链" class="headerlink" title="主从链"></a>主从链</h3><ul><li>从服务器比较多的时候，为了不影响主服务器的性能，可以设置中间层来分担主服务器的复制工作</li></ul><p><a href="https://github.com/CyC2018/CS-Notes">【参考文章】GitHub-CyC2018&#x2F;CS-Notes</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;数据类型&quot;&gt;&lt;a href=&quot;#数据类型&quot; class=&quot;headerlink&quot; title=&quot;数据类型&quot;&gt;&lt;/a&gt;数据类型&lt;/h2&gt;&lt;h3 id=&quot;STRING&quot;&gt;&lt;a href=&quot;#STRING&quot; class=&quot;headerlink&quot; title=&quot;STRIN</summary>
      
    
    
    
    <category term="缓存" scheme="https://harryzhang.cn/categories/%E7%BC%93%E5%AD%98/"/>
    
    
    <category term="Redis" scheme="https://harryzhang.cn/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>TCP是如何实现可靠传输的？</title>
    <link href="https://harryzhang.cn/2023/03/25/TCP%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E7%9A%84%EF%BC%9F/"/>
    <id>https://harryzhang.cn/2023/03/25/TCP%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E7%9A%84%EF%BC%9F/</id>
    <published>2023-03-25T06:43:37.000Z</published>
    <updated>2023-03-25T06:58:47.366Z</updated>
    
    <content type="html"><![CDATA[<p>在计算机网络的经典五层协议中，TCP属于运输层，实现了进程间的通信，保证了数据的可靠传输，属于计算机网络协议族中最重要的协议之一，那么TCP是如何实现可靠数据传输的呢？</p><h2 id="底层实现"><a href="#底层实现" class="headerlink" title="底层实现"></a>底层实现</h2><p>运输层的进程间通信是通过socket实现的，socket是一个抽象的概念，在Linux系统中以文件的形式存在。网络层通过IP来区分主机，运输层则增加了端口的概念来区分进程。TCP协议中使用目标IP、目标端口、源IP、源端口来定义一个socket，只需要在运输层的报文头部附加上这些信息，目标主机就会知道数据要发送那个socket，对应监听该socket的进程就可以收到数据进行处理。</p><h2 id="TCP报文格式"><a href="#TCP报文格式" class="headerlink" title="TCP报文格式"></a>TCP报文格式</h2><p>TCP报文包括首部和数据部分，首部附加了TCP报文的信息，首部长度固定部分为20字节，还有40字节的可选部分，具体如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-cdbb73e6c3f47d3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-cdbb73e6c3f47d3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>其中几个关键字段的作用如下：</p><ul><li>源端口和目的端口：分别16个字节（表示范围0-65535），用来区分主机上的进程</li><li>序号：TCP连接中的每个字节都编一个序号，表示本报文的第一个字节在整个数据包中的偏移位置</li><li>确认号：期望收到对方的下一个报文段的数据的第一个字节的序号</li><li>数据偏移：首部长度，4字节为单位</li><li>标志位<ul><li>ACK：ACK&#x3D;1表示接收发向发送方发的确认报文</li><li>SYN：同步SYN&#x3D;1表示是一个连接请求或连接接受报文</li><li>FIN：FIN&#x3D;1表示发送方已经发送完毕，可以断开连接</li></ul></li><li>窗口：发送方接收缓冲区剩下的字节数</li><li>校验和：检验报文在网络传输过程中是否发生了变化</li><li>选项字段：<ul><li>窗口扩大选项，用于流量控制</li><li>时间戳选项</li><li>选择确认选项，由于接收方收到了不连续的报文，告知发送方目前收到的数据报范围（两个4字节的边界表示）</li></ul></li></ul><h2 id="可靠传输原理"><a href="#可靠传输原理" class="headerlink" title="可靠传输原理"></a>可靠传输原理</h2><p>网络层只管尽可能将数据从一个主机发送到另一个主机，并不保证数据可靠到达，由于网络环境总是不稳定的，可能存在丢包、差错等请求，TCP则通过一系列的机制在运输层保证了数据的可靠传输。<br>网络传输可能发生的异常情况和解决方法：</p><ul><li>丢包：超时重传</li><li>差错：校验码来检验数据正确收到</li></ul><h3 id="停止等待协议"><a href="#停止等待协议" class="headerlink" title="停止等待协议"></a>停止等待协议</h3><p>要实现可靠传输，最简单的方法就是发送方发送一个报文，接收方收到报文后发送确认报文表示我收到了，你可以发下一个了，传输模型如下：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-60467e00e08bd710.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-60467e00e08bd710.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>这种方式保证可靠传输称为停止等待协议，这种方式缺点也很明显，效率非常低。</p><h3 id="连续ARQ协议"><a href="#连续ARQ协议" class="headerlink" title="连续ARQ协议"></a>连续ARQ协议</h3><p>为了提高传输效率，充分利用带宽，发送方会连续的发送数据包，如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-3e2aee42126ae328.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-3e2aee42126ae328.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>客户端不等收到前一个包的确认报文就开始不断的发下一个包，这样可以充分利用网络带宽，提高传输效率，但是于此同时也带来了另外的问题，那么TCP是如何解决这些问题的？</p><h4 id="确认报文冗余"><a href="#确认报文冗余" class="headerlink" title="确认报文冗余"></a>确认报文冗余</h4><p><strong>累计确认</strong>：网络中充斥着大量的发送包和确认回复报文，这些数据只是为了确认报文到达，并不是实际需要传输的数据。是不是一定要每一个报文都要发一个回复确认的报文呢，TCP采用了累计确认的方法：接收方在累计收到了一定量的数据包后发送一个确认报文告诉发送方在此之前的数据包都已经收到了，这样便可以减少确认报文的数量，提高带宽利用率。</p><h4 id="丢包的处理"><a href="#丢包的处理" class="headerlink" title="丢包的处理"></a>丢包的处理</h4><p><strong>GBN（回退n步）</strong>：如果发生丢包的情况，在连续ARQ中，如果接受方收到了123 567个字节，编号为4字节的包丢失了，按照累计确认只能发送3的确认回复，567都要丢掉，因为发送发会进行重传。</p><p><strong>选择确认ACK</strong>：在TCP报文头部的选项字段部分设置已收到的报文，每一段用两个边界来确定，比如上述情况可以用[1,3]和[5,7]来表示，客户端就会根据选项只重传丢失的数据段。</p><h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><p>因为接收方读数据的能力有限，发送发不能一直发送报文直到把缓冲区所有数据发送完，这样会导致接收方无法接收丢弃掉数据包，发送方收不到确认认为超时又会继续重传，产生了大量无用数据的重传。对此情况TCP使用滑动窗口来解决，基本模型如下：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-06581f647ab4c35b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-06581f647ab4c35b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li>发送方根据接受方缓冲区的大小，设置自己可发送窗口大小，处于窗口内的数据表示可以发送，之外的数据不能发送</li><li>当窗口内的未确认数据收到确认回复时，整个窗口往前移动，知道发送完所有数据</li></ul><p>滑动窗口机制实现了TCP的<strong>流量控制</strong>，不至于发送太快导致太多的数据丢弃和重传。</p><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><p>为了避免网络过分拥挤导致丢包严重，传输效率低，TCP实现了拥塞控制机制，拥塞控制的解决办法本质上是流量控制，控制发送方发送的速度，而上文提到流量控制是通过滑动窗口来实现的，所以最终也是通过调整发送方的滑动窗口大小来实现的。</p><p>拥塞控制的几个重要的概念：慢启动、拥塞避免、快恢复、快重传</p><h3 id="Reno算法模型"><a href="#Reno算法模型" class="headerlink" title="Reno算法模型"></a>Reno算法模型</h3><p><img src="https://upload-images.jianshu.io/upload_images/14151453-2ca1f629fb91be2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-2ca1f629fb91be2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><ul><li>慢启动：最开始的时候把窗口设置为较小的值，然后每轮变成两倍（虽然叫慢启动，但其实是指数增长）</li><li>拥塞避免：当窗口大小达到初始阈值ssthresh，每轮窗口大小增加1（试探网络最大的负载能力）</li><li>如果发生了超时，表示极可能发生了拥塞，此时直接执行慢启动，尽可能让网络中的报文先接收，以尽快恢复网络状况。</li><li>快重传：如果收到三个重复的ACK，表示中间有段数据丢包了，发送方无需等待计时器到达超时时间，立即进行重传丢失的报文段。</li><li>快恢复：连续收到了三个重复ACK，说明网络情况还不是很拥堵，此时将窗口初始的阈值减半，然后执行拥塞避免，这个过程称为快恢复。</li></ul><p>Reno算法是比较常见的TCP实现的拥塞控制算法，其他拥塞算法还有Tahoe（已废弃不用）、New Reno等，通过拥塞控制算法可以很大程度避免网络拥挤。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【书籍】计算机网络：自顶向下方法<br>【码农有道】<a href="https://mp.weixin.qq.com/s/B1Qttaejav4UzPn0GNoOHw">这一篇TCP总结请收下</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在计算机网络的经典五层协议中，TCP属于运输层，实现了进程间的通信，保证了数据的可靠传输，属于计算机网络协议族中最重要的协议之一，那么TCP是如何实现可靠数据传输的呢？&lt;/p&gt;
&lt;h2 id=&quot;底层实现&quot;&gt;&lt;a href=&quot;#底层实现&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://harryzhang.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="TCP" scheme="https://harryzhang.cn/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>HTTPS原理详解</title>
    <link href="https://harryzhang.cn/2023/03/25/HTTPS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"/>
    <id>https://harryzhang.cn/2023/03/25/HTTPS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/</id>
    <published>2023-03-25T06:43:24.000Z</published>
    <updated>2023-03-25T06:58:23.210Z</updated>
    
    <content type="html"><![CDATA[<p>Web应用存在HTTP和HTTPS两种通信方式，HTTP默认端口80，数据以明文传输，HTTPS默认端口443，数据加密传输。</p><h2 id="HTTPS协议"><a href="#HTTPS协议" class="headerlink" title="HTTPS协议"></a>HTTPS协议</h2><p>HTTPS实际上并不是一种新的网络协议，是HTTP的基础上加了SSL层，数据的加密就是在SSL层完成的。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-4915c1ecfe442f0d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-4915c1ecfe442f0d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h2 id="数据传输方式"><a href="#数据传输方式" class="headerlink" title="数据传输方式"></a>数据传输方式</h2><h3 id="明文传输"><a href="#明文传输" class="headerlink" title="明文传输"></a>明文传输</h3><p>客户端和服务器已明文方式传输数据，没有安全性，数据再传输过程中可能被劫持和篡改<br><img src="https://upload-images.jianshu.io/upload_images/14151453-af0efb8a2b3599db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-af0efb8a2b3599db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3 id="对称加密传输"><a href="#对称加密传输" class="headerlink" title="对称加密传输"></a>对称加密传输</h3><p>对称加密算法：双方使用同一秘钥对数据进行加解密（AES、DES）<br><img src="https://upload-images.jianshu.io/upload_images/14151453-046d2c536baae247.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-046d2c536baae247.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br><strong>特点</strong>：</p><ul><li>如果不知道秘钥，是无法解出对应的明文，但是如果所有客户端都用相同的秘钥，相当于没有加密，坏人也可以作为一个用户拿到秘钥。</li><li>加解密性能高</li></ul><p>一种改进的方案是每个客户端先协商一个加密算法和秘钥，不同客户端使用不同的算法和秘钥，这就坏人即使作为一个用户也不知道别的用户的秘钥。但是这种方式协商秘钥的过程是公开明文的，坏人也有办法窃取到秘钥的，仍然存在风险。</p><h3 id="非对称加密传输"><a href="#非对称加密传输" class="headerlink" title="非对称加密传输"></a>非对称加密传输</h3><p>非对称加密算法：加密解密采用不同的秘钥，私钥加密后的密文，所有的公钥都可以解密，公钥加密后的密文只有私钥能解密。私钥通常只有一个人有，公钥可以公开发给所有人。（常见算法：RSA）<br><img src="https://upload-images.jianshu.io/upload_images/14151453-eefe11cf0a2b22f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-eefe11cf0a2b22f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong>特点</strong>：</p><ul><li>只要把私钥保存在服务器，公钥发给客户端，那么客户端向服务器发送的数据就是安全的，但是服务器向客户端发送的数据坏人也可以通过公钥解密</li><li>加解密消耗的时间较长，传输效率会降低</li></ul><h3 id="HTTPS（对称加密-非对称加密）"><a href="#HTTPS（对称加密-非对称加密）" class="headerlink" title="HTTPS（对称加密+非对称加密）"></a>HTTPS（对称加密+非对称加密）</h3><p><img src="https://upload-images.jianshu.io/upload_images/14151453-9a21634026ce4d86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-9a21634026ce4d86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p><strong>特点</strong>：</p><ul><li>使用非对称加密传输协商一个对称加密算法和秘钥</li><li>使用对称加密算法对数据加密传输</li><li>数据双向安全，且效率较高</li></ul><h2 id="CA机构和数字证书"><a href="#CA机构和数字证书" class="headerlink" title="CA机构和数字证书"></a>CA机构和数字证书</h2><p>从前面可以看到，协商阶段时候用非对称加密，客户端一开始就要持有公钥，那么客户端如何安全的获取公钥呢？<br>如果服务端直接将公钥发给客户端，中间可能被坏人劫持，返回一个假公钥，客户端使用假公钥进行加密后请求，坏人就可以使用假私钥解出明文，篡改内容后再使用真公钥加密后请求到服务器，这时服务器拿到的是被篡改后的数据。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-fb5c49e4b5019e80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-fb5c49e4b5019e80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>数字证书和CA机构就是用来保证服务器安全的发送公钥给客户端的。<br><strong>校验过程</strong></p><ol><li>读取证书中的所有者，有效期等信息进行校验</li><li>查找系统内置的受信任证书发布机构CA，与服务器下发的证书中的CA对比，校验是否是合法机构颁发</li><li>如果找不到，浏览器报错警告证书不可信</li><li>如果找到了：</li></ol><ul><li>对证书里的数字签名使用公钥解密得到明文的hash摘要</li><li>浏览器使用相同的hash算法计算明文的hash值，将这个值与上述计算的摘要对比验证证书的合法性。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一个完整的HTTPS请求流程如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/14151453-06d256f8dff32472.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-06d256f8dff32472.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://juejin.cn/post/6844903830916694030">【掘金】深入理解HTTPS工作原理</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Web应用存在HTTP和HTTPS两种通信方式，HTTP默认端口80，数据以明文传输，HTTPS默认端口443，数据加密传输。&lt;/p&gt;
&lt;h2 id=&quot;HTTPS协议&quot;&gt;&lt;a href=&quot;#HTTPS协议&quot; class=&quot;headerlink&quot; title=&quot;HTTPS协议</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://harryzhang.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="HTTPS" scheme="https://harryzhang.cn/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>Session和Cookie</title>
    <link href="https://harryzhang.cn/2023/03/25/Session%E5%92%8CCookie/"/>
    <id>https://harryzhang.cn/2023/03/25/Session%E5%92%8CCookie/</id>
    <published>2023-03-25T06:43:05.000Z</published>
    <updated>2023-03-25T06:58:16.825Z</updated>
    
    <content type="html"><![CDATA[<p>我们知道HTTP协议是无状态的，那么在Web开发中如何做好用户的整个浏览过程的控制，最经典的解决方案就是使用Cookie和Session。<br>Cookie是客户端的机制，把用户数据缓存在客户端，而Session是服务端的机制，每个用户都会被分配一个唯一的SessionID，可以通过url传输或保存在客户端的Cookie中，也可以将Session保存在数据库中，比如Redis中。</p><h2 id="Session和Cookie是怎么来的？"><a href="#Session和Cookie是怎么来的？" class="headerlink" title="Session和Cookie是怎么来的？"></a>Session和Cookie是怎么来的？</h2><p>假如你在浏览器上从来没有登录过GitHub，当你第一次登录的时候需要输入用户名和密码进行验证，通过验证后会调到个人首页，那么在登录成功后你点击你的某个代码仓库的时候服务器如何验证你的身份呢？因为HTTP协议是无状态的，服务器并不知道你上次已经验证过了，一种方法是每次请求都带上用户名和密码，这显然会导致用户体验极差。那么就需要再客户端或服务器上保存身份信息了，于是Cookie和Session就产生了。</p><h3 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h3><h4 id="Cookie原理"><a href="#Cookie原理" class="headerlink" title="Cookie原理"></a>Cookie原理</h4><p>Cookie就是本地计算机保存一些用户操作的历史信息，用户再次访问时在HTTP请求头中带上Cookie信息，服务端就可以对其进行验证。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-e9dd7894922a2adb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-e9dd7894922a2adb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="数据内容"><a href="#数据内容" class="headerlink" title="数据内容"></a>数据内容</h4><p>Cookie本质上是由浏览器管理存储在客户端的一小段文本，Chrome浏览器可以使用EditThisCookie插件来管理Cookie，如下图所示。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-ae9b877211f0b906.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-ae9b877211f0b906.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h4 id="会话Cookie和持久Cookie"><a href="#会话Cookie和持久Cookie" class="headerlink" title="会话Cookie和持久Cookie"></a>会话Cookie和持久Cookie</h4><ul><li>会话Cookie：Cookie是有有效期的，如果不设置过期时间，则表示这个Cookie的生命周期从创建到浏览器关闭为止，只要关闭浏览器Cookie就消失了，相当于数据保存在内存中，进程结束就丢失了</li><li>持久Cookie：如果设置了过期时间，浏览器会把Cookie数据保存到磁盘上，关闭浏览器再次打开依然有效，直到Cookie过期，浏览器通常都使用的持久Cookie。</li></ul><h3 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h3><h4 id="Session原理"><a href="#Session原理" class="headerlink" title="Session原理"></a>Session原理</h4><p>Session是服务器用来保存用户操作的历史信息的，使用SessionID来标识Session，SessionID由服务器产生，保证随机性和唯一性，相当于一个随机秘钥，避免在传输中暴露用户真实密码，但是服务器仍要将请求对Session进行对应，需要借助Cookie保存客户端的标识（SessionID）。<br><img src="https://upload-images.jianshu.io/upload_images/14151453-849911fdca5ee4a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload" data-srcset="https://upload-images.jianshu.io/upload_images/14151453-849911fdca5ee4a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>当服务器需要对某个请求创建Session的时候，首先检查这个客户端的请求是否包含了SessionID，如果已经包含则表示次客户端之前已经创建过，只需要根据SessionID查询对应的Session。如果请求没有携带SessionID，则会生成一个Session和对应的SessionID，同时在本次响应中返回SessionID。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>【1】<a href="https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/06.1.md">build-web-application-with-golang</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我们知道HTTP协议是无状态的，那么在Web开发中如何做好用户的整个浏览过程的控制，最经典的解决方案就是使用Cookie和Session。&lt;br&gt;Cookie是客户端的机制，把用户数据缓存在客户端，而Session是服务端的机制，每个用户都会被分配一个唯一的SessionI</summary>
      
    
    
    
    <category term="计算机网络" scheme="https://harryzhang.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="Session" scheme="https://harryzhang.cn/tags/Session/"/>
    
    <category term="Cookie" scheme="https://harryzhang.cn/tags/Cookie/"/>
    
  </entry>
  
</feed>
