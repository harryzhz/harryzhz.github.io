{"meta":{"title":"Harry 的个人空间","subtitle":"","description":"一个后端开发工程师的技术博客","author":"harry zhang","url":"https://harryzhang.cn/blog","root":"/blog/"},"pages":[{"title":"全部标签","date":"2023-03-19T05:57:02.000Z","updated":"2026-02-26T06:21:08.435Z","comments":true,"path":"tags/index.html","permalink":"https://harryzhang.cn/blog/tags/index.html","excerpt":"","text":""},{"title":"friends","date":"2023-03-19T05:57:22.000Z","updated":"2026-02-26T06:21:08.434Z","comments":true,"path":"friends/index.html","permalink":"https://harryzhang.cn/blog/friends/index.html","excerpt":"","text":""},{"title":"全部分类","date":"2023-03-19T05:56:46.000Z","updated":"2026-02-26T06:21:08.434Z","comments":true,"path":"categories/index.html","permalink":"https://harryzhang.cn/blog/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2023-03-12T16:11:09.000Z","updated":"2026-02-26T06:21:08.433Z","comments":true,"path":"about/index.html","permalink":"https://harryzhang.cn/blog/about/index.html","excerpt":"","text":"平平无奇"}],"posts":[{"title":"Docker 安装 Elasticsearch 和 Kibana 实践","slug":"Docker-安装-Elasticsearch-和-Kibana-实践","date":"2023-08-16T14:50:59.000Z","updated":"2026-02-26T06:21:08.433Z","comments":true,"path":"2023/08/16/Docker-安装-Elasticsearch-和-Kibana-实践/","link":"","permalink":"https://harryzhang.cn/blog/2023/08/16/Docker-%E5%AE%89%E8%A3%85-Elasticsearch-%E5%92%8C-Kibana-%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"依赖反转(DIP)原则在整洁架构中的应用","slug":"依赖反转-DIP-原则在整洁架构中的应用","date":"2023-07-19T14:47:52.000Z","updated":"2026-02-26T06:21:08.429Z","comments":true,"path":"2023/07/19/依赖反转-DIP-原则在整洁架构中的应用/","link":"","permalink":"https://harryzhang.cn/blog/2023/07/19/%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC-DIP-%E5%8E%9F%E5%88%99%E5%9C%A8%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","excerpt":"","text":"整洁架构 DIP 整洁架构简介 直接上图 整洁架构从外到内分为四层，源码中的依赖关系必须只指向同心圆的内侧，即由底层机制指向高层策略 业务实体这一层封装整个系统的关系业务逻辑，能被系统中的其他不同应用复用。对应领域驱动设计中的概念就是领域模型。 用例用例通常包含的是特定应用场景下的业务逻辑，这一层封装了整个系统所有用例。这些用例引导了数据在业务实体之间的流入&#x2F;流出，通过编排业务实体中的关键方法来实现业务用例的目标。 这一层发生的改变不应该影响业务实体，同时也不应该受外部因素（比如数据库、UI框架）的影响。该层的变化应该只和应用本身的行为变化有关。 接口适配器接口适配器层通常是一组数据转换器，负责将数据从对用例和业务实体最方便操作的格式转换为外部系统最方便的操作格式。例如这一层应该包含整个 GUI MVC 框架，展示器、视图、控制器都应该属于接口适配层，而模型部分则应该由控制器传给用例，用例再传回展示器和视图。 同样这一层也会负责将数据从对业务实体与用例方便的格式转换为数据持久化最方便的格式。 这一层也会负责将来自外部服务的数据转换为系统用例和业务实体所需的格式。 框架与驱动程序这一层一般是由工具、工具、Web 框架等组成，包含了所有的实现细节，Web、数据库都是实现细节。这一层也是最容易和频繁可能改变的，将其放在最外层就很难影响到其他层了。 依赖反转代码如何保证整洁架构所约束的依赖关系原则呢，通常是通过依赖反转来实现。比如需要将业务数据持久化，那直觉上来看肯定用例层需要调用接口适配层提供的数据库持久化方法，这就违反了只允许外层依赖内层的原则。 如上图所示，通过依赖反转，在用例层提供数据持久化需要的接口（Data Access Interface），由适配层提供具体的实现（MySQL Access），这样持久化时用例层不关注具体的实现，只需要调用用例层定义的接口即可。通过这种方法即将业务逻辑和具体的持久化方式解耦，又满足了只能外层依赖内层的原则。 应用示例 一个简单的文件存储服务，核心功能包括：文件上传、文件下载 组件依赖关系如下所示： 按照整洁架构的分层，简单分析上述文件存储服务 demo（上图省略了 Web 框架等处于最外层的组件）。 1. 实体层实体层包含了两个核心实体：文件实体、文件配置实体。 文件实体：包含增、删、改查文件 DB 记录等方法，以及获取文件存储类型、存储 Key 的方法 文件配置实体：包含获取上传文件大小限制等配置的方法 2. 用例层用例层包含了文件服务的两个核心业务用例：上传文件和下载文件，还包括了用于操作配置、数据库、对象存储、消息队列的一系列接口。 上传用例：调用文件配置实体获取上传配置，通过 StorageAccess 接口将文件内容持久化到对象存储或其他介质，再调用 DBAccess 的方法保存文件记录，最后通过 MQAccess 的方法发送一条上传文件的消息。 下载用例：调用文件实体的方法查询到文件的存储 Key，再调用 StorageAccess 的方法下载文件内容。 3. 接口适配层接口适配层则实现了四个适配器。 ACM: 用于管理动态配置 OSS: 用于上传、下载文件对象 MySQL: 用于增删改查文件记录 RocketMQ: 用于发送文件上传消息 可以看到通过按照整洁架构的分层方式和依赖反转原则，文件服务的组件依赖关系非常清晰（图中三层只存在从下到上方向的依赖），而且将业务逻辑和存储介质等基础设施解耦，底层组件的替换完全不会影响到业务用例的逻辑。","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://harryzhang.cn/blog/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"}],"tags":[]},{"title":"VSCode 项目多窗口改为多 Tab 样式","slug":"VSCode-项目多窗口改为多-Tab-样式","date":"2023-07-01T04:07:04.000Z","updated":"2026-02-26T06:21:08.425Z","comments":true,"path":"2023/07/01/VSCode-项目多窗口改为多-Tab-样式/","link":"","permalink":"https://harryzhang.cn/blog/2023/07/01/VSCode-%E9%A1%B9%E7%9B%AE%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%94%B9%E4%B8%BA%E5%A4%9A-Tab-%E6%A0%B7%E5%BC%8F/","excerpt":"","text":"环境 macOS Ventura 13.4 VSCode 1.79.2 问题当打开多个项目时，每个项目都占一个新的窗口，日常工作经常会打开至少五个以上项目，多窗口切换不方便，个人更习惯只开一个窗口，多个项目分多个 Tab 的模式 解决方法按如下方式可以切换到分 Tab 模式： 打开 Mac 系统偏好设置，找到「桌面与程序坞」选项（低版本系统在「通用」里），将「打开文稿时首选标签页」选项改为 始终 打开 VSCode 偏好设置（快捷键 cmd + ,） 搜索 native tab 结果如下，将选项设为开启状态（需要重启 VSCode） 重启后效果窗口效果变成如下样式 至此即可通过开关「Native Tab」设置切换 VS Code 的窗口样式。","categories":[{"name":"工具","slug":"工具","permalink":"https://harryzhang.cn/blog/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"VSCode","slug":"VSCode","permalink":"https://harryzhang.cn/blog/tags/VSCode/"}]},{"title":"Go 语言 Channel 最佳实践","slug":"Go-语言-Channel-最佳实践","date":"2023-05-14T09:31:52.000Z","updated":"2026-02-26T06:21:08.425Z","comments":true,"path":"2023/05/14/Go-语言-Channel-最佳实践/","link":"","permalink":"https://harryzhang.cn/blog/2023/05/14/Go-%E8%AF%AD%E8%A8%80-Channel-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"简介 Channel 基本概念介绍 基本使用方法参见 Go指南 Go 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。 不带缓冲的通道创建不带缓冲的通道语法如下 ch := make(chan int) 不带缓冲的通道发送和接收操作在另一端准备好之前都会阻塞，可以想象为是直接由发送者将数据传给接收者，没有中间缓冲区。这使得 Go 程可以在没有显式的锁或竞态变量的情况下进行同步。 带缓冲的通道将缓冲长度作为第二个参数提供给 make 来初始化一个带缓冲的信道 ch := make(chan int, 100) 仅当信道的缓冲区填满后，向其发送数据时才会阻塞。当缓冲区为空时，接受方会阻塞。 关闭通道close(ch) 发送者可通过 close 关闭一个信道来表示没有需要发送的值了。接收者可以通过为接收表达式分配第二个参数来测试信道是否被关闭：若没有值可以接收且信道已被关闭，那么在执行完 v, ok := &lt;-ch之后 ok 会被设置为 false。 循环 for i := range ch 会不断从通道接收数据直到它被关闭 注意： 信道通常情况无需关闭，只有在必须告诉接收者不在有要发送的数据时才有必要关闭，不合理的关闭反而会带来各种问题，比如往一个已关闭的通道里写入数据导致 panic。因此很多 Channel 的使用教程会建议不要关闭通道，或者说只有发送者才能关闭通道 select 通道select 语句使一个 Go 程可以等待多个通信操作。select 会阻塞到某个分支可以继续执行为止，这时就会执行该分支。当多个分支都准备好时会随机选择一个执行。 select &#123; case v &lt;- ch1: case v &lt;- ch2: case &lt;-quit: return &#125; 应用场景 Channel 的几种经典应用场景及示例 Channel 用于 Goroutine 之间的通信，常用于交换数据、并发控制、协程同步、超时控制等场景 1. 生产-消费模型用来在生产者和消费者之前的数据传输，生产者协程将结果发送到通道，消费者协程从通道读取结果，生产者和消费者是并发进行的 func producer(ch chan&lt;- int) &#123; defer close(ch) for i := 0; i &lt; 5; i++ &#123; time.Sleep(time.Second) fmt.Printf(&quot;[%s] Produced: %d\\n&quot;, time.Now().Format(time.DateTime), i) ch &lt;- i &#125; &#125; func consumer(ch &lt;-chan int) &#123; for &#123; if v, ok := &lt;-ch; ok &#123; time.Sleep(time.Second) fmt.Printf(&quot;[%s] Consumed: %d\\n&quot;, time.Now().Format(time.DateTime), v) &#125; else &#123; break &#125; &#125; &#125; func TestProdConsume(t *testing.T) &#123; ch := make(chan int, 5) go producer(ch) go consumer(ch) time.Sleep(10 * time.Second) &#125; 执行结果如下： === RUN TestProdConsume [2023-05-15 00:35:58] Produced: 0 [2023-05-15 00:35:59] Produced: 1 [2023-05-15 00:35:59] Consumed: 0 [2023-05-15 00:36:00] Consumed: 1 [2023-05-15 00:36:00] Produced: 2 [2023-05-15 00:36:01] Consumed: 2 [2023-05-15 00:36:01] Produced: 3 [2023-05-15 00:36:02] Consumed: 3 [2023-05-15 00:36:02] Produced: 4 [2023-05-15 00:36:03] Consumed: 4 --- PASS: TestProdConsume (10.00s) 2. 限制并发数当你有大量任务想通过 Goroutine 并发处理，但又不希望同时起太多 Goroutine 导致负载过高，可以通过 Channel 控制并发数量。 以下代码示例中，TotalNum 表示任务总数，ParallelNum 表示并发数 func TestConcurrencyNumberLimit(t *testing.T) &#123; const TotalNum = 10 const ParallelNum = 2 wg := &amp;sync.WaitGroup&#123;&#125; // 限制并发数，缓冲区大小即为最大并发数 ch := make(chan struct&#123;&#125;, ParallelNum) for i := 0; i &lt; TotalNum; i++ &#123; wg.Add(1) // 通道满时写入操作阻塞在这里，则不会继续起新的协程 ch &lt;- struct&#123;&#125;&#123;&#125; go func(idx int) &#123; defer func() &#123; wg.Done() &lt;-ch &#125;() fmt.Printf(&quot;[%s] process: %d/%d\\n&quot;, time.Now().Format(time.DateTime), idx, TotalNum) time.Sleep(1 * time.Second) &#125;(i + 1) &#125; wg.Wait() &#125; 执行结果如下，可以看到并发数设置为 2 时每秒完成两个任务，10 个任务总共耗时 5 秒 === RUN TestConcurrencyNumber [2023-05-15 00:07:42] process: 2/10 [2023-05-15 00:07:42] process: 1/10 [2023-05-15 00:07:43] process: 3/10 [2023-05-15 00:07:43] process: 4/10 [2023-05-15 00:07:44] process: 5/10 [2023-05-15 00:07:44] process: 6/10 [2023-05-15 00:07:45] process: 7/10 [2023-05-15 00:07:45] process: 8/10 [2023-05-15 00:07:46] process: 9/10 [2023-05-15 00:07:46] process: 10/10 --- PASS: TestConcurrencyNumber (5.00s) 3. 超时控制func TestTimeout(t *testing.T) &#123; ch := make(chan int, 1) // 执行一个耗时的任务 go func() &#123; time.Sleep(2 * time.Second) ch &lt;- 1 &#125;() select &#123; case res := &lt;-ch: // 任务执行完毕 fmt.Println(&quot;result: &quot;, res) case &lt;-time.After(1 * time.Second): // 任务执行超时 fmt.Println(&quot;timeout&quot;) &#125; &#125; 当任务耗时 2 秒，超时时间 1 秒时输出如下： === RUN TestTimeout timeout --- PASS: TestTimeout (1.00s) 当任务耗时 2 秒，超时时间 3 秒时输出如下： === RUN TestTimeout result: 1 --- PASS: TestTimeout (2.00s) 如何优雅关闭通道关于 “只能发送者关闭通道” 只是一种口头的约束，你可以在任何地方调用 close 方法来关闭通道，程序也可以编译运行。 实际上是发送者还是接收者关闭通道并没有太大影响，重点是通道的所有者，通常是创建通道的 Goroutine 做为所有者，负责管理通道的生命周期。 如果是一个发送者，可以直接由发送者关闭。如果是多个发送者，希望所有发送者发送完毕再关闭通道，则需要有个额外的 Goroutine 来管理所有发送者，并在所有发送者结束后来关闭通道。代码示例如下： func TestCh(t *testing.T) &#123; ch := make(chan int, 10) // 启动所有发送者协程 wg := &amp;sync.WaitGroup&#123;&#125; for i := 1; i &lt; 10; i++ &#123; wg.Add(1) go func(v int) &#123; defer wg.Done() ch &lt;- v fmt.Println(&quot;send:&quot;, v) &#125;(i) &#125; // 启动接受者协程 quit := make(chan struct&#123;&#125;) go func() &#123; // 接收数据直到通道关闭 for v := range ch &#123; fmt.Println(&quot;receive:&quot;, v) &#125; quit &lt;- struct&#123;&#125;&#123;&#125; &#125;() // 等待所有发送者协程结束，关闭通道 wg.Wait() fmt.Println(&quot;send over...&quot;) close(ch) // 等待接收者协程结束 &lt;-quit fmt.Println(&quot;receive over!!!&quot;) &#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://harryzhang.cn/blog/categories/Golang/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://harryzhang.cn/blog/tags/Go/"}]},{"title":"Go 语言中的值方法和指针方法","slug":"Go-语言中的值方法和指针方法","date":"2023-05-14T08:21:05.000Z","updated":"2026-02-26T06:21:08.425Z","comments":true,"path":"2023/05/14/Go-语言中的值方法和指针方法/","link":"","permalink":"https://harryzhang.cn/blog/2023/05/14/Go-%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%80%BC%E6%96%B9%E6%B3%95%E5%92%8C%E6%8C%87%E9%92%88%E6%96%B9%E6%B3%95/","excerpt":"","text":"概念函数和方法在 Go 语言中，我们可以为自定义类型定义方法。方法是一个与特定类型关联的函数。方法可以被定义在值类型上或指针类型上。这两种方法分别称为值方法和指针方法。 // 函数 func Hello() &#123; fmt.Println(&quot;Hello World!&quot;) &#125; type Welcome struct&#123;&#125; // 方法 func (w Welcome) Hello() &#123; fmt.Println(&quot;Hello World!&quot;) &#125; 接收者 值方法: 是定义在值类型上的方法，它们使用值作为接收器（即方法调用的目标对象）。 指针方法: 是定义在指针类型上的方法，它们使用指针作为接收器。 // 指针方法 func (w *Welcome) SetName(name string) &#123; w.name = name &#125; // 值方法 func (w Welcome) Welcome() &#123; fmt.Printf(&quot;Welcome %s&quot;, w.name) &#125; 区别 如果你在类型上定义了一个值方法，那么它不会修改接收者的原始值，如果定义了指针方法，则可以修改接收者的原始值 值方法可以通过指针和值类型的变量调用 指针方法只能通过指针变量来调用，但是如果某个值是可寻址的（addressable，或者说左值），那么编译器会在值调用指针方法时自动插入取地址符，使得在此情形下看起来像指针方法也可以通过值来调用 func TestWelcome(t *testing.T) &#123; // 正确: 值类型调用值类型的方法 NewWelcome().Hello() // 正确: 指针类型的变量可以调用指针方法和值方法 NewWelcomePtr().SetName(&quot;Harry&quot;) NewWelcomePtr().Welcome() // 正常: w 为值类型的变量，但是因为 w 是可寻址的，所以编译器会自动转换 w := NewWelcome() w.SetName(&quot;Harry&quot;) w.Welcome() // 报错: cannot call pointer method SetName on Welcome // 函数返回值是不可寻址的 NewWelcome().SetName(&quot;Harry&quot;) &#125; 如何选择 如果需要修改接收者的原始值，则必须使用指针方法 当不希望方法修改接收者的原始值时使用值方法 当不需要修改原始值且对象比较大时希望避免因值传递带来的性能开销时，使用指针方法。 当不需要修改原始值且对象比较简单时使用值方法 扩展自动转换Go 语言会自动处理值和指针之间的转换。即使定义了指针方法，也可以通过值调用它（Go 会自动转换为指针）；同样，定义了值方法，也可以通过指针调用它（Go 会自动解引用）。 左值和右值 值类型 区别 左值 可寻址，可通过 &amp; 取地址符获取内存地址 右值 不可寻址，没有分配内存地址 总结 值方法内的修改不会影响接收者原始值，指针方法可以 指针类型可以调用指针方法和值方法 值类型只能调用值方法，但是如果该值是可寻址的情况编译器会自动转换，使得看起来像值类型调用了指针方法","categories":[{"name":"Golang","slug":"Golang","permalink":"https://harryzhang.cn/blog/categories/Golang/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://harryzhang.cn/blog/tags/Go/"}]},{"title":"数据结构（6）: 单调栈","slug":"数据结构-6-单调栈","date":"2023-04-02T08:29:44.000Z","updated":"2026-02-26T06:21:08.424Z","comments":true,"path":"2023/04/02/数据结构-6-单调栈/","link":"","permalink":"https://harryzhang.cn/blog/2023/04/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-6-%E5%8D%95%E8%B0%83%E6%A0%88/","excerpt":"","text":"特性单调栈是一种特殊的栈数据结构，它满足元素的单调性（单调递增或单调递减）。与普通栈相比，单调栈在出栈时有一定的规则，使得出栈后栈中的元素仍然保持单调性。 单调栈主要有两个操作：入栈和出栈。入栈时，先判断栈顶元素是否符合单调性，如果不符合，则将其弹出，一直重复此过程直到符合单调性后再入栈；出栈时，弹出栈顶元素即可。 算法应用单调栈在算法中有许多应用，例如在求解 Next Greater Element（下一个更大元素）等问题中。 以求解 Next Greater Element 问题为例，给定一个数组 nums，要求找出每个元素的下一个更大元素（即在数组中右边第一个比它大的数），若不存在则为-1。我们可以使用单调栈来解决这个问题。 具体的实现步骤如下： 遍历数组 nums，依次将元素入栈 当栈顶元素小于当前元素时，弹出栈顶元素，将其下一个更大元素设为当前元素，并继续弹出栈顶元素，直到栈为空或栈顶元素大于等于当前元素 当遍历完数组后，栈中剩余的元素的下一个更大元素均为-1 实例代码： func nextGreaterElement(nums []int) []int &#123; stack := []int&#123;&#125; res := make([]int, len(nums)) for i := range res &#123; res[i] = -1 &#125; for i := 0; i &lt; len(nums); i++ &#123; for len(stack) &gt; 0 &amp;&amp; nums[stack[len(stack)-1]] &lt; nums[i] &#123; res[stack[len(stack)-1]] = nums[i] stack = stack[:len(stack)-1] &#125; stack = append(stack, i) &#125; return res &#125; 实战1. 每日温度 LeetCode 739. 每日温度 给定一个整数数组 temperatures ，表示每天的温度，返回一个数组 answer ，其中 answer[i] 是指对于第 i 天，下一个更高温度出现在几天后。如果气温在这之后都不会升高，请在该位置用 0 来代替。 该问题就是典型的 Next Greater Element（下一个更大元素） 问题，题目等价于找出右边第一个比当前元素大的距离。 示例代码: func dailyTemperatures(temperatures []int) []int &#123; n := len(temperatures) ans := make([]int, n) stk := []int&#123;&#125; for i := 0; i &lt; n; i++ &#123; for len(stk) &gt; 0 &amp;&amp; temperatures[i] &gt; temperatures[stk[len(stk)-1]] &#123; top := stk[len(stk)-1] stk = stk[:len(stk)-1] ans[top] = i - top &#125; stk = append(stk, i) &#125; return ans &#125; 2. 循环数组下一个更大元素 LeetCode 503. 下一个更大元素 II 给定一个循环数组 nums （ nums[nums.length - 1] 的下一个元素是 nums[0] ），返回 nums 中每个元素的 下一个更大元素 。数字 x 的 下一个更大的元素 是按数组遍历顺序，这个数字之后的第一个比它更大的数，这意味着你应该循环地搜索它的下一个更大的数。如果不存在，则输出 -1 。 该问题和题目 739. 每日温度 类似，不同点在于该问题是循环数组，遍历到最后一个元素后要循环变量一次，因此只需要将遍历的次数改为 2 * n ，取下标改成 i % n 即可 示例代码: func nextGreaterElements(nums []int) []int &#123; n := len(nums) ans := make([]int, n) for i := range ans &#123; ans[i] = -1 &#125; stk := []int&#123;&#125; for i := 0; i &lt; 2*n; i++ &#123; for len(stk) &gt; 0 &amp;&amp; nums[i%n] &gt; nums[stk[len(stk)-1]] &#123; top := stk[len(stk)-1] stk = stk[:len(stk)-1] ans[top] = nums[i%n] &#125; stk = append(stk, i%n) &#125; return ans &#125; 3. 接雨水 LeetCode 42. 接雨水给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。 示例代码： func trap(height []int) int &#123; stk := []int&#123;&#125; ans := 0 for i := 0; i &lt; len(height); i++ &#123; for len(stk) &gt; 0 &amp;&amp; height[stk[len(stk)-1]] &lt; height[i] &#123; top := stk[len(stk)-1] stk = stk[:len(stk)-1] if len(stk) &gt; 0 &#123; // 弹出的栈顶元素、当前栈顶元素、当前元素构成凹槽区域 // 高：当前元素和当前栈顶元素的较小值 - 弹出的栈顶元素 // 宽：当前元素下标 - 当前栈顶元素下表 - 1 ans += (min(height[i], height[stk[len(stk)-1]]) - height[top]) * (i - stk[len(stk) - 1] - 1) &#125; &#125; stk = append(stk, i) &#125; return ans &#125; func min(x, y int) int &#123; if x &lt; y &#123; return x &#125; return y &#125; 4. 柱状图中最大矩形 LeetCode 84. 柱状图中最大的矩形给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。求在该柱状图中，能够勾勒出来的矩形的最大面积。 该问题比 42. 接雨水 问题难的点在于要注意边界条件，为方便处理输入本身单调递增和单调递减的边界情况，在输入列表头和尾各添加一个 0。 示例代码： func largestRectangleArea(heights []int) int &#123; ans := 0 // 头尾各加一个 0 处理边界 case heights = append([]int&#123;0&#125;, heights...) heights = append(heights, 0) stk := []int&#123;0&#125; for i := 1; i &lt; len(heights); i++ &#123; for heights[i] &lt; heights[stk[len(stk)-1]] &#123; top := stk[len(stk)-1] stk = stk[:len(stk)-1] // 高：弹出的栈顶元素 // 宽：当前元素下标 - 当前栈顶下标 - 1 h := heights[top] w := i - stk[len(stk)-1] - 1 ans = max(ans, h*w) &#125; stk = append(stk, i) &#125; return ans &#125; func max(x, y int) int &#123; if x &gt; y &#123; return x &#125; return y &#125; 总结使用单调栈解决算法问题的关键点有一下几点： 找到需要维护单调性的数组。通常是需要找到比当前位置大或小的元素。 根据需要维护的单调性，选择递增栈或递减栈。 确定每个元素的入栈和出栈条件。入栈条件通常是当前元素与栈顶元素的比较关系，出栈条件通常是满足当前单调性的元素。 对于每个入栈的元素，计算其对应的答案。通常是栈顶元素对应的答案，即找到比当前元素大或小的元素。 根据具体情况，确定栈中存储的是元素的下标还是元素本身。 单调栈算法通常需要先对数组进行预处理，以便在计算过程中能够快速获取需要的信息。另外，在使用单调栈解决算法问题时，需要特别注意边界条件和特殊情况的处理，以保证算法的正确性和稳定性。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"单调栈","slug":"单调栈","permalink":"https://harryzhang.cn/blog/tags/%E5%8D%95%E8%B0%83%E6%A0%88/"},{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"}]},{"title":"Go 协程调度原理及应用","slug":"Go-协程调度原理及应用","date":"2023-03-25T07:42:00.000Z","updated":"2026-02-26T06:21:08.416Z","comments":true,"path":"2023/03/25/Go-协程调度原理及应用/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/Go-%E5%8D%8F%E7%A8%8B%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%E5%8F%8A%E5%BA%94%E7%94%A8/","excerpt":"","text":"什么是协程？进程和线程一个应用程序时运行在操作系统上的一个进程。进程是一个运行在自己独立内存空间的独立执行体，是操作系统进行资源分配的最小单位。一个进程则有一个或多个线程组成，这些线程是共享进程内存地址空间的执行体，是操作系统进行任务调度的最小单位。而使用多线程进行工作时，由于共享父进程的内存空间等资源，访问同一个数据需要对其进行加锁，保证同一时间只有一个线程操作一个数据。这样不仅会提高编码的复杂度，还会有多个线程抢占锁、线程切换带来的额外开销。 协程在Go中，应用程序并发处理的部分被称作goroutines（协程），它是一种更轻量级的线程，和操作系统的线程之间并无一对一的关系。协程是根据一个或多个线程的可用性，映射（多路复用，执行于）在它们之上的；协程调度器负责在Go运行时调度进行协程的工作。 通道（Channel）协程工作在相同的地址空间中，所以共享内存的方式是同步的，可以使用互斥锁来实现，但是Go中更好的方案是使用Channel来同步协程。通道类型（Chan）就像一个可用于发送类型化数据的管道，由其负责协程之间的通信，在任何时间，一个通道数据被设计为只有一个协程可以对其访问，所以不会发生数据竞争。 通道阻塞默认情况下，Go创建的通道是同步且无缓冲的：在有接受者接受数据之前，发送不会结束，发送者是直接将数据交给接受者的，所以这种通道的发送或接受操作在对方准备好之前都是阻塞的。例如以下代码，执行会报错死锁：示例1.1: func main() &#123; ch := make(chan int) ch &lt;- 1 &lt;-ch &#125; 因为对ch的读写都在main函数的主协程中，执行到ch &lt;-1时由于接收ch的数据还没准备好，发送数据将被阻塞，程序无法继续执行。必须使用关键字go来启动一个新的协程发送数据，另一个协程接收数据，如下所示：示例1.2 func main() &#123; ch := make(chan int) go func() &#123; ch &lt;- 1 &#125;() fmt.Println(&lt;- ch) &#125; 使用make创建一个通道的时候可以传入第二个参数指定通道缓冲区大小，这种方式在通道写满之前，发送数据不会被阻塞，通道不为空时接收操作不会被阻塞，如果将示例1.1中的创建通道传第二个参数为1，就可以正常运行不会死锁了，代码如下：示例1.3 func main() &#123; ch := make(chan int, 1) ch &lt;- 1 fmt.Println(&lt;- ch) &#125; Go协程调度原理调度器架构Go的调度器从最开始的单线程经过不断的改进、优化，发展到现在的GMP模型，在GMP模型中有三个重要的结构： G(Goroutine)：go协程，一个可执行单元，调度器作用就是对所有G的切换 M(Thread)：操作系统上的线程，G运行与M上，一个G可能由多个不同的M运行，一个M可以运行多个G P(Processor)：处理器，他包含了运行G的资源，如果线程M想运行G，必须先获取P，P还包含了可运行的G队列。一个M一个时刻只拥有一个P，M和P的数量是1：1的。 上图中各个模块的作用如下： 全局队列：存放等待运行G P的本地队列：和全局队列类似，存放的也是等待运行的G，存放数量上限256个。新建G时，G优先加入到P的本地队列，如果队列满了，则会把本地队列中的一半G移动到全局队列 P列表：所有的P都在程序启动时创建，保存在数组中，最多有GOMAXPROCS个，可通过runtime.GOMAXPROCS(N)修改，N表示设置的个数 M是Goroutine调度器和操作系统调度器的桥梁，每个M代表一个内核线程，操作系统调度器负责把内核线程分配到CPU的核心上执行。 调度策略复用线程调度器核心思想是尽可能避免频繁的创建、销毁线程，对线程进行复用以提高效率。1. work stealing机制（窃取式）当本线程无G可运行时，尝试从其他线程绑定的P窃取G，而不是直接销毁线程。2. hand off机制当本线程M因为G进行的系统调用阻塞是，线程释放绑定的P，把P转移给其他空闲的M’执行。 利用多核CPU并行GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU核心上运行。 抢占一个goroutine最多占用CPU10ms，防止其他goroutine等待太久得不到执行被“饿死”。 全局G队列全局G队列是有互斥锁保护的，访问需要竞争锁，新的调度器将其功能弱化了，当M执行work stealing从其他P窃取不到G时，才会去全局G队列获取G。 Go并发编程实例两个协程交替打印1-100 用两个协程顺序打印出1-100，要求一个协程打印1、3、5、7…奇数，另一个协程打印2、4、6、8…偶数，输出必须是顺序的。 示例代码： func main() &#123; // ch用来同步两个协程交替执行 ch := make(chan int) // ch_end用来阻塞主程序，让两个协程可以执行完 ch_end := make(chan int) go func() &#123; for i := 1; i &lt;= 100; i++ &#123; ch &lt;- 1 if i % 2 == 0 &#123; fmt.Println(i) &#125; &#125; ch_end &lt;- 1 &#125;() go func() &#123; for i := 1; i &lt;= 100; i++ &#123; &lt;-ch if i % 2 != 0 &#123; fmt.Println(i) &#125; &#125; &#125;() &lt;-ch_end &#125; 并行素数筛选 有一个协程不断生2~n的自然数，对每个素数起一个协程，用来筛选素数 示例代码: func generate(ch chan int, n int) &#123; for i := 2; i &lt;= n ; i++ &#123; fmt.Println(&quot;generate:&quot;, i) ch &lt;- i &#125; close(ch) &#125; func filter(in, out chan int, prime int) &#123; for i := range in &#123; fmt.Printf(&quot;filter(%d): %d\\n&quot;, prime, i) if i % prime != 0 &#123; out &lt;- i &#125; &#125; close(out) &#125; func main() &#123; res := []int&#123;&#125; ch := make(chan int) go generate(ch, 112) for &#123; if prime, ok := &lt;- ch; ok &#123; res = append(res, prime) ch_out := make(chan int) go filter(ch, ch_out, prime) // 前一个素数过滤协程的输出通道是后一个素数过滤通道的输入通道 ch = ch_out &#125; else &#123; break &#125; &#125; fmt.Println(&quot;main:&quot;, res) &#125; 实现超时机制 当设置的超时时间到达后如果work还不可执行就终止等待，返回超时 示例代码 func TimeOut(timeout time.Duration) &#123; ch_to := make(chan bool, 1) go func() &#123; time.Sleep(timeout) ch_to &lt;- true &#125;() ch_do := make(chan int, 1) go func() &#123; time.Sleep(3e9) ch_do &lt;- 1 &#125;() select &#123; case i := &lt;- ch_do: fmt.Println(&quot;do something, id:&quot;, i) case &lt;-ch_to: fmt.Println(&quot;timeout&quot;) break &#125; &#125; 实现迭代器 实现一个惰性迭代器，每次调用返回一个列表元素，直到所有的元素被访问完返回nil 示例代码： // 迭代器 func iterator(iterable []interface&#123;&#125;) chan interface&#123;&#125;&#123; yield := make(chan interface&#123;&#125;) go func() &#123; for i := 0; i &lt; len(iterable); i++ &#123; yield &lt;- iterable[i] &#125; close(yield) &#125;() return yield &#125; // 获取下一个元素 func next(iter chan interface&#123;&#125;) interface&#123;&#125; &#123; for v := range iter &#123; return v &#125; return nil &#125; func main() &#123; nums := []interface&#123;&#125;&#123;1, 2, 3, 4, 5&#125; iter := iterator(nums) for v := next(iter); v != nil; v = next(iter) &#123; fmt.Println(v) &#125; &#125; 参考【1】《The Way to Go》：并发、并行和协程【2】Golang的协程调度器原理及GMP设计思想？","categories":[{"name":"Golang","slug":"Golang","permalink":"https://harryzhang.cn/blog/categories/Golang/"}],"tags":[{"name":"Goroutine","slug":"Goroutine","permalink":"https://harryzhang.cn/blog/tags/Goroutine/"},{"name":"GMP","slug":"GMP","permalink":"https://harryzhang.cn/blog/tags/GMP/"}]},{"title":"Go 实战: 基于Thrift框架的 RPC 服务 Demo","slug":"Go-实战-基于Thrift框架的-RPC-服务-Demo","date":"2023-03-25T07:40:58.000Z","updated":"2026-02-26T06:21:08.417Z","comments":true,"path":"2023/03/25/Go-实战-基于Thrift框架的-RPC-服务-Demo/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/Go-%E5%AE%9E%E6%88%98-%E5%9F%BA%E4%BA%8EThrift%E6%A1%86%E6%9E%B6%E7%9A%84-RPC-%E6%9C%8D%E5%8A%A1-Demo/","excerpt":"","text":"Thrift架构简介Thrift自顶向下可分为四层 Server(single-threaded, event-driven)服务器进程调度 Processor(compiler generated)RPC接口处理函数分发，IDL定义接口的实现将挂接到这里面 Protocol (JSON, compact etc)协议，定义数据传输格式 TBinaryProtocol（二进制格式） TCompactProtocol（压缩格式） TJSONProtocol （JSON格式） TDebugProtocol （易看的文本格式，方便debug） Transport(raw TCP, HTTP etc)网络传输，定义数据传输方式 TSocket（阻塞式socket） TServerTransport（服务端模式，非阻塞socket） TFramedTransport（以帧为单位，非阻塞式） TMemoryTransport（内存形式） TFileTransport（文件形式） TZlibTransport（使用zlib压缩，与其他方式联合使用） Thrift实际上是实现了C&#x2F;S模式，通过代码生成工具将接口定义文件生成服务器端和客户端代码（可以为不同语言），从而实现服务端和客户端跨语言的支持。 开发环境系统：macOS Big Sur 11.1IDE ：GoLand 2020.3.4Thrift：0.14.1 软件安装安装thriftbrew install thrift # 安装 thrift -version # 查看版本检查是否安装成功 安装thrift support插件Plugins-&gt;Marketplace搜索thrift support，安装后重启IDE即可如果搜不到可以去官网下载对应版本的安装包本地安装 开发编写thrift IDLIDL语法官方文档 user.thrift namespace go demo struct User &#123; 1:required i32 id, 2:required string name, 3:required string avatar, 4:required string address, 5:required string mobile, &#125; struct UserList &#123; 1:required list&lt;User&gt; userList, 2:required i32 page, 3:required i32 limit, &#125; service.thrift include &quot;user.thrift&quot; // 标记各语言的命名空间（包名），不同语言需要单独声明 namespace go demo // 重新定义类型名称，同c语言 typedef map&lt;string, string&gt; Data // 定义响应体结构 struct Response &#123; 1:required i32 errcode, 2:required string errmsg, 3:required Data data, &#125; // 定义服务接口，相当于go的interface service Greeter &#123; Response SayHello( 1:required user.User user ) Response GetUser( 1:required i32 uid ) &#125; 生成目标语言代码执行命令：thrift -r --gen go service.thrift生成以下代码文件： 编写golang服务端代码服务端： package main import ( &quot;context&quot; &quot;encoding/json&quot; &quot;flag&quot; &quot;fmt&quot; &quot;github.com/apache/thrift/lib/go/thrift&quot; &quot;os&quot; &quot;thrift_practice/src/gen-go/demo&quot; ) func Usage() &#123; fmt.Fprint(os.Stderr, &quot;Usage of &quot;, os.Args[0], &quot;:\\n&quot;) flag.PrintDefaults() fmt.Fprint(os.Stderr, &quot;\\n&quot;) &#125; //定义服务 type Greeter struct &#123; &#125; //实现IDL里定义的接口 //SayHello func (this *Greeter) SayHello(ctx context.Context, u *demo.User) (r *demo.Response, err error) &#123; strJson, _ := json.Marshal(u) return &amp;demo.Response&#123;Errcode: 0, Errmsg: &quot;success&quot;, Data: map[string]string&#123;&quot;User&quot;: string(strJson)&#125;&#125;, nil &#125; //GetUser func (this *Greeter) GetUser(ctx context.Context, uid int32) (r *demo.Response, err error) &#123; return &amp;demo.Response&#123;Errcode: 1, Errmsg: &quot;user not exist.&quot;&#125;, nil &#125; func main() &#123; //命令行参数 flag.Usage = Usage addr := flag.String(&quot;addr&quot;, &quot;localhost:9090&quot;, &quot;Address to listen to&quot;) flag.Parse() //protocol var protocolFactory thrift.TProtocolFactory protocolFactory = thrift.NewTBinaryProtocolFactoryDefault() //transport var transportFactory thrift.TTransportFactory transportFactory = thrift.NewTTransportFactory() //handler handler := &amp;Greeter&#123;&#125; //transport,no secure var err error var transport thrift.TServerTransport transport, err = thrift.NewTServerSocket(*addr) if err != nil &#123; fmt.Println(&quot;error running server:&quot;, err) &#125; //processor processor := demo.NewGreeterProcessor(handler) fmt.Println(&quot;Starting the simple server... on &quot;, *addr) //start tcp server server := thrift.NewTSimpleServer4(processor, transport, transportFactory, protocolFactory) err = server.Serve() if err != nil &#123; fmt.Println(&quot;error running server:&quot;, err) &#125; &#125; 客户端：（借助go testing） package main import ( &quot;context&quot; &quot;fmt&quot; &quot;github.com/apache/thrift/lib/go/thrift&quot; &quot;testing&quot; &quot;thrift_practice/src/gen-go/demo&quot; ) var ctx = context.Background() func GetClient() *demo.GreeterClient &#123; addr := &quot;:9090&quot; var transport thrift.TTransport var err error transport, err = thrift.NewTSocket(addr) if err != nil &#123; fmt.Println(&quot;Error opening socket:&quot;, err) &#125; //protocol var protocolFactory thrift.TProtocolFactory protocolFactory = thrift.NewTBinaryProtocolFactoryDefault() //no buffered var transportFactory thrift.TTransportFactory transportFactory = thrift.NewTTransportFactory() transport, err = transportFactory.GetTransport(transport) if err != nil &#123; fmt.Println(&quot;error running client:&quot;, err) &#125; if err := transport.Open(); err != nil &#123; fmt.Println(&quot;error running client:&quot;, err) &#125; iprot := protocolFactory.GetProtocol(transport) oprot := protocolFactory.GetProtocol(transport) client := demo.NewGreeterClient(thrift.NewTStandardClient(iprot, oprot)) return client &#125; //GetUser func TestGetUser(t *testing.T) &#123; client := GetClient() rep, err := client.GetUser(ctx, 100) if err != nil &#123; t.Errorf(&quot;thrift err: %v\\n&quot;, err) &#125; else &#123; t.Logf(&quot;Recevied: %v\\n&quot;, rep) &#125; &#125; //SayHello func TestSayHello(t *testing.T) &#123; client := GetClient() user := &amp;demo.User&#123;&#125; user.Name = &quot;thrift&quot; user.Address = &quot;address&quot; rep, err := client.SayHello(ctx, user) if err != nil &#123; t.Errorf(&quot;thrift err: %v\\n&quot;, err) &#125; else &#123; t.Logf(&quot;Recevied: %v\\n&quot;, rep) &#125; &#125; 运行测试 运行服务端代码 运行客户端：go test -v 参考资料【1】从零开始基于go-thrift创建一个RPC服务【2】Go Tutorial【3】Thrift RPC框架指南","categories":[{"name":"Golang","slug":"Golang","permalink":"https://harryzhang.cn/blog/categories/Golang/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://harryzhang.cn/blog/tags/Go/"},{"name":"Thrift","slug":"Thrift","permalink":"https://harryzhang.cn/blog/tags/Thrift/"},{"name":"RPC","slug":"RPC","permalink":"https://harryzhang.cn/blog/tags/RPC/"}]},{"title":"Go 实战: Socket 编程","slug":"Go-实战-Socket-编程","date":"2023-03-25T07:40:10.000Z","updated":"2026-02-26T06:21:08.416Z","comments":true,"path":"2023/03/25/Go-实战-Socket-编程/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/Go-%E5%AE%9E%E6%88%98-Socket-%E7%BC%96%E7%A8%8B/","excerpt":"","text":"Socket如何通信在网络中要唯一确定一个进程需要用一个三元组（Protocol，IP，Port），IP地址唯一确定一台主机，再通过协议和端口唯一确定一个进程，这里也可以看到TCP和UDP可以绑定同一个端口。能唯一确定网络中的进程了，便可以利用这个标志在他们之间进行数据交互。 Socket基础TCP&#x2F;IPGo支持的IP类型 IPv4 IPv6 Go支持的协议类型 TCP UDP Go Socket编程Go语言的net包对TCP和UDP协议提供了支持，可以借助net改包方便的开发Socket应用 TCP SocketTCP客户单和服务端通信时需要建立一个连接，Go语言的net包中TCPConn类型就表示一个TCP连接，主要有以下两个函数，用来读写数据： func (c *TCPConn) Write(b []byte) (int, error) func (c *TCPConn) Read(b []byte) (int, error) 客户端建立连接需要知道服务器的地址，net表中的TCPAddr类型表示一个TCP的地址信息，定义如下： type TCPAddr struct &#123; IP IP Port int Zone string // IPv6 scoped addressing zone &#125; 可以使用ResolveTCPAddr获取一个TCPAddr func ResolveTCPAddr(net, addr string) (*TCPAddr, os.Error) 常用的控制TCP连接相关函数 func DialTimeout(net, addr string, timeout time.Duration) (Conn, error)设置连接超时，客户端和服务端都适用，超过设置时间返回连接失败 func (c *TCPConn) SetReadDeadline(t time.Time) errorfunc (c *TCPConn) SetWriteDeadline(t time.Time) error设置读写超时 func (c *TCPConn) SetKeepAlive(keepalive bool) os.Error设置keepAlive属性。操作系统层在tcp上没有数据和ACK的时候，会间隔性的发送keepalive包，操作系统可以通过该包来判断一个tcp连接是否已经断开，在windows上默认2个小时没有收到数据和keepalive包的时候认为tcp连接已经断开，这个功能和我们通常在应用层加的心跳包的功能类似。 TCP Server服务端要做的事如下： 监听一个地址端口 调用accept（阻塞）等待连接 当请求到来时接受请求并读写数据 数据交互完成后关闭连接 示例根据客户端发送的数据来返回不同格式的当前时间，使用goroutine支持并发请求。server.go package main import ( &quot;fmt&quot; &quot;log&quot; &quot;net&quot; &quot;os&quot; &quot;strconv&quot; &quot;strings&quot; &quot;time&quot; ) func main() &#123; service := &quot;localhost:7777&quot; tcp_addr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, service) checkError(err) // 监听本地7777端口 listener, err := net.ListenTCP(&quot;tcp&quot;, tcp_addr) checkError(err) for &#123; log.Println(&quot;[server] listening&quot;, tcp_addr.String()) // 等待客户端连接 conn, err := listener.Accept() if err != nil &#123; continue &#125; go handleDatetime(conn) &#125; &#125; // 事件处理 func handleDatetime(conn net.Conn) &#123; // 设置读超时 conn.SetReadDeadline(time.Now().Add(10 * time.Second)) defer conn.Close() for &#123; buffer := make([]byte, 128) read_len, err := conn.Read(buffer) if err != nil &#123; fmt.Println(err) break &#125; // 根据读到的数据返回对应的时间格式 if read_len == 0 &#123; break &#125; else if strings.TrimSpace(string(buffer[:read_len])) == &quot;timestamp&quot; &#123; daytime := strconv.FormatInt(time.Now().Unix(), 10) conn.Write([]byte(daytime)) &#125; else &#123; daytime := time.Now().String() conn.Write([]byte(daytime)) &#125; log.Println(&quot;[server] response to:&quot;, conn.RemoteAddr().String()) &#125; &#125; func checkError(err error) &#123; if err != nil &#123; fmt.Fprintf(os.Stderr, &quot;Fatal error: %s&quot;, err.Error()) os.Exit(1) &#125; &#125; 运行结果如下： TCP Client客户端要做的事如下： 向服务端发起连接请求 发送数据到服务端，接收来自服务端的响应数据 数据交互完成后关闭连接 示例client.go package main import ( &quot;flag&quot; &quot;fmt&quot; &quot;net&quot; &quot;os&quot; ) func main() &#123; service := flag.String(&quot;host&quot;, &quot;127.0.0.1:7777&quot;, &quot;an ip address&quot;) flag.Usage = func() &#123; fmt.Fprintf(os.Stdout, &quot;Usage of %s:\\n&quot;, &quot;mock http request&quot;) flag.PrintDefaults() &#125; flag.Parse() tcp_addr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, *service) checkError(err) // 发起连接请求 conn, err := net.DialTCP(&quot;tcp&quot;, nil, tcp_addr) checkError(err) // 读写数据 _, err = conn.Write([]byte(&quot;timestamp\\\\r\\\\n&quot;)) checkError(err) buffer := make([]byte, 256) _, err = conn.Read(buffer) checkError(err) fmt.Println(&quot;[client] receive from:&quot;, conn.RemoteAddr().String()) fmt.Println(string(buffer)) // 关闭连接 conn.Close() os.Exit(0) &#125; func checkError(err error) &#123; if err != nil &#123; fmt.Fprintf(os.Stderr, &quot;Fatal error: %s&quot;, err.Error()) os.Exit(1) &#125; &#125; 在服务端运行的前提下，运行客户端后结果如下：客户端： 服务端： 参考资料【1】GitHub&#x2F;astaxie&#x2F;build-web-application-with-golang-8.1 Socket编程","categories":[{"name":"Golang","slug":"Golang","permalink":"https://harryzhang.cn/blog/categories/Golang/"}],"tags":[{"name":"Socket","slug":"Socket","permalink":"https://harryzhang.cn/blog/tags/Socket/"},{"name":"Go","slug":"Go","permalink":"https://harryzhang.cn/blog/tags/Go/"}]},{"title":"一致性哈希算法原理","slug":"一致性哈希算法原理","date":"2023-03-25T07:25:04.000Z","updated":"2026-02-26T06:21:08.422Z","comments":true,"path":"2023/03/25/一致性哈希算法原理/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/","excerpt":"","text":"传统哈希算法的局限性在分布式系统中，通常使用多个节点来保存数据，以提高并发能力和容量，那么如果决定数据保存到哪个节点上呢？一般的做法是通过一个哈希函数对数据key进行计算，然后对节点数量取模，从而得到数据分配的节点：node_id = hash(key) % N但是这种做法在节点数量N变化的时候，大部分key的计算的节点都会重新分配。如果是应用在分布式缓存，就会导致大规模的缓存失效，引起缓存雪崩。 一致性哈希算法原理一致性哈希算法将哈希空间分配到哈希环的数据结构上，取值范围0~2^32-1，并且起点与终点相连。 将服务器通过哈希函数（以IP或者主机名作为key）放置到环上 对数据key使用相同的哈希函数，落到哈希空间上的某个点，如果该点不是服务器节点的位置，则顺时针向前寻找，直到碰到第一个服务器节点，将数据分配到该节点。 新增节点新增了节点S4，那么影响的只是哈希空间S3到S4之间的数据，如原来key4是分配到节点S1，现在分配到了S4。 下线节点节点S2下线，只影响哈希空间S1到S2之间的数据，如原来key2分配到了S2，现在分配到了S3。 虚拟节点优化当服务节点比较少的时候会出现分配不平衡的问题，造成大量数据集中到一个节点上，如下图所示：大部分的哈希空间都会分配到S1上，少量分配到S2上。为了解决这种数据倾斜问题，一致性哈希引入了虚拟节点机制：对每一个服务器节点计算多个哈希，每个计算结果都防止一个此服务器对应的虚拟节点。具体做法可以在服务器IP后面加上编号再计算哈希值。如上图所示，对S1和S2分别虚拟出两个节点，形成四个虚拟节点，数据分配方式不变，不过多了先顺时针找到服务器的虚拟节点，再映射到对应的物理服务器节点。 特点 良好的伸缩性。一致性哈希算法保证了增加或减少服务器时，数据存储的改变最少，比传统的哈希算法大大节省了数据移动的开销。 更好的适应数据增长。当数据不断增长，部分虚拟节点可能包含很多数据，造成数据分配不平衡，此时可以将包含数据多的虚拟节点分裂，这种分裂仅仅是将原有的虚拟节点一分为二，不需要对全部数据重新哈希划分。 参考【1】 图解一致性哈希算法【2】一致性Hash算法详解","categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://harryzhang.cn/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"一致性哈希","slug":"一致性哈希","permalink":"https://harryzhang.cn/blog/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"}]},{"title":"数据库和缓存数据一致性问题如何解决?","slug":"数据库和缓存数据一致性问题如何解决","date":"2023-03-25T07:24:43.000Z","updated":"2026-02-26T06:21:08.423Z","comments":true,"path":"2023/03/25/数据库和缓存数据一致性问题如何解决/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/","excerpt":"","text":"业务使用Redis做缓存，当有数据更新时，如何保证缓存及时更新 读数据流程请求到来，业务代码会先查Redis，查不到再去查DB，并将结果写入Redis 写数据方案1. 先删除缓存，再更新DB可行性先删除缓存，再更新DB，下次读请求到来会从数据库查到新的数据更新到缓存中。如果先更新缓存，在更新DB，更新DB失败会导致数据不一致。 问题容灾不足如果删除缓存失败的情况，如果业务继续进行，更新DB，那么在缓存过期之前仍然查到的是旧数据。如果业务返回失败，则对Redis变成了强依赖。 并发不安全考虑如下场景： A请求删除缓存，A请求更新DB B请求查询缓存，不存在 B请求查询DB，查到旧数据（更新未完成），写入缓存 A请求更新DB完成 这就导致缓存中仍存的旧数据，数据不一致。 2. 先更新DB，再删除缓存这种策略解决了方法1中的并发问题，但是还是有极小可能存在并发问题，考虑如下情况： 请求A查询缓存，缓存刚好失效 请求A查询DB，得到一个旧值 请求B更新数据库 请求B删除缓存 请求A将查到的旧值写入缓存 这种情况确实会产生数据不一致，但是考虑到DB的读操作总是比写操作快的多，这种场景基本不可能出现。 如何杜绝并发问题延迟异步删，保证读操作完成后再删除缓存。 如何容灾上述方案中如果删除缓存失败了怎么办？ 引入消息队列 更新DB 删除缓存，如果失败将要删除的key发送至消息队列 消费消息，获得需要删除的key，删除key缓存直到成功 订阅binlog上述方法对业务代码的侵入性比较大，为此可以启动一个程序订阅MySQL的binlog用来发现数据更新，流程如下： 业务代码更新数据库，MySQL将更新操作写入binlog 订阅程序提取中更新的数据以及key，尝试删除key的缓存 如果删除缓存失败，将key发送至消息队列 消费者程序从消息队列中获取待删除的key，重试删除直到成功。 参考【1】Redis与Mysql双写一致性方案解析","categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://harryzhang.cn/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"一致性","slug":"一致性","permalink":"https://harryzhang.cn/blog/tags/%E4%B8%80%E8%87%B4%E6%80%A7/"},{"name":"Cache-Aside","slug":"Cache-Aside","permalink":"https://harryzhang.cn/blog/tags/Cache-Aside/"}]},{"title":"限流算法有哪些?","slug":"限流算法有哪些","date":"2023-03-25T07:24:13.000Z","updated":"2026-02-26T06:21:08.424Z","comments":true,"path":"2023/03/25/限流算法有哪些/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B/","excerpt":"","text":"为什么要限流？由于Web服务无法控制调用方的行为，当遇到请求并发量超过系统的容量阈值，会导致服务器资源耗尽从而导致服务异常或宕机，而且某个服务的请求量突增还会影响到上游的服务，如DB或者是其他的公共服务，导致整个系统瘫痪。可能导致流量突增的原因有以下几点： 热点业务的突发请求（如大型活动） 调用方bug导致的请求量倍增 恶意攻击的请求 为了对服务进行保护，就需要对请求进行限流。 常见算法固定窗口计数器算法算法思路： 将时间划分为多个窗口 每个窗口内每有一次请求计数器加1 如果计数器超过了限制数量，则本窗口内的所有请求都被丢弃，当时间到达下一个窗口时，计数器重置。 特点：原理和实现都比较简单，但是这种算法可能会让通过的请求量为阈值的两倍。比如当阈值是100时，第一个窗口在0-0.5秒期间没有请求，0.5-1.0秒期间有100个请求，然后到了第二个窗口计数器已经重置，在1.0-1.5秒期间有100个请求，这样看来在0.5-1.5秒的1秒内通过了200个请求。 滑动窗口计数器算法该方法就是对固定窗口计数算法的窗口时间细分更多的区间，并且按照时间在区间上滑动，如下图所示：算法思路： 将时间划分多个区间，维护一个包含多个区间的窗口 每个区间内每有一次请求就将该区间的计数器加1 每经过一个区间时间，丢弃最老的一个区间，加入最新的一个区间 如果当前窗口内区间的请求计数总和超过了限制数量则本窗口内所有新的请求都被丢弃。 特点：将时间划分为更小单位的区间，按时间滑动，避免了固定窗口计数器会产生双倍请求的问题，但是时间区间的精度越高，算法需要的空间容量就越大。 漏桶算法 算法思路： 将每个请求视作“水滴”放入“漏桶”进行存储 漏桶以固定的速率（通常是服务的最大容量）向外漏出请求交给服务器执行 如果漏桶空了则停止漏水，如果漏桶满了则丢弃新来的请求 特点：通常使用消息队列来实现漏桶。该算法能良好的保证瞬时请求量不会超过阈值，但是当短时间内有大量的突发请求时，即使服务器没有负载，每个请求也都需要在队列中等待一段时间才能被响应。 令牌桶算法算法思路： 令牌以固定速录添加到桶中，如果桶满了直接丢弃 请求到达时从桶中取令牌，取到了令牌的请求交给服务器执行 如果桶空了，尝试取令牌的请求就会被拒绝 特点：令牌桶算法既能将流量均匀的分布，又能接受服务器承受的容量范围内的突发请求，因此是目前使用比较广泛的一种限流算法。缺点是突发流量时第一个周期会多放过一些请求。 参考【1】InfoQ：分布式服务限流实战，已经为你排好坑了【2】阿里云：限流算法介绍","categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://harryzhang.cn/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"限流","slug":"限流","permalink":"https://harryzhang.cn/blog/tags/%E9%99%90%E6%B5%81/"},{"name":"漏桶","slug":"漏桶","permalink":"https://harryzhang.cn/blog/tags/%E6%BC%8F%E6%A1%B6/"},{"name":"令牌桶","slug":"令牌桶","permalink":"https://harryzhang.cn/blog/tags/%E4%BB%A4%E7%89%8C%E6%A1%B6/"}]},{"title":"分布式全局唯一 ID 生成方案有哪些？","slug":"分布式全局唯一-ID-生成方案有哪些？","date":"2023-03-25T07:23:45.000Z","updated":"2026-02-26T06:21:08.423Z","comments":true,"path":"2023/03/25/分布式全局唯一-ID-生成方案有哪些？/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80-ID-%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F/","excerpt":"","text":"全局唯一ID要求分布式系统中，我们会对一些数据量大的业务进行拆分，如用户表、订单表，当数据量巨大导致数据库性能下降时，通常会进行分库分表，无法利用MySQL的自增ID，那么就需要一个单独的系统来生成全局唯一ID，而且生成的ID要求具有以下特性： 整个系统全局唯一 ID趋势递增，提高数据库插入的效率（索引是递增的，避免乱序插入提高索引的维护成本） ID简单，占用空间小，查询效率高 常见方案UUID全局唯一首先可以想到使用UUID，基本各种语言都提供了UUID的库 优点： 代码实现简单 本地生成，没有性能问题 全球唯一的，数据迁移容易 缺点： 每次生成的ID是无序的，不满足趋势递增 UUID是字符串，而且比较长，占用空间大，查询效率低 ID没有含义，可读性差 MySQL自增主键单表可以使用MySQL的自增ID，多表的情况下其实也可以使用自增ID，只是和单表每次+1不同，分多表的情况下每次需要加N，具体如下图：上图中共分成了两个库4个表，那么每个表初始值一次为1~4，之后每次自增时+4，这样保证了每个表的ID不会重复，而且是趋势递增的，解决了单表的问题。 缺点：一旦步长定好就无法扩容，数据库单机能力有限，不易于横向扩展 雪花snowflake方案雪花算法生成64位二进制正整数，然后转换为10进制的数，具体方案如下图：最高的一个bit不用，接下来的41个bit表示微秒级的时间（表示范围约69年），再接下来的10个bit机器编号可以分别表示1024台机器，如果对IDC划分，可以将10-bit的高几位表示IDC，最低位的12个字节是一个自增序列，表示范围为2^12&#x3D;4096个，理论上这种方案每秒可以生成的唯一ID数约为4096*1000&#x3D;409.6w个。 优点： 整个ID满足趋势递增 不依赖第三方系统，稳定性和性能都比较高 可以根据自身业务分配bit位，比较灵活 缺点： 强依赖系统时钟，如果系统时钟回拨，会导致ID重复或者服务不可用 Redis利用Redis的incr原子性操作一般方案为年份+月份+小时+Redis自增。 优点： 有序递增，可读性强 性能较高 缺点： 占用带宽，依赖Redis 更优的方案美团的Leaf-segment方案在之前的数据方案中，利用自增id每次从数据库只取了一个id，由于数据库的IO能力有限，不能支持高并发的场景，那么如果一次取一批id，消耗完再取一批，是不是就可以提高并发能力了？具体的方案架构如下：抽象出Proxy Server，用于从数据库批量获取，然后在Leaf内部中逐个消耗分发给用户服务。如图中的数据库表结构：biz_tag用来区分业务，业务之间的id号相互隔离互不影响，每次从数据库取出step个id号，将数据操作次数减少到了1&#x2F;step。对于多个Leaf抢占数据库可以利用MySQL的事务和锁机制，先更新再查询，保证多个Leaf请求的id范围不会重复复。 Begin UPDATE table SET max_id=max_id+step WHERE biz_tag=xxx SELECT tag, max_id, step FROM table WHERE biz_tag=xxx Commit 这样返回给业务服务的ID范围应该是[max_id-step+1, max_id] 优点： Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景 ID是趋势递增的64位数字 高可用：Leaf内部可以使用缓存，即使数据宕机短时间服务仍可用 可以自定义max_id和step，便于业务迁移 缺点： ID号码不够随机，可能导致发号数量的信息 TP999数据波动大，当多个Leaf同时消耗完后，还是会阻塞在数据库更新上，业务可能会出现偶尔的时延毛刺 强依赖DB，DB宕机会导致系统不可用 双buffer优化对于第一个缺点，由于是这个方案设计上的问题不能优化了，但对于第二个缺点，可以作进一步的优化，具体思路如下：之前的方案Leaf从数据库取号段是在号段消耗完的时候进行的，这导致了需要等待从DB取回号段的时间才能返回下一个ID号码，而数据库的操作是比较耗时的，导致Leaf服务阻塞，该次请求时延会突增。为了解决这个问题，希望两次取号段能尽量做到无缝衔接，那么在号段消耗到某个点（比如100&#x2F;1000）的时候异步的就请求DB取下一个号段然后保存在内存中，而不是等到号段用完再同步请求DB，这样就可以很大程度减少因为DB阻塞带来的业务抖动，具体实现如下图：Leaf服务内部采用两个segment buffer，当前号段已下发10%时，如果下一个号段未更新，则启动线程去更新下个号段，这样当buffer1消耗完时buffer2很可能已经更新好了，只需要直接切换当前segment到segment buffer2，然后就可以继续发放号码。两个buffer交替工作，平滑DB带来的I&#x2F;O阻塞。 数据库高可用容灾对于第三个缺点强依赖DB的问题，需要DB高可用，可以采用一主两从的方式，分机房部署（常见的架构有“同城三机房”、“两城三中心”），Master和Slave采用半同步复制同步数据，保证至少有两个节点数据一致且不丢失，同时可以接入中间件来实现主从切换。 参考【1】一线大厂的分布式唯一ID生成方案是什么样的？【2】Leaf——美团点评分布式ID生成系统","categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://harryzhang.cn/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"唯一ID","slug":"唯一ID","permalink":"https://harryzhang.cn/blog/tags/%E5%94%AF%E4%B8%80ID/"},{"name":"snowflake","slug":"snowflake","permalink":"https://harryzhang.cn/blog/tags/snowflake/"},{"name":"leaf","slug":"leaf","permalink":"https://harryzhang.cn/blog/tags/leaf/"}]},{"title":"从五个问题出发认识消息队列","slug":"从五个问题出发认识消息队列","date":"2023-03-25T07:23:17.000Z","updated":"2026-02-26T06:21:08.422Z","comments":true,"path":"2023/03/25/从五个问题出发认识消息队列/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E4%BB%8E%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E5%87%BA%E5%8F%91%E8%AE%A4%E8%AF%86%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","excerpt":"","text":"消息队列消息队列是分布式系统的一个重要组件，从五个问题来初步认识一下消息队列，基本原理是什么样的，如何正确的使用消息队列。 Q1: 为什么需要消息队列？ Q2: 如何保证消息不丢失？ Q3: 如何处理重复消息？ Q4: 如何保证消息有序性？ Q5: 如何处理消息堆积？ 为什么需要异步处理 随着业务的增长，业务逻辑会不断加重，为了保持较快速的响应，可以在核心逻辑处理完后就返回，其他逻辑放到消息队列之后异步处理 应用解耦 业务模块增加，可以通过订阅核心服务的消息主题，不影响核心服务 流量控制 后端服务无法支撑大量的并发请求，请求先放到队列，后端服务尽最大的能力消费队列 日志处理基本概念模型 点对点（队列）模型 同一个消息只能由一个消费者消费一次 Rabbit MQ 发布&#x2F;订阅模型 订阅了某个主题的所有消费者都可以消费该主题的消息 Rocket MQ、Kafka 各个组件术语（Kafka） 生产者（Producer） 消息队列服务器（Broker） 主服务器（Leader） 从服务器（Follower） 主题（Topic） 分区（Partition） 消费者组（Consumer Group） 消费者（Consumer） 工作流程 生产消息（发送数据） 从Kafka Cluster获取分区的Leader，Producer将消息发送给Leader Leader将消息写入本地文件（此时可以直接到步骤3） 2.1. Followers从Leader pull消息并写入本地后向Leader发送ACK确认 Leader向Producer响应ACK 存储数据 单独开辟一块磁盘，顺序写入 每个分区相当于一个文件目录 Partition&#x2F;Segment .index .log .timeindex 消费消息（接收数据） Consumer也是从Leader中拉取数据 一个消费者组内的某个消费者可以消费一个Topic的不同分区，单同一个组内的不同消费者不能同时消费某个Topic的同一个分区，一个组的消费者数量最好和分区数相同 分区的好处 方便扩展 提高并发 实际问题如何保证消息队列不丢失？ 生产消息阶段 正确处理Broker的响应，做重试机制 数据存储阶段 数据落盘再响应成功，有多个副本时可以等多副本都落盘再响应成功 消费消息阶段 业务逻辑处理完再确认消息 确保了可靠性的同时会影响性能，根据业务选择合适的方式 如何处理重复消息？ 为了保证消息不丢失，消息重复是不可避免的 业务逻辑幂等性 增加version版本号做控制 数据库唯一索引 如何保证消息有序？ 全局有序 一个生产者、一个分区、一个消费者 部分有序 消息按特定规则分配到不同的分区，分区本身是有序的，每个分区由一个消费者消费 如何处理消息堆积？ 定位问题，如果是bug引起，修改bug（实际生产场景如果由于发版导致，先回滚再定位原因） 如果不是bug，看能不能优化消费逻辑 如果不能优化，就要横向扩容，同时增加分区数和消费者数量 参考文章1 微信公众号文章参考文章2 知乎","categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://harryzhang.cn/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://harryzhang.cn/blog/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"MQ","slug":"MQ","permalink":"https://harryzhang.cn/blog/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://harryzhang.cn/blog/tags/RabbitMQ/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://harryzhang.cn/blog/tags/RocketMQ/"},{"name":"Kafka","slug":"Kafka","permalink":"https://harryzhang.cn/blog/tags/Kafka/"}]},{"title":"无处不在的微服务","slug":"无处不在的微服务","date":"2023-03-25T07:23:00.000Z","updated":"2026-02-26T06:21:08.423Z","comments":true,"path":"2023/03/25/无处不在的微服务/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"概念基本定义 微服务就是一些协同工作的小而自治的服务 服务注册与发现 微服务之间互相调用，服务发现需要管理各个服务的服务器地址，当进行扩容或摘除时能及时更新 服务监控 监控、日志、调用链、告警通知、健康检查 服务容错 熔断 切换 限流和降级 重试 服务安全 敏感服务进行身份验证和授权 HTTPS传输 隐私数据加密存储 服务治理 引入微服务框架 相比单体架构优点 技术异构性 不同服务内部可以选择不同的语言开发，也可以选择适合各自服务的数据库（MySQL、Redis） 隔离性 一个服务不可用不会导致整个系统或其他服务不可用，各个服务相互独立的 可扩展性 可以只对影响性能的瓶颈资源进行扩展升级 简化部署 单个服务的修改迭代只需要发步自己的改动 易优化 代码量不会很大，重构相对容易且改动带来的影响可控 缺点 管理复杂 难定位问题 微服务框架Dubbo 阿里 仅支持Java语言 Tars 腾讯 仅支持C++语言 Motan 微博 仅支持Java gRPC 谷歌 支持多种语言 thrift Facebook 支持多种语言 微服务框架和RPCRPC（Remote Procedure Call） 允许像调用本地函数一样调用另一个程序的函数（C&#x2F;S模式） 微服务框架 微服务框架一般都包含了RPC的实现和一系列的服务治理能力，是一套软件开发框架，可以基于这个框架实现自己的服务，方便的利用框架提供的服务治理和RPC能力，微服务框架也被某些人称为RPC框架 下一代微服务架构服务网格（Service Mesh） 特点 应用程序间通讯中间层 轻量级网络代理 应用程序无感知 解耦应用程序的重试&#x2F;超时、监控、追踪和服务发现 Service Mesh之于微服务，类似TCP&#x2F;IP之于网络通信 【参考资料】知乎：微服务架构是什么？","categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://harryzhang.cn/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"微服务","slug":"微服务","permalink":"https://harryzhang.cn/blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://harryzhang.cn/blog/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"分布式系统基础知识概述","slug":"分布式系统基础知识概述","date":"2023-03-25T07:21:46.000Z","updated":"2026-02-26T06:21:08.423Z","comments":true,"path":"2023/03/25/分布式系统基础知识概述/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/","excerpt":"","text":"基础性能 性能指标 响应时间 吞吐量（QPS、TPS） 并发用户数：不是越高越好，如果系统来不及处理就会阻塞，响应时间会大大提高 性能优化 集群 缓存（Redis、CDN） 异步 伸缩性 扩容 \b无状态的\b应用服务器可以通过负载均衡器想集群中添加新的节点 关系型数据库可以用过Sharding实现 非关系型数据库对伸缩性支持很好 扩展性 添加新的功能对现有系统的其他应用无影响 使用消息队列进行解耦 分布式服务奖业务可复用的部分\b模块化 可用性 冗余（多点备份，异地双活） 故障切换 服务降级 监控 安全性 应对各种攻击手段 SQL注入 XSS攻击 分布式分布式锁 数据库唯一索引 没有失效时间，解锁失败会造成死锁 只能是非阻塞，插入失败无法重试 不可重入，已获得锁的进程也必须重新获取锁 Redis的SETNX指令 节点挂了就不可用，造成死锁 RedLock \b高可用 Zookeeper的有序节点 分布式事务 两阶段提交（2PC） 准备阶段 协调者询问所有参与者事务执行的结果 提交阶段 \b协调者根\b据所有参与者返回的结果判断最终是提交还是回滚 \b存在问题 同步阻塞 单点故障 数据不一致 本地消息表 1.\b 分布式事务操作方完成写业务数据后向本地消息表发送一个消息，\b确保这个消息一定会写入本地消息表 之后将本地消息表中的消息转发到消息队列，转发成功则从本地消息表删除，否则继续重发 分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作 CAP 分布式系统不可能同时满足\b 一致性（Consistency） 分区容忍性（Partition Tolerance） 可用性（Availability） 权衡 分区容忍性必不可少，可用性和一致性的权衡 为了保证一致性，不能访问未同步完成的节点，就失去了部分可用性 为了保证可用性，允许读取所有节点的数据，但是数据可能不一致 BASE 概念 基本可用（Basically Available） \b分布式系统在\b故障的时候保证核心可用，允许\b损失部分可用性 软状态（Soft State） 允许\b系统中的数据存在中间状态，并认为\b该中间状态不会影响整体可用性 最终一致性（Eventually Consistent） 系统中的所有数据副本在经过一段时间的同步后，最终能达到一致性的状态 竞选协议 Paxos 执行过程 Prepare Accept Learn 约束条件 正确性 可终止性 Raft 集群负载均衡 算法 轮询 服务器性能均衡的场景 加权轮询 轮询的基础上根据权重分配 最少连接 将请求发送给当前最少连接的服务器上 加权最少连接 根据权重结算最少连接 随机算法 源地址哈希 对\b客户端IP计算哈希值取模 转发实现 HTTP重定向 返回302重新发起请求 延迟高，处理能力有限 \bDNS域名解析 解析域名同时使用负载均衡\b算法计算服务器IP 优点：能根据地理位置进行域名解析，可以返回最近的服务器 缺点：DNS多级缓存，当\b下线机器需要修改DNS记录，生效时间慢 反向代理 \bOpenresty&#x2F;Nginx 缺点：所有请求和响应都要经过反向代理服务器，容易成为瓶颈 网络层 链路层 LVS Session管理 Sticky Session Session Replication Session Server Redis、MySQL 攻击技术跨站脚本攻击：XSS（Cross-Site Scripting）跨站请求伪造：CSRF（Cross-Site request forgery） 检查Referer头 添加token校验 验证码 SQL注入 sql quote预处理 拒绝服务攻击（DoS、DDoS）一致性哈希基本原理 将哈希空间看做一个环，每个节点都配置在环上，每个数据对象通过哈希取模得到哈希值后，顺时针向前走，存放在碰到第一个节点上 分布不均问题 虚拟节点解决 LRU消息队列消息模型 点对点 生产者向MQ中发送了一个消息后，只能被一个消费者消费一次 发布&#x2F;订阅 生产者向频道发送了一个消息后，多个消费者可以从该频道订阅这条消息并消费 使用场景 异步处理 流量削峰 应用解耦 可靠性 发送端可靠性 本地消息表 接收端可靠性 幂等性 唯一消息ID 【参考文章】GitHub-CyC2018&#x2F;CS-Notes","categories":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://harryzhang.cn/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://harryzhang.cn/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"CAP","slug":"CAP","permalink":"https://harryzhang.cn/blog/tags/CAP/"},{"name":"BASE","slug":"BASE","permalink":"https://harryzhang.cn/blog/tags/BASE/"}]},{"title":"MySQL 连接错误问题解决","slug":"MySQL-连接错误问题解决","date":"2023-03-25T07:15:48.000Z","updated":"2026-02-26T06:21:08.419Z","comments":true,"path":"2023/03/25/MySQL-连接错误问题解决/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/MySQL-%E8%BF%9E%E6%8E%A5%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","excerpt":"","text":"软件环境 操作系统：Ubuntu16.04-server MySQL版本：5.7.25 故障一只能通过localhost登录MySQL 报错如下 $mysql -h172.16.0.1 -uroot -p123456mysql: [Warning] Using a password on the command line interface can be insecure.ERROR 1130 (HY000): Host ‘172.16.0.1’ is not allowed to connect to this MySQL server 解决方法此处参考自：https://stackoverflow.com/questions/19101243/error-1130-hy000-host-is-not-allowed-to-connect-to-this-mysql-server 首先查看你的root用户允许的主机ip mysql&gt;SELECT host FROM mysql.user WHERE User &#x3D; ‘root’;+———–+| host |+———–+| localhost |+———–+1 row in set (0.24 sec)一般结果中只有localhost或同时有localhost和127.0.0.1； 然后如果你想指定允许某个ip可访问可执行如下命令 CREATE USER &#39;root&#39;@&#39;ip_address&#39; IDENTIFIED BY &#39;some_pass&#39;;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;ip_address&#39;; 如果想要允许所有ip执行如下命令 CREATE USER &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;some_pass&#39;;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39;; 上面两种最后都要flush启用更改 FLUSH PRIVILEGES; 然后在执行一次查询会发现结果多了一行“%”，说明更改成功+———–+| host |+———–+| % |+———–+| localhost |+———–+1 row in set (0.24 sec)再次登录如果仍旧失败，请看故障2 故障二 报错如下 $mysql -h172.16.0.1 -uroot -p123456mysql: [Warning] Using a password on the command line interface can be insecure.ERROR 2003 (HY000): Can’t connect to MySQL server on ‘172.16.0.1’ (111) 解决方法 查看mysql的配置文件 $vim &#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf 将下面一行注释或者修改 注释#bind-address = 127.0.0.1修改bind-address = 0.0.0.0 重启mysql启用更改 $service mysql restart 再次尝试登录即可成功登录！","categories":[{"name":"数据库","slug":"数据库","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://harryzhang.cn/blog/tags/MySQL/"}]},{"title":"MySQL ORDER BY 如何实现排序的?","slug":"MySQL-ORDER-BY-如何实现排序的","date":"2023-03-25T07:12:42.000Z","updated":"2026-02-26T06:21:08.417Z","comments":true,"path":"2023/03/25/MySQL-ORDER-BY-如何实现排序的/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/MySQL-ORDER-BY-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%8E%92%E5%BA%8F%E7%9A%84/","excerpt":"","text":"MySQL是如何进行排序的？假设有一个表t结构如下图所示： id为主键，type上建有索引，那么如果要查类型为1，val最小的1000行，那么SQL语句如下：SELECT type, val, detail FROM t WHERE type = 1 ORDER BY val LIMIT 1000; 全字段排序对上述查询执行explain结果如下： Using filesort表示需要排序，MySQL会给每个线程分配一块内存用来排序，称为sort buffer，具体的流程如下： 初始化sort buffer，确定放入type，val，detail三个字段 从索引type中找到第一个满足type&#x3D;1条件的主键id 根据id回主键索引查询type和val的值存入sort buffer中，从索引type中继续取下一个id 重复3的操作直到type不满足条件 对sort buffer中的数据按照val字段做快速排序 按照排序结果取前1000行返回 如果sort buffer够存下所有需要排序的记录，排序在内存中完成，如果内存放不下则需要借助磁盘临时文件进行外部排序。 rowid排序全字段排序过程里只对原表扫描的一遍，剩下的操作都是在sort buffer 和临时文件中执行的，但是如果要查询的字段比较多，sort buffer能存的行数就很少，需要分成多个临时文件进行外部排序，性能比较差，所以在单行数大的情况下这种方式明显不合适。 MySQL的参数max_length_for_sort_data表示如果单行记录长度超过这个值，就认为单行太大，要换一种排序算法，排序过程中只放要排序的列和主键id，执行流程如下： 初始化sort buffer，放入val，id字段 从索引type中找到第一个满足type&#x3D;1条件的主键id 根据id回主键索引查询val的值，将val和id存入sort buffer中，从索引type中继续取下一个id 重复3的操作直到type不满足条件 对sort buffer中的数据按照val字段做快速排序 按照排序结果依次取1000行，并按照id值回表取出type，val，detail三个字段返回 可以看到改流程与全字段排序的主要区别在于： 第1步放入sort buffer的字段不同，rowid排序只放入排序字段和id，全字段排序放入查询的全部字段 第6步，rowid排序完成后要再回主键索引查一次全部数据返回，全字段排序因为所以要返回的字段内容都在sort buffer中了所以直接返回 说明：结果集只是一个逻辑概念，实际上MySQL从排序后的sort buffer中依次取出id，然后到原表查询所有字段的结果不需要在服务端再消耗内存保存，是直接返回的。 联合索引避免排序上面两种方法都是需要建临时表进行排序的，对于MySQL来说都是成本比较高的操作。但并不是所有order by都是需要排序的，因为MySQL索引是天然有序的，如果在type和val字段创建一个联合索引idx_type_val，那么该查询就不需要排序了，这时执行过程就变成了如下流程： 在索引idx_type_val上找到第一个满足type&#x3D;1条件记录 根据索引上的主键id回主键索引查询所有字段的值返回，在idx_type_val索引上继续取一下个值 重复2的操作直到不满足type&#x3D;1或者超过1000行结束。 使用联合索引，首先不在需要建临时表做排序，其次也不需要扫描出满足type&#x3D;1条件的所有记录，因为索引有序直接扫描前1000行就结束了，大大减少了扫描的行数。 优先队列排序对于MySQL来说并不是所有的排序都是用快速排序实现的，假如之前的查询变成了如下：EXPLAIN SELECT type, val FROM t WHERE type = 1 ORDER BY val LIMIT 3;假设type&#x3D;1的记录有1万条，只需要去前val最小的前三行。 对于这种情况，即使sort buffer不能放下1万行记录，会发现MySQL也没有使用到临时文件，这时因为选择了另一种算法：优先队列算法。 算法流程 对于这10000准备排序的记录，先取前三行构造一个最大堆 取下一行Next记录跟当前堆顶记录Top比较，如果Next.val &lt; Top.val，就把堆顶记录弹出，将Next记录放入堆 重复2的操作直到取出所有10000行记录，最后堆中的三个记录就是最小的三个 复杂度快速排序时间复杂度是O(N*logN)，优先队列排序时间复杂度为O((N-K)*logK)，K表示堆的大小，即返回记录的个数，对于该场景下为(N-3)*log3，基本可以看做线性时间复杂度，如果是limit 1的时候就相当于求最小值，该算法就是线性时间复杂度。其次sort buffer中只需要维护堆，内存的消耗也大大减少，空间复杂度为O(K)。 order by rand()如果需要随机选1个数，SQL语句可能如下：SELECT * FROM t ORDER BY RAND() LIMIT 1需要注意到是这种方式会建临时表进行排序，临时表除了查询字段会多加一个排序字段存放rand()生成的值，即对每一行记录使用rand()函数生成一个随机数，然后根据这个数来排序。 这种写法的成本是比较高的，所以建议尽量避免这种写法，建议先随机一个0~N-1的值（N表示表总行数），然后去查数据库的某行，比如： def rand1(): N = mysql.query(&quot;select count(*) from t&quot;) res = mysql.query(&quot;select * from t limit N, 1&quot;) return res 参考【极客时间】MySQL实战45讲：16、17","categories":[{"name":"数据库","slug":"数据库","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://harryzhang.cn/blog/tags/MySQL/"},{"name":"排序","slug":"排序","permalink":"https://harryzhang.cn/blog/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"MySQL 脏页刷盘","slug":"MySQL-脏页刷盘","date":"2023-03-25T07:12:03.000Z","updated":"2026-02-26T06:21:08.418Z","comments":true,"path":"2023/03/25/MySQL-脏页刷盘/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/MySQL-%E8%84%8F%E9%A1%B5%E5%88%B7%E7%9B%98/","excerpt":"","text":"什么是脏页？InnoDB在处理更新语句时，先写内存再写redo log，并不会立即将数据页的更新落地到磁盘（WAL机制），这就会产生升内存数据页和磁盘数据页的数据不一致的情况，这种数据不一致的数据页称为脏页，当脏页写入到磁盘（这个操作称为flush）后，数据一致后称为干净页。 什么时候会flush脏页？ redo log写满redo log大小是固定的，写完后会循环覆盖写入。当有新的内容要写入时，系统必须停止所有的更新操作，将checkpoint向前推进到新的位置，但是在推进之前必须将覆盖部分的所有脏页都flush到磁盘上。 内存不足需要淘汰数据页当系统内存不足，又有新的数据页要更新，就需要淘汰一些数据页，如果淘汰的是脏页，就需要flush到磁盘（如果是干净页就直接释放出来复用）。 系统空闲的时候后台会定期flush适量的脏页到磁盘 MySQL正常关闭（shut down）时会把所有脏页都flush到磁盘 flush对系统性能的影响第3种是系统空闲不会有性能问题，第4种是要关闭了不考虑性能问题。第1和2的情况flush脏页会产生系统性能问题。 redo log写满此时整个系统不能再更新了，更新数会降为0，所以这种情况要尽量避免。 内存不够InnoDB缓冲池（buffer pool）中的内存页有三种状态： 未使用的空闲内存 使用了为脏页 使用了未干净页 当一个SQL语句要淘汰的脏页数量太多，会导致语句执行的响应时间显著边长。 flush速度控制策略InnoDB为了避免出现上述两种情况，需要有控制脏页比例的策略，控制的主要参考因素就是：脏页比例和redo log写盘速度。 磁盘的IO能力需要告诉InnoDB的磁盘读写能力（IOPS）让引擎全力flush脏页，磁盘的IOPS可以通过fio工具测试。 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 如果innodb_io_capacity参数设置的不合理，比如远远低于磁盘实际的IOPS，InnoDB会认为IO性能低，刷脏页速度会很慢，甚至低于脏页的生成速度，导致脏页累计影响查询和更新性能。 速度计算流程为了兼顾正常的业务请求，InnoDB引擎控制按照磁盘IOPS的百分比来刷脏页，具体流程如下： 参数innodb_max_dirty_pages_pct控制脏页比例上限，默认75%。InnoDB根据当前脏页比例（设为M），计算出一个0~100的数字F1(M)，伪代码如下 def F1(M): if M &gt;= innodb_max_dirty_pages_pct: return 100 return 100 * M / innodb_max_dirty_pages_pct InnoDB每次写入的日志都有一个序号，当前写入的序号跟checkpoint对应的需要之间的差值设为N，根据N计算出一个0~100的数值F2(N)，N越大F2(N)越大 根据前两步计算出的两个值取较大值记为R，然后InnoDB会根据innodb_io_capacity设置的磁盘IOPS能力乘以R%来控制刷脏页的速度 脏页比例计算:Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_totalSQL语句如下： select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = &#39;Innodb_buffer_pool_pages_dirty&#39;; select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = &#39;Innodb_buffer_pool_pages_total&#39;; select @a/@b; 连锁flush在准备flush一个脏页时，如果相邻的数据页也是脏页，会把这个脏页一起flush，而且对这个新的脏页还可能有相邻的脏页导致连锁flush。InnoDB使用innodb_flush_neighbors参数控制这个行为，值为1会产生上述连锁flush的情况，值为0则不会找相邻页。 找相邻页flush的机制虽然可以减少很多随机IO，但会增加一次flush时间，导致flush时的SQL语句执行时间变慢。 现在基本都使用的SSD这种IOPS比较高的硬盘，建议将innodb_flush_neighbors参数设为0，提高flush的速度。 总结flush会占用IO资源影响了正在执行的SQL语句，本来正常情况下执行很快的一条语句，突然耗时大大增加，造成业务抖动。要尽量避免这种情况，需要合理的设置innodb_io_capacity的值，并且多关注脏页比例，不要让脏页比例经常接近75%。 参考资料【极客时间】MySQL实战45讲：第12节","categories":[{"name":"数据库","slug":"数据库","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://harryzhang.cn/blog/tags/MySQL/"},{"name":"脏页","slug":"脏页","permalink":"https://harryzhang.cn/blog/tags/%E8%84%8F%E9%A1%B5/"}]},{"title":"MySQL 索引原理详解","slug":"MySQL-索引原理详解","date":"2023-03-25T07:11:48.000Z","updated":"2026-02-26T06:21:08.418Z","comments":true,"path":"2023/03/25/MySQL-索引原理详解/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/MySQL-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"索引的底层实现InnoDB存储引擎数据结构使用B+树 B+树B+数据的基本结构如下图 为什么选用B+树MySQL为什么要选B+树作为存储结构呢，与B树相比有哪些优点？ 1. 减少磁盘访问，提高查询效率B+树非叶子节点上是不存数据的，仅存键值，而B树节点中不仅存储键值，也会存储数据。因为数据页的大小是固定的（InnoDB中页的默认大小是16KB），如果不存储数据，那么就会存储更多的键值，相应的树的阶数N就会更大，树高就会越低，这样查询数据进行磁盘IO的次数就会大大减少，数据查询的效率也会更快。以InnoDB的一个整数字段索引为例，阶数N大概是1200，这棵树高是4的时候，就可以存1200^3（约17亿）个值，因为根节点总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。 2. 提高范围查找效率因为B+树的所有数据均存储在叶子节点，而且是有序的，使得B+树范围查找，排序查找，分组查找以及去重查找变的简单，而B树的数据分散在各个节点上，实现起来比较困难。 普通索引和唯一索引如何选择？普通索引不需要保证一条记录的唯一性，查询和更新操作都不需要保证数据页已经读到内存中，相反唯一索引为了保证唯一性，更新时必须要保证数据页在内存中，需要检查是否满足唯一性 查询操作的区别 普通索引：查找到满足条件的第一个记录后，需要查找下一条记录，直到碰到不满足的记录 唯一索引：查找满足条件的第一个记录就会停止检索 因为是innoDB的读写操作是以数据页为单位的，通常情况目标记录的下一个记录也会在内存中，对于普通索引来说，只是多了一次判断操作，这个CPU成本可以忽略不计，如果是目标记录恰好在某页的最后，下一条记录需要从磁盘中读取，这个I\\O成本会大一些，但是这种情况出现的概率很低。所以对于查询操作来说，唯一索引更快，但是性能差异非常小。 更新操作的区别change buffer当更新一个数据页时，如果数据页在内存中就直接更新，如果数据页还没有在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存再change buffer中，这样就不用从磁盘中读入数据了，大大提高了更新操作的性能。InnoDB会在下次访问这个数据页的时候将数据页读入内存然后执行change buffer中与这个页有关的操作，保证数据的最终一致性。 change buffer是可持久化的数据，也会被写到磁盘中，写入change buffer操作也会记录在redo log中。 merge：将change buffer中的操作应用到原数据页的过程称为merge，merge除了在查询操作时会触发，系统后台有线程会定期merge，数据库正常关闭（shut down）时也会执行merge操作。 优点： 减少读磁盘，明显提升更新操作的速度 数据读入内存会占用buffer pool，可以减少内存使用，提高内存利用率 使用条件： 唯一索引的更新操作需要判断唯一性约束，必须将数据读到内存中才能判断，因此唯一索引的更换不能使用 只有普通索引可使用 change buffer使用的是buffer pool中的内存，因此不能过大。 应用场景： 写多读少的业务，如账单、日志类的系统 如果业务更新后马上会做查询，那么merge的操作会被触发，这样随机访问磁盘的次数不会减少还增加了change buffer的维护代价，反而起到了反作用。 索引的选择 在业务保证唯一性的前提下，尽量选择普通索引。 如果更新后面马上伴随这查询，应该关闭change buffer change buffer和redo log使用change buffer的更新语句执行的过程： 如果数据页在内存中，直接更新内存 如果数据页不在内存中，在change buffer中记录更新操作 将1或2的动作记录在redo log中 区别 redo log主要是节省随机写磁盘的IO消耗（转为顺序写） change buffer主要节省随机读磁盘的IO消耗 为什么MySQL优化器会选错索引优化器选择索引的目的是找一个最优的方案，并用最小的代价去执行语句，扫描行数是影响执行速度的代价之一，扫描行数越少，意味着访问磁盘数据越少，消耗的CPU资源也越少（扫描行数并不是唯一判断标准，还会结合是否使用临时表、是否排序等因素进行综合判断）。在不涉及临时表和排序的情况下，选错索引肯定是在判断扫描行数的时候出错了 扫描行数如何计算的执行语句前MySQL并不能精确的知道这个条件的记录有多少条，只能根据统计信息来估算扫描记录数。 索引的基数一个索引上不同的值越多，这个索引的区分度就越好，而一个索引上不同的值的个数称为基数，基数越大说明区分度越好。 基数的计算MySQL使用采样统计（选择采样而不是全表扫描是为了节省计算成本）： InnoDB默认会选择N个数据页，统计这些页面上的不同值得到一个平均值，然后乘以索引的页面数得到基数。 数据表持续更新的过程中，当变更的数据行占比超过1&#x2F;M的时候，会自动触发做一次索引统计 解决方案 当发现explain的结果预估的rows值跟实际差距比较大可以使用analyze table命令解决 使用force index()强行选择某个索引 优化SQL语句引导MySQL选择更合适的索引 新建一个更合适的索引 字符串前缀索引给一个字符串字段上加索引有如下两种选择： 整个字符串加索引：alter table user add index idx_email(email); 前六个字符索引：alter table user add index idx_email(email(6)); 优点 前缀索引的索引结构只保存了前n个字符，索引占用的空间会更小 使用前缀索引定义合适的长度，即可以节省空间，又不会增加太多查询成本 缺点 增加了查询额外扫描次数，需要查找到所有前缀匹配的记录，每条记录都要回表查询完整数据进行判断。 使用前缀索引会破坏覆盖索引（查询字段上都建了索引，不需要回表）对查询性能的优化 其他方式 倒序存储加前缀索引：当字符串的前n为重复度高的情况 hash字段：添加一个hash字段，保存字符串字段的校验码（如crc32） 这两种方法都不支持范围查找，都会产生额外的cpu计算消耗，hash字段的查询性能更稳定，crc32计算的值冲突概率非常小。 独立索引必须是独立的索引字段才能用到索引，在索引上使用函数、表达式都会导致不能使用索引树搜索，从而导致慢查询。 CASE1：在索引上使用函数建表语句如下： CREATE TABLE `tradelog` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `operator` int(11) DEFAULT NULL, `t_modified` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`), KEY `t_modified` (`t_modified`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 如果要查询几年内某个月的交易总数，查询语句可能如下：select count(*) from tradelog where month(t_modified)=7;索引上使用函数可能会导致其失去有序性，从而不能使用树搜索（不代表使用索引，可以在索引上遍历），即使没有改变索引的有序性优化器还是不能用索引快速查找，所以要避免这种写法。 CASE2：隐式类型转换假如有如下语句：select * from tradelog where tradeid=110717;tradeid字段是varchar类型，如果要和数字作比较会将其转换为数字类型，对于优化器来说上述语句相当于:select * from tradelog where CAST(tradid AS signed int) = 110717;可以看到隐式的在索引字段上使用了函数，从而导致不能使用树搜索。 CASE3：隐式编码转换如果在做连表查询是，驱动表和被驱动表的字段编码类型不一致，会导致索引不能使用树搜索。 参考资料【极客时间】MySQL实战45讲：09、10、11节","categories":[{"name":"数据库","slug":"数据库","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://harryzhang.cn/blog/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://harryzhang.cn/blog/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"MySQL 中一条 SQL 语句是如何执行的？","slug":"MySQL-中一条-SQL-语句是如何执行的？","date":"2023-03-25T07:11:22.000Z","updated":"2026-02-26T06:21:08.418Z","comments":true,"path":"2023/03/25/MySQL-中一条-SQL-语句是如何执行的？/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/MySQL-%E4%B8%AD%E4%B8%80%E6%9D%A1-SQL-%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/","excerpt":"","text":"SQL语句执行的经过从用户发起请求，到服务接口调用MySQL驱动，MySQL服务器执行完SQL语句返回结果中间发生了什么？首先放一张图来看整个过程使用到的各个组件，然后再对各个过程进行分析。 1. 连接过程以Openresty服务器为例，Openresty是多进程+I&#x2F;O多路复用结构（Nginx的I&#x2F;O模型），可以支撑高的并发，一个Worker就是一个进程，一个进程可以处理多条请求。我们知道当需要执行SQL语句时需要先于MySQL服务器建立连接，如果每个一个请求都建立一个连接，使用完再关闭连接，如果频繁的创建和销毁连接显然是不合理的，浪费系统资源造成性能下降，这时连接池就出现了。 连接池连接池会维护多个（长）连接，一个SQL语句执行时分配一个连接，使用完不会销毁连接，而是放到空闲队列中等待下次使用，这样可以在高并发的场景大大减少创建、销毁连接带来的性能问题。 连接器类似Web服务器通过连接池维护与数据库服务器的连接，MySQL的连接器提供了同样的功能，也维护了一个连接池，不同的是MySQL连接器同时还有权限验证的功能。 修改密码不会影响已经建立的链接。 连接完成后如果没有操作，改连接就会处于空闲状态，可以使用show processlist命令查看，如果长时间没有操作连接器会在到达超时时间后断开它。 长连接长连接是客户端持续有请求，使用的是同一个连接，建立连接的过程通常是比较慢的，建议尽量使用长连接。但是长连接累计较多时可能会导致内存过大（内存管理在连接对象里），比系统强行kill，引起MySQL异常重启，可以使用以下两种方法解决： 定期断开长连接。 如果是MySQL5.7及以上的版本，可以在每次执行一个比较大的操作后执行mysql_reset_connection重新初始化连接资源（不会重新建立连接）。 2. 执行过程查询缓存如果是查询语句，而且开启了查询缓存，连接器拿到一个查询请求后，会先查看查询缓存是否有（之前执行过这条语句）。缓存key为sql语句，value是查询结果。 不建议开启查询缓存，除非是基本不会变的数据表。因为只要对表有更新，该表上的所有查询缓存都会清空，导致查询命中率很低。 分析器分析器的功能就是对SQL语句做词法分析和语法分析，解析这条语句要干什么，语法错误会返回错误提醒。 优化器优化器是在表中有多个索引的时候决定使用哪个索引，或者有多表关联（join）的时候决定各个表的连接顺序。 执行器通过分析器知道了要做什么，优化器知道了改怎么做，执行器就是真正的语句执行阶段。开始执行的时候要先判断对表是否有权限（在优化器之前也会做预检查）。执行器会调用存储引擎提供的接口进行读写操作。 3. 更新语句执行过程查询语句是只读的，比较简单，经过一系列组件最终查询到结果返回。但是更新语句就相对复杂一些，涉及到两个日志模块：redo log和binlog。 redo log（重做日志）如果每次更新都要刷盘，整个过程磁盘IO成本、查询成本都比较高，为了提升更新效率，InnoDB引擎提供了redo log（顺序写入速度很快）。 WAL（Write-Ahead Logging）：先写日志，再写磁盘。当有一条记录需要更新的时候，InnoDB引擎会先将记录写入redo log并更新内存，这时候更新就算完成了，再需要的时候再将这个操作更新到磁盘里。 日志结构：redo log大小是固定的，比如配置一组4个文件，每个文件1G，就可以记录总共4G的记录。从头开始写，写完后又回到开头循环写入。 crash-safe：故障安全，redo log除了能提高更新操作的效率，同时还保证了故障安全，在数据库异常时不会导致数据丢失。 binlog（归档日志）MySQL最开始没有InnoDB引擎，binlog日志只用于归档和复制，只依靠binlog没有crash-safe能力。 redo log是InnoDB引擎独有的，属于存储层；binlog是MySQL提供的，属于server层 redo log是物理日志，记录在某个数据页上做了什么修改；binlog是逻辑日志，记录SQL语句的原始逻辑 redo log是循环写的，空间固定，用完会从头开始写；binlog是追加写的，一定大小后切换到下一个文件，不会覆盖 Buffer Pool缓冲池InnoDB重要的内存结构，数据的操作都是在Buffer Pool中操作的，如果数据不在缓冲内存中，会先从磁盘中读取到数据页到缓冲池，然后再执行相关操作。 update执行过程update T set k = k + 2 where id = &#39;1&#39; limit 1 执行器调引擎读接口找id&#x3D;2这一行，如果数据页本来在内存就直接返回，否则先从磁盘load到内存中再返回。 然后执行器将k值加上2，得到新的一行数据，在调用引擎的写接口写入这行新数据。 引擎将这行数据更新到内存中，同时将更新操作记录到redo log，此时redo log处于prepare状态，然后告知执行器执行完成，可以提交事务。 执行器生成这个操作的binlog并写入磁盘。 执行器调用存储引擎的事务提交接口，引擎把刚写入redo log改为commit状态，更新完成。 两阶段提交保证了crash-safe能力，如果不使用两阶段提交，使用binlog恢复数据库时会导致与原数据库状态不一致。 假如不使用两阶段提交，在写日志时机器发生故障： redo log写入（比如k，本来为0，执行更新后k &#x3D; 2）后发生故障，binlog未写入。由于redo log写完之后即使系统崩溃，也会能将数据恢复，恢复后这一行数据k&#x3D;2。但是binlog没写完就crash，binlog没有记录这条语句，如果使用binlog来恢复时会少一个事务，恢复后的k&#x3D;0，原数据库k&#x3D;2。 binlog写入后发生故障，redo log未写入。redo log为写入，崩溃后这个事务无效，k&#x3D;0。但是binlog已经记录了更新语句，之后恢复时会多出一个事务，恢复后k&#x3D;2，原数据库k&#x3D;0。 总结 MySQL连接器使用连接池维护连接，并进行检查权限，接收一个SQL语句 然后通过分析器、优化器知道如何执行SQL语句 通过执行器与存储引擎交互，完成数据的读写。 数据更新同时会写入两个重要的日志文件：redo log和binlog，并通过两阶段提交保证了crash-safe能力。 参考资料【码农有道】详解一条 SQL 的执行过程【极客时间】MySQL实战45讲01、02讲","categories":[{"name":"数据库","slug":"数据库","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://harryzhang.cn/blog/tags/MySQL/"},{"name":"SQL语句","slug":"SQL语句","permalink":"https://harryzhang.cn/blog/tags/SQL%E8%AF%AD%E5%8F%A5/"}]},{"title":"MySQL 和 NoSQL基础知识概述","slug":"MySQL-和-NoSQL基础知识概述","date":"2023-03-25T07:10:58.000Z","updated":"2026-02-26T06:21:08.418Z","comments":true,"path":"2023/03/25/MySQL-和-NoSQL基础知识概述/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/MySQL-%E5%92%8C-NoSQL%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/","excerpt":"","text":"MySQL索引 B+Tree 平衡树，查找树，所有叶子节点位于同一层 进行查找时首先再根节点进行二分查找，找到一个key所在的指针，然后递归的在指针所指向的节点进行查找，直到查到叶子节点，然后在叶子节点二分查找，找出key所对应的data 插入删除操作会破坏数的平衡性，需要进行分裂、合并、旋转等操作来维护平衡性 与红黑树相比 B+树的高度更低 更适合磁盘访问，节点大小设置和磁盘页大小一致 磁盘预读，减少I&#x2F;O MySQL索引 索引类型 B+Tree索引 大多数MySQL存储引擎的默认索引类型 有序性保证查找、排序、分组效率更高 可以指定多个列为索引列，多个索引列共同组成键 适用于全键值、键值范围和键前缀（只支持最左前缀）查找 主索引和辅助索引 主索引的叶子节点data域记录着完整的数据记录，称为聚簇索引，一个表只能有一个聚簇索引 辅助索引的叶子节点域记录着主键的值，因此使用辅助索引要先查到主键的值，再到主索引查数据 哈希索引 O(1)查找，但失去了有序性 无法用于排序和分组 只支持精确查找，不能用于部分查找和范围查找 InnoDB自适应哈希索引，当某个索引值被使用的非常频繁时，会在B+Tree索引只上再建一个哈希索引，以实现快速的哈希查找 全文索引 查找文本中的关键字而不是等值比较 空间数据索引 索引优化 独立的列：索引列不能是表达式的一部分，也不能是函数的参数，否则不会使用索引 多列索引：需要使用多个列作为条件查询时，使用多列索引比使用单列索引性能更好 索引列的顺序：选择性强的索引列放在前面 前缀索引：对于BLOB、TEXT、VARCHAR类型的数据，必须使用前缀索引，只索引开始的部分字符 覆盖索引：索引包含所有需要查询的字段的值 索引通常远小于数据行的大小，只读取索引能减少数据访问量 一些存储引擎（MyISAM）在内存中只缓存索引，只访问索引可以不使用系统调用 对于InnoDB引擎，若辅助索引能够覆盖查询，则无需访问主索引 优点 大大减少需要扫描的数据行数 帮助服务器避免进行排序和分组，以及避免创建临时表 将随机I&#x2F;O变为顺序I&#x2F;O 使用条件 对于非常小的表大部分情况下全表扫描更高效（如用来保存配置信息的表） 对于中型大型的表，使用索引的效果非常明显 对于特大型的表，建立和维护索引的代价会随之增长 分区 分库分表 查询性能优化 使用Explain进行分析 Select_type：查询类型，如简单查询，联合查询、子查询 key：使用的索引 Rows：扫描的行数 优化数据访问 减少请求的数据量 只返回必要的列，拒绝无脑select * from… 只返回必要的行，使用limit限制返回的数据数量 缓存重复查询的数据 减少扫描的行数 用索引覆盖查询 重构查询方式 切分大查询 分解大连接查询（将一个大连接查询分解成对每个表进行 一次单表查询，然后在应用程序中进行关联） - 让缓存更高效，分解后多个查询，即使一个表发生改变，其他表的缓存仍然可以使用 - 单表查询的结果可能被其他查询用到，减少冗余记录的查询 - 减少锁竞争 - 应用层进行连接，更容易对数据库进行拆分，从而更容易做到高性能和可伸缩 - 查询本身效率提升 存储引擎 InnoDB MySQL默认的事务型存储引擎 实现了四个标准的事务隔离级别 主索引是聚簇索引，在索引中保存了数据，对查询性能很大提升 内部做了优化，比如磁盘读取数据时采用可预测性读，自动创建自适应哈希索引，能加快插入操作的插入缓冲区 支持真正的在线热备份 MyISAM 设计简单，提供了很多特性，如压缩表、空间数据索引 不支持事务、不支持行级锁 如果不是特殊特性需要，建议都使用InnoDB引擎 复制 主从复制 binlog线程：负责将主服务器上的数据更改写入二进制日志中 I&#x2F;O线程：负责从主服务器上读取binlog，并写入从服务器的中继日志（Relay Log） SQL线程：负责读取中继日志，解析出SQL更改并在从服务器中重放（Replay） 主从复制不是强一致性，只能保证最终一致性 复制模式 异步模式 主节点不会主动push binlog，同步不及时 半同步复制 主节点只需要接收到一台从节点的返回信息就会commit，否则会等到超时然后切换成异步模式再提交，不保证从节点写入db。减少了数据延迟，响应时间会变长 全同步复制 全同步模式是主节点和从节点全部执行了commit并确认才会想客户端返回成功。响应时间最长 读写分离 优点 主从服务器负责各自的读写，减少锁竞争 增加冗余，提高可用性 中间件 MySQL-Proxy MySQL-Router MyCat binlog的业务应用 数据异构 随着业务发展，一些表各个业务都关注，但是对字段的使用场景不同。如订单表，可以通过binlog解析成用户维度的订单信息供用户中心查询、商户维度的订单表供运营管理、审计等 缓存更新 客户端更新了数据，缓存还未过期，可以通过binlog获取数据变更，并同步到缓存中 任务分发 多个系统依赖同一块重要数据，当数据发生变化需要通知其他系统。可以由调度系统订阅binlog进行相应的任务分发、消息发送 NoSQLnot only sqlKV型 Redis 搜索型 ElasticSearch 列式 HBase 海量数据存储，数据持久化 读写性能好 横向扩展再关系型数据库中最方便的之一 本身没有单点故障，高可用 可存储结构化或半结构化的数据 比较重，依赖Hadoop组件，运维成本高 KV式，条件查询弱 不支持分页查询 文档型 MongoDB 【参考资料】GitHub-CyC2018&#x2F;CS-Notes","categories":[{"name":"数据库","slug":"数据库","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://harryzhang.cn/blog/tags/MySQL/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://harryzhang.cn/blog/tags/NoSQL/"}]},{"title":"数据库基础知识概述","slug":"数据库基础知识概述","date":"2023-03-25T07:10:28.000Z","updated":"2026-02-26T06:21:08.423Z","comments":true,"path":"2023/03/25/数据库基础知识概述/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/","excerpt":"","text":"事务 ACID 原子性 隔离性 一致性 持久性 应对系统崩溃，可以用Redo Log恢复 AUTOCOMMIT：MySQL默认采用自动提交，不显示start transaction，每个查询都会被当成一个事务执行并自动提交 并发一致性问题 丢失修改 脏读 不可重复读 幻读 insert操作引起 锁 锁粒度 行锁 表锁 锁类型 读写锁 互斥锁（X锁、写锁） 共享锁（S锁、读锁） 一个事务对数据A加了X锁，期间其他事务不能对A加任何锁 一个事务对数据A加了S锁，其他事务可以对A加S锁，但是不能加X锁 - 意向锁 - 可以更容易支持多粒度加锁 - IX/IS锁，表示一个事务想要再表中的某个数据行上加X/S锁 - 一个事务再获得某个数据行的S锁之前，必须先获得表的IS锁或更强的锁 - 一个事务在获得某个数据行的X锁之前，必须先获得表的IX锁 - 任意IS/IX锁之间都是兼容的 封锁协议 一级：事务T要修改A时必须加X锁，直到T结束才释放（解决丢失修改问题） 二级：在一级基础上事务T要读取A时必须加S锁，读取完立即释放锁（解决脏读问题） 三级：在二级的基础上，要求读取A时必须加S锁，直到事务结束才释放（解决不可重复读问题） 两段锁协议：加锁和解锁分两个阶段进行，保证可串行化调度 事务隔离级别 读未提交（RU） 读提交（RC） 可重复度（RR） 可串行化（Serializable） 多版本并发控制（MVCC） 版本号 系统版本号SYS_ID:每开启一个新事务时递增 事务版本号TRX_ID:事务开启时的系统版本号 ReadView 当前系统未提交的事务列表，以及最大ID和最小ID 快照读：SELECT，不需要进行加锁 当前读：INSERT、UPDATE、DELETE，需要加锁 SELECT时可以显式指定加锁 select * from table where ? lock in share mode;(S锁) select * from table where ? for update;(X锁) Next-Key Locks 可重复读级别下，使用MVCC+Next-Key Lock可以解决幻读 Record Locks: 锁定一个记录上的索引 Gap Locks：锁定索引之间的间隙，但是不包括索引本身 关系数据库 异常 冗余数据、修改异常、删除异常、插入异常 范式 为了解决异常 第一范式：属性不可分割 第二范式：非主属性完全依赖于键码 第三范式：非主属性不传递函数依赖于键码 【参考文章】GitHub-CyC2018&#x2F;CS-Notes","categories":[{"name":"数据库","slug":"数据库","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://harryzhang.cn/blog/tags/MySQL/"}]},{"title":"Redis 集群架构","slug":"Redis-集群架构","date":"2023-03-25T07:04:57.000Z","updated":"2026-02-26T06:21:08.421Z","comments":true,"path":"2023/03/25/Redis-集群架构/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/Redis-%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84/","excerpt":"","text":"单实例往往不能满足生产环境的需求，需要引入Redis集群，比较常见的Redis集群方案有主从复制、哨兵模式、官网的Redis Cluster，另外还有一些Proxy模式，各大厂商也有自己的方案。 主从复制模式基本架构 工作原理 slave向master发送SYNC命令，master接收到命令后通过bgsave保存快照（RDB持久化），并使用缓冲区记录保存快照期间执行的写命令 master将快照文件发送给slave，继续往缓冲区记录写命令 slave收到快照文件后载入数据 master快照发送完成后想slave发送缓冲去的写命令，slave接收命令并执行，完成复制初始化 此后每次执行一个写命令都会同步发送给slave，保持master于slave之间的数据一致性 特点最简单的一种集群方案，本质上写入还是单实例（Master节点），读可以在主节点或从节点，能够实现读写分离。缺点是容量依赖单节点，无法实现分区，不具备自动容错与恢复。 哨兵模式为了解决主从复制模式不能自动进行故障恢复的不足，引入特殊的哨兵节点（Sentinel），用来监控Redis节点，在发生故障时选举出领头哨兵，由领头哨兵从所有的Slave节点中选一个作为新的Master节点，完成故障转移。 基本架构 Sentinel内部互相有连接，用于监控其他Sentinel和通信，同时每个Sentinel和每个Redis节点之间有两条连接，一个连接用来发送命令通信，一个连接用来订阅Redis节点的_sentinel_:hello频道和获取监控该节点其他Sentinel的信息。 工作原理与Master建立连接后，Sentinel会执行以下操作： 定期向Master和Slave发送INFO命令，发送INFO命令可以获取当前数据库节点信息，如果当前是Master节点，能自动发现Master的Slave节点。 定期向Master和Slave的_sentinel_:hello频道发送自己的信息 定期向Master、Slave和其他Sentinel发送PING命令 故障转移如果Sentinel向数据库节点发送的PING命令超时，Sentinel认为其主管下线，如果该节点是主节点，Sentinel会向其他Sentinel发送命令询问他们是否也认为改Master主观下线，如果达到一定数量的投票，Sentinel会认为改Master客观下线，并开启选举领头节点进行故障恢复，选举采用Raft算法： 认为Master客观下线的Sentinel-1向每个Sentinel发送命令，要求对方选自己为领头哨兵。 如果目标Sentinel节点没有选过其他人，则会同意选举Sentinel-1为领头哨兵 如果有超过一半的Sentinel统一Sentinel-1当选领头，则Sentinel-1成为领头。 如果有多个Sentinel同时竞选，导致一轮投票没有选出领头，则开启下一轮竞选，直到选出领头。 领头哨兵从故障Master的Slave节点选出一个当选新的Master，选择的规则如下： 所有在线的Slave选优先级最高的，优先级通过slave-priority配置 如果有多个高优先级的Slave，则选取复制偏移量最大的（数据最完整的） 如果以上条件都一样，选取id最小的 挑选出要升级的Slave后，领头Sentinel向该节点发送命令使其成为Master，然后再向其他Slave发送命令接收新的Master，其他Slave收到命令后向新的Master节点发送命令进行数据同步，将故障的Master更新为新的Master的Slave节点。 特点能够自动故障转移，提高了可用性，但是同样还是存在主从复制模式的难以扩容，受限于Redis单机能力的缺点。 Redis Cluster基本架构 Cluster采用无中心架构 所有Redis节点彼此互联，内部使用二进制协议优化传输速度和带宽 节点的fail是通过集群中半数以上节点检测失效判定的 客户端与key所在的Redis节点不需要直连，内部会做重定向；不需要中间代理层，客户端连接集群任意一个节点即可。 工作原理 Redis Cluster引入了槽位slot的概念（取值0-16383），每个节点均分这些slot 当对某个key操作的时候，Redis会计算key的crc16值，然后对16384取模，这样每个key都会对应一个0-16383范围的哈希槽，根据哈希槽找到负责对应槽位的节点，然后自动跳转到这个槽位上进行存取操作 为了提高可用性，Cluster同时支持主从复制，每个Master对应一个或多个Slave节点，当主节点宕机的时候启动从节点 如果一个集群半数以上的Master节点认为某个Master节点疑似下线，那么这个Master将被标记为已下线。 故障转移的方法和Sentinel模式类似： 从复制故障Master节点的所有Slave节点选一个作为新的Master 被选中的Slave节点执行SLAVEOF no one命令，成为新的Master节点 新的Master节点会撤销所有对已下线Master节点的槽指派，将这些槽指派给自己 新的Master节点向集群广播一条PONG消息，让集群中的其他节点知道这个节点已经由Slave变成了Master节点，并且已接管了槽位 新的主节点开始接受和自己负责处理的slot有关的命令请求，故障转移完成。 特点优点 无中心架构，不存在单点故障 不需要中间代理，减少依赖 支持横向扩展，伸缩性更好，能提供的并发能力更高 能自动故障转移，高可用 缺点 客户端实现复杂 数据异步复制，不保证数据强一致性 Slave作为冷备不提供服务 批量操作限制 事务支持有限，只支持多key在同一节点的事务操作 参考【1】书籍：Redis设计与实现【2】 一文掌握Redis的三种集群方案","categories":[{"name":"缓存","slug":"缓存","permalink":"https://harryzhang.cn/blog/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://harryzhang.cn/blog/tags/Redis/"},{"name":"Redis 集群","slug":"Redis-集群","permalink":"https://harryzhang.cn/blog/tags/Redis-%E9%9B%86%E7%BE%A4/"}]},{"title":"Redis 热点 key 问题如何解决?","slug":"Redis-热点-key-问题如何解决","date":"2023-03-25T07:04:18.000Z","updated":"2026-02-26T06:21:08.420Z","comments":true,"path":"2023/03/25/Redis-热点-key-问题如何解决/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/Redis-%E7%83%AD%E7%82%B9-key-%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/","excerpt":"","text":"什么是热点key？对于web应用来说，用户消费的数据远远大于生产的数据，大多人使用都只是进行浏览，少数的人才会进行评论。对于web服务来说，某些热门的内容，读请求的量级可能是非常大的，数据库无法支持这么高并发的请求，基本都会使用Redis集群做缓存，但是如果如果热点数据的请求量过大，导致热点key所在Redis节点无法支撑，这种情况就需要采用额外的措施解决。当然Redis的性能还是非常好的，大多数业务量级都可以撑住，除非业务体量很大。 解决方案服务端缓存这种方式就是将热点数据同时缓存在服务器的内存中，增加一级缓存，如果数据在内存缓存中，就直接读，不用去请求Redis。如果数据没有再请求Redis，获取到数据再写入内存缓存中。这样就大大减少了Redis的压力，而且直接读内存的速度会更快。 备份热点key为了不让热点key只请求到某一个redis节点，可以在热点key后面加一个随机数，这样热点数据可能就hash到不同的槽位，从而请求到不同的Redis节点，相当于一个key有了多个不同的备份，分散在多个Redis节点上。 参考【1】关于Redis热点key的一些思考","categories":[{"name":"缓存","slug":"缓存","permalink":"https://harryzhang.cn/blog/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://harryzhang.cn/blog/tags/Redis/"},{"name":"热点 key","slug":"热点-key","permalink":"https://harryzhang.cn/blog/tags/%E7%83%AD%E7%82%B9-key/"}]},{"title":"Redis 基础知识概述","slug":"Redis-基础知识概述","date":"2023-03-25T07:03:37.000Z","updated":"2026-02-26T06:21:08.419Z","comments":true,"path":"2023/03/25/Redis-基础知识概述/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/Redis-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%A6%82%E8%BF%B0/","excerpt":"","text":"数据类型STRING 字符串、整数、浮点数 LIST 列表 SET 集合 ZSET 有序集合 HASH 哈希表 数据结构字典 链地址法解决冲突 rehash、渐进式rehash 跳跃表 基于有序链表建多级索引 相比红黑树的优点 实现起来更简单 范围查找更快 支持无锁操作 使用场景计数器 string可以进行自增自减运算，适合频繁读写的计数器 缓存查找表 类似缓存，利用快速查找特性。DNS记录 消息队列 List类型可以模拟消息队列 会话缓存分布式锁 RedLock 多个redis节点，申请锁，当超过N&#x2F;2个节点能获得锁则认为可以获得锁 互斥：任何时刻只能有一个client获取锁 避免死锁 只要大部分redis节点存活就可以正常提供服务 SETNX命令自行实现 其他 Set可以实现交集、并集实现共同关注等功能 ZSet有序性实现排行榜 事务MUTI、EXEC将多个命令包围不支持回滚，当一个命令出错会继续执行剩下的命令WATCH命令 乐观锁，可以监控一个或多个键，一旦被监控的某个键被修改，之后的事务就不会执行 具有ACID的一致性和隔离性，当appendfsync选项设置为always时也具有持久性流水线方式，减少通信次数事件文件事件 基于Reactor模式开发了自己的网络事件处理器，使用I&#x2F;O多路复用同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会调用对应事件类型的事件处理器 时间事件 定时事件 周期性事件 集群方案哨兵模式 Sentinel 集群监控：定期ping集群中的其他服务器和哨兵，检查是否在线 消息通知：如果某个redis实例故障，哨兵负责发消息给管理员 故障转移：如果主节点挂了，会在从节点中选举出新的主节点 配置中心：发生故障转移后通知客户端新的master地址 至少要3个哨兵，保证自身的健壮性 Redis-Cluster 一共分配16383个槽位（slot） 方案说明 通过哈希方式将数据分片，每个节点均分存储一定哈希槽区间的数据 每份数据分片会存在多个互为主从的多节点上 数据写入主节点，在同步从节点，同一分片的多个节点间的数据不保持一致性 读取数据时如果key没有分配在该节点会返回转向指令，指向正确的节点 每个redis需要额外开放一个加1w的端口来进行节点间通信（gossip协议） 优点 无中心架构，支持动态扩容，对业务透明 具备Sentinel的监控和自动故障转移能力 客户端不需要连接所有节点（会自动转向） 高性能，客户端直连redis服务器，免去proxy代理的损耗 缺点 运维复杂，数据迁移需要人工干预 不支持批量操作（pipeline） 缓存异常缓存雪崩 大面积缓存失效 解决方案 设置随机的过期时间 并发不多的时候加锁排队 缓存穿透 缓存和DB都不存在的数据 解决方案 接口层拦截 设置空缓存，过期时间要短 布隆过滤器 缓存击穿 缓存中没有，但是并发用户很多 解决方案 设置热点数据永不过期 persist key 加互斥锁 缓存预热 缓存降级 对比MemcachedMemcached 仅支持字符串类型 不支持持久化 不支持分布式 Redis 读写性能优异，Read：11w&#x2F;s、Write：8.1w&#x2F;s 支持RDB和AOF两种持久化方式 支持事务，具有原子性 数据结构丰富 支持主从复制 Redis缺点 内存通常比较小且贵，不适用海量数据 比较难支持在线扩容 键的过期时间每个键设置过期时间，过期后会自动删除惰性删除定期删除定时删除数据淘汰策略当内存超出容量，会施行淘汰策略全局键空间选择性删除 noevication allkeys-lru allkeys-random 设置过期时间的键空间选择性移除 volatile-lru volatile-random volatile-ttl 持久化RDB（默认方式） 数据快照 优点 只有一个dump.rdb文件，方便持久化 容灾兴好，一个文件可以安全的保存到磁盘 单独进程处理，不会影响主进程的IO操作 数据集大时比AOF启动更快 缺点 定期执行持久化操作，故障会丢失数据 AOF 写命令追加到AOF文件 always：每个写命令都同步 everysec：每秒同步一次 no：让操作系统决定何时同步 优点 数据安全，always模式每进行一次写命令就记录到aof文件一次 append模式写文件，即使中途宕机可以redis-check-aof工具解决数据一致性问题 AOF重写机制，减少冗余命令 缺点 文件大，恢复速度慢 复制命令slaveof $&#123;host&#125; $&#123;port&#125; 连接过程 主服务器创建快照文件（rdb）发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完再向从服务器发送存储在缓冲区的写命令 从服务器丢弃所有旧数据，载入快照文件，接收主服务器发来的写命令 主服务器每执行一次写命令，就向所有从服务器发送相同的写命令 主从链 从服务器比较多的时候，为了不影响主服务器的性能，可以设置中间层来分担主服务器的复制工作 【参考文章】GitHub-CyC2018&#x2F;CS-Notes","categories":[{"name":"缓存","slug":"缓存","permalink":"https://harryzhang.cn/blog/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://harryzhang.cn/blog/tags/Redis/"}]},{"title":"TCP是如何实现可靠传输的？","slug":"TCP是如何实现可靠传输的？","date":"2023-03-25T06:43:37.000Z","updated":"2026-02-26T06:21:08.422Z","comments":true,"path":"2023/03/25/TCP是如何实现可靠传输的？/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/TCP%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E7%9A%84%EF%BC%9F/","excerpt":"","text":"在计算机网络的经典五层协议中，TCP属于运输层，实现了进程间的通信，保证了数据的可靠传输，属于计算机网络协议族中最重要的协议之一，那么TCP是如何实现可靠数据传输的呢？ 底层实现运输层的进程间通信是通过socket实现的，socket是一个抽象的概念，在Linux系统中以文件的形式存在。网络层通过IP来区分主机，运输层则增加了端口的概念来区分进程。TCP协议中使用目标IP、目标端口、源IP、源端口来定义一个socket，只需要在运输层的报文头部附加上这些信息，目标主机就会知道数据要发送那个socket，对应监听该socket的进程就可以收到数据进行处理。 TCP报文格式TCP报文包括首部和数据部分，首部附加了TCP报文的信息，首部长度固定部分为20字节，还有40字节的可选部分，具体如下图所示： 其中几个关键字段的作用如下： 源端口和目的端口：分别16个字节（表示范围0-65535），用来区分主机上的进程 序号：TCP连接中的每个字节都编一个序号，表示本报文的第一个字节在整个数据包中的偏移位置 确认号：期望收到对方的下一个报文段的数据的第一个字节的序号 数据偏移：首部长度，4字节为单位 标志位 ACK：ACK&#x3D;1表示接收发向发送方发的确认报文 SYN：同步SYN&#x3D;1表示是一个连接请求或连接接受报文 FIN：FIN&#x3D;1表示发送方已经发送完毕，可以断开连接 窗口：发送方接收缓冲区剩下的字节数 校验和：检验报文在网络传输过程中是否发生了变化 选项字段： 窗口扩大选项，用于流量控制 时间戳选项 选择确认选项，由于接收方收到了不连续的报文，告知发送方目前收到的数据报范围（两个4字节的边界表示） 可靠传输原理网络层只管尽可能将数据从一个主机发送到另一个主机，并不保证数据可靠到达，由于网络环境总是不稳定的，可能存在丢包、差错等请求，TCP则通过一系列的机制在运输层保证了数据的可靠传输。网络传输可能发生的异常情况和解决方法： 丢包：超时重传 差错：校验码来检验数据正确收到 停止等待协议要实现可靠传输，最简单的方法就是发送方发送一个报文，接收方收到报文后发送确认报文表示我收到了，你可以发下一个了，传输模型如下： 这种方式保证可靠传输称为停止等待协议，这种方式缺点也很明显，效率非常低。 连续ARQ协议为了提高传输效率，充分利用带宽，发送方会连续的发送数据包，如下图所示：客户端不等收到前一个包的确认报文就开始不断的发下一个包，这样可以充分利用网络带宽，提高传输效率，但是于此同时也带来了另外的问题，那么TCP是如何解决这些问题的？ 确认报文冗余累计确认：网络中充斥着大量的发送包和确认回复报文，这些数据只是为了确认报文到达，并不是实际需要传输的数据。是不是一定要每一个报文都要发一个回复确认的报文呢，TCP采用了累计确认的方法：接收方在累计收到了一定量的数据包后发送一个确认报文告诉发送方在此之前的数据包都已经收到了，这样便可以减少确认报文的数量，提高带宽利用率。 丢包的处理GBN（回退n步）：如果发生丢包的情况，在连续ARQ中，如果接受方收到了123 567个字节，编号为4字节的包丢失了，按照累计确认只能发送3的确认回复，567都要丢掉，因为发送发会进行重传。 选择确认ACK：在TCP报文头部的选项字段部分设置已收到的报文，每一段用两个边界来确定，比如上述情况可以用[1,3]和[5,7]来表示，客户端就会根据选项只重传丢失的数据段。 滑动窗口因为接收方读数据的能力有限，发送发不能一直发送报文直到把缓冲区所有数据发送完，这样会导致接收方无法接收丢弃掉数据包，发送方收不到确认认为超时又会继续重传，产生了大量无用数据的重传。对此情况TCP使用滑动窗口来解决，基本模型如下： 发送方根据接受方缓冲区的大小，设置自己可发送窗口大小，处于窗口内的数据表示可以发送，之外的数据不能发送 当窗口内的未确认数据收到确认回复时，整个窗口往前移动，知道发送完所有数据 滑动窗口机制实现了TCP的流量控制，不至于发送太快导致太多的数据丢弃和重传。 拥塞控制为了避免网络过分拥挤导致丢包严重，传输效率低，TCP实现了拥塞控制机制，拥塞控制的解决办法本质上是流量控制，控制发送方发送的速度，而上文提到流量控制是通过滑动窗口来实现的，所以最终也是通过调整发送方的滑动窗口大小来实现的。 拥塞控制的几个重要的概念：慢启动、拥塞避免、快恢复、快重传 Reno算法模型 慢启动：最开始的时候把窗口设置为较小的值，然后每轮变成两倍（虽然叫慢启动，但其实是指数增长） 拥塞避免：当窗口大小达到初始阈值ssthresh，每轮窗口大小增加1（试探网络最大的负载能力） 如果发生了超时，表示极可能发生了拥塞，此时直接执行慢启动，尽可能让网络中的报文先接收，以尽快恢复网络状况。 快重传：如果收到三个重复的ACK，表示中间有段数据丢包了，发送方无需等待计时器到达超时时间，立即进行重传丢失的报文段。 快恢复：连续收到了三个重复ACK，说明网络情况还不是很拥堵，此时将窗口初始的阈值减半，然后执行拥塞避免，这个过程称为快恢复。 Reno算法是比较常见的TCP实现的拥塞控制算法，其他拥塞算法还有Tahoe（已废弃不用）、New Reno等，通过拥塞控制算法可以很大程度避免网络拥挤。 参考【书籍】计算机网络：自顶向下方法【码农有道】这一篇TCP总结请收下","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://harryzhang.cn/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://harryzhang.cn/blog/tags/TCP/"}]},{"title":"HTTPS原理详解","slug":"HTTPS原理详解","date":"2023-03-25T06:43:24.000Z","updated":"2026-02-26T06:21:08.417Z","comments":true,"path":"2023/03/25/HTTPS原理详解/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/HTTPS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"Web应用存在HTTP和HTTPS两种通信方式，HTTP默认端口80，数据以明文传输，HTTPS默认端口443，数据加密传输。 HTTPS协议HTTPS实际上并不是一种新的网络协议，是HTTP的基础上加了SSL层，数据的加密就是在SSL层完成的。 数据传输方式明文传输客户端和服务器已明文方式传输数据，没有安全性，数据再传输过程中可能被劫持和篡改 对称加密传输对称加密算法：双方使用同一秘钥对数据进行加解密（AES、DES）特点： 如果不知道秘钥，是无法解出对应的明文，但是如果所有客户端都用相同的秘钥，相当于没有加密，坏人也可以作为一个用户拿到秘钥。 加解密性能高 一种改进的方案是每个客户端先协商一个加密算法和秘钥，不同客户端使用不同的算法和秘钥，这就坏人即使作为一个用户也不知道别的用户的秘钥。但是这种方式协商秘钥的过程是公开明文的，坏人也有办法窃取到秘钥的，仍然存在风险。 非对称加密传输非对称加密算法：加密解密采用不同的秘钥，私钥加密后的密文，所有的公钥都可以解密，公钥加密后的密文只有私钥能解密。私钥通常只有一个人有，公钥可以公开发给所有人。（常见算法：RSA） 特点： 只要把私钥保存在服务器，公钥发给客户端，那么客户端向服务器发送的数据就是安全的，但是服务器向客户端发送的数据坏人也可以通过公钥解密 加解密消耗的时间较长，传输效率会降低 HTTPS（对称加密+非对称加密） 特点： 使用非对称加密传输协商一个对称加密算法和秘钥 使用对称加密算法对数据加密传输 数据双向安全，且效率较高 CA机构和数字证书从前面可以看到，协商阶段时候用非对称加密，客户端一开始就要持有公钥，那么客户端如何安全的获取公钥呢？如果服务端直接将公钥发给客户端，中间可能被坏人劫持，返回一个假公钥，客户端使用假公钥进行加密后请求，坏人就可以使用假私钥解出明文，篡改内容后再使用真公钥加密后请求到服务器，这时服务器拿到的是被篡改后的数据。 数字证书和CA机构就是用来保证服务器安全的发送公钥给客户端的。校验过程 读取证书中的所有者，有效期等信息进行校验 查找系统内置的受信任证书发布机构CA，与服务器下发的证书中的CA对比，校验是否是合法机构颁发 如果找不到，浏览器报错警告证书不可信 如果找到了： 对证书里的数字签名使用公钥解密得到明文的hash摘要 浏览器使用相同的hash算法计算明文的hash值，将这个值与上述计算的摘要对比验证证书的合法性。 总结一个完整的HTTPS请求流程如下图所示： 参考【1】【掘金】深入理解HTTPS工作原理","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://harryzhang.cn/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://harryzhang.cn/blog/tags/HTTPS/"}]},{"title":"Session和Cookie","slug":"Session和Cookie","date":"2023-03-25T06:43:05.000Z","updated":"2026-02-26T06:21:08.421Z","comments":true,"path":"2023/03/25/Session和Cookie/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/Session%E5%92%8CCookie/","excerpt":"","text":"我们知道HTTP协议是无状态的，那么在Web开发中如何做好用户的整个浏览过程的控制，最经典的解决方案就是使用Cookie和Session。Cookie是客户端的机制，把用户数据缓存在客户端，而Session是服务端的机制，每个用户都会被分配一个唯一的SessionID，可以通过url传输或保存在客户端的Cookie中，也可以将Session保存在数据库中，比如Redis中。 Session和Cookie是怎么来的？假如你在浏览器上从来没有登录过GitHub，当你第一次登录的时候需要输入用户名和密码进行验证，通过验证后会调到个人首页，那么在登录成功后你点击你的某个代码仓库的时候服务器如何验证你的身份呢？因为HTTP协议是无状态的，服务器并不知道你上次已经验证过了，一种方法是每次请求都带上用户名和密码，这显然会导致用户体验极差。那么就需要再客户端或服务器上保存身份信息了，于是Cookie和Session就产生了。 CookieCookie原理Cookie就是本地计算机保存一些用户操作的历史信息，用户再次访问时在HTTP请求头中带上Cookie信息，服务端就可以对其进行验证。 数据内容Cookie本质上是由浏览器管理存储在客户端的一小段文本，Chrome浏览器可以使用EditThisCookie插件来管理Cookie，如下图所示。 会话Cookie和持久Cookie 会话Cookie：Cookie是有有效期的，如果不设置过期时间，则表示这个Cookie的生命周期从创建到浏览器关闭为止，只要关闭浏览器Cookie就消失了，相当于数据保存在内存中，进程结束就丢失了 持久Cookie：如果设置了过期时间，浏览器会把Cookie数据保存到磁盘上，关闭浏览器再次打开依然有效，直到Cookie过期，浏览器通常都使用的持久Cookie。 SessionSession原理Session是服务器用来保存用户操作的历史信息的，使用SessionID来标识Session，SessionID由服务器产生，保证随机性和唯一性，相当于一个随机秘钥，避免在传输中暴露用户真实密码，但是服务器仍要将请求对Session进行对应，需要借助Cookie保存客户端的标识（SessionID）。 当服务器需要对某个请求创建Session的时候，首先检查这个客户端的请求是否包含了SessionID，如果已经包含则表示次客户端之前已经创建过，只需要根据SessionID查询对应的Session。如果请求没有携带SessionID，则会生成一个Session和对应的SessionID，同时在本次响应中返回SessionID。 参考【1】build-web-application-with-golang","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://harryzhang.cn/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"Session","slug":"Session","permalink":"https://harryzhang.cn/blog/tags/Session/"},{"name":"Cookie","slug":"Cookie","permalink":"https://harryzhang.cn/blog/tags/Cookie/"}]},{"title":"什么是WebSocket？","slug":"什么是WebSocket？","date":"2023-03-25T06:42:47.000Z","updated":"2026-02-26T06:21:08.422Z","comments":true,"path":"2023/03/25/什么是WebSocket？/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E4%BB%80%E4%B9%88%E6%98%AFWebSocket%EF%BC%9F/","excerpt":"","text":"基本概念WebSocket是一种网络通信协议，是HTML5新增的特性，实现了基于浏览器的远程socket，使浏览器和服务器可以进行全双工通信，大部分浏览器都对此做了支持。WebSocket的URL格式形如：ws:&#x2F;&#x2F;localhost:80&#x2F;、wss:&#x2F;&#x2F;localhost:443&#x2F; 为什么有了HTTP协议还要WebSocketHTTP协议采用的是客户端（浏览器）轮询的方式，即客户端发送请求，服务端做出响应，为了获取最新的数据，需要不断的轮询发出HTTP请求，占用大量带宽。WebSocket采用了一些特殊的报头，使得浏览器和服务器只需要通过“握手”建立一条连接通道后，此链接保持活跃状态，之后的客户端和服务器的通信都使用这个连接，解决了Web实时性的问题，相比于HTTP有一下好处： 一个Web客户端只建立一个TCP连接 WebSocket服务端可以主动推送（push）数据到Web客户端 有更加轻量级的头，减少了数据传输量 WebSocket原理 建立连接WebSocket建立连接必须由浏览器发起，是一个标准的HTTP请求，如下图所示 请求 请求地址以ws://开头 请求头Upgrade: websocket和Connection:Upgrade表示要将这个连接转换为WebSocket连接 Sec-WebSocket-Key用于标识连接，是一个base64编码的字符串 Sec-WebSocket-Version指定了WebSocket协议版本 响应 响应状态码101表示本次连接的HTTP协议将被更改 Upgrade: websocket表示更改后的协议是WebSocket Sec-WebSocket-Accept通过如下方式计算： 对请求头的Sec-WebSocket-Key字符串加上一个固定的字符串，例如：H+VLjR1wb4JQ62TmabK87g==258EAFA5-E914-47DA-95CA-C5AB0DC85B11 然后对该字符串用sha1算法散列出二进制值，再对其进行base64加密，例如：ccJoRDcGOFzCVrIwpX/qF3BoIN0= 数据格式WebSocket的协议比较简单，在第一次handshake通过之后，连接建立成功，之后的通讯数据都是以”\\x00”开头，以”\\xFF”结尾，对客户端来说这个是透明的，WebSocket的实现组件会对原始数据掐头去尾。 特点 建立在TCP协议只上，服务端比较容易实现 于HTTP协议有良好的兼容性，默认端口也是80和443，握手阶段使用HTTP协议，因此握手时不容易屏蔽，能通过各种HTTP代理服务器 数据格式轻量，通信高效且节省带宽 支持传输文本数据和二进制数据 没有同源限制，客户端可以与任意服务器通信 也支持加密传输，WS+SSL，URL形如wss:// Go语言实现go的标准SDK中没有支持WebSocket，但是官方维护的net子包中支持go get golang.org/x/net/websocket 客户端&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt;&lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/javascript&quot;&gt; var sock = null; var wsuri = &quot;ws://127.0.0.1:7777&quot;; window.onload = function() &#123; console.log(&quot;onload&quot;); sock = new WebSocket(wsuri); sock.onopen = function() &#123; console.log(&quot;connected to &quot; + wsuri); &#125; sock.onclose = function(e) &#123; console.log(&quot;connection closed (&quot; + e.code + &quot;)&quot;); &#125; sock.onmessage = function(e) &#123; console.log(&quot;message received: &quot; + e.data); &#125; &#125;; function send() &#123; var msg = document.getElementById(&#39;message&#39;).value; sock.send(msg); &#125;; &lt;/script&gt; &lt;h1&gt;WebSocket Echo Test&lt;/h1&gt; &lt;form&gt; &lt;p&gt; Message: &lt;input id=&quot;message&quot; type=&quot;text&quot; value=&quot;Hello, world!&quot;&gt; &lt;/p&gt; &lt;/form&gt; &lt;button onclick=&quot;send();&quot;&gt;Send Message&lt;/button&gt; &lt;/body&gt; &lt;/html&gt; 客户端JavaScript代码，通过new WebSocket(wsuri)创建了一个WebSocket连接，握手成功后会触发onopen事件，客户端绑定了四个事件： onopen：建立连接后触发 onmessage：收到消息后触发 onerror：发生错误时触发 onclose：关闭连接时触发 服务端package main import ( &quot;golang.org/x/net/websocket&quot; &quot;log&quot; &quot;net/http&quot; ) func handleEcho(ws *websocket.Conn) &#123; var err error for &#123; var reply string if err = websocket.Message.Receive(ws, &amp;reply); err != nil &#123; log.Println(&quot;[server] Can&#39;t receive&quot;) break &#125; log.Println(&quot;[server] Received from client:&quot;, reply) msg := &quot;welcome: &quot; + reply if err = websocket.Message.Send(ws, msg); err != nil &#123; log.Println(&quot;[server] Can&#39;t Send&quot;) break &#125; log.Println(&quot;[server] Send to client:&quot;, msg) &#125; &#125; func main() &#123; http.Handle(&quot;/&quot;, websocket.Handler(handleEcho)) log.Println(&quot;[server] listen in 127.0.0.1:7777&quot;) if err := http.ListenAndServe(&quot;:7777&quot;, nil); err != nil &#123; log.Fatal(&quot;[server] ListenAndServe:&quot;, err) &#125; &#125; 运行后在客户端页面点击Send Message按钮，可以看到服务端如下响应： 参考资料【1】build-web-application-with-golang【2】廖雪峰：WebSocket【3】阮一峰：WebSocket教程","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://harryzhang.cn/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"WebSocket","slug":"WebSocket","permalink":"https://harryzhang.cn/blog/tags/WebSocket/"}]},{"title":"计算机网络基础概述","slug":"计算机网络基础概述","date":"2023-03-25T05:58:26.000Z","updated":"2026-02-26T06:21:08.424Z","comments":true,"path":"2023/03/25/计算机网络基础概述/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0/","excerpt":"","text":"网络网络层传输层 TCP、UDP 特点 UDP：无连接，尽最大可能交付数据，面向报文，支持一对一、一对多、多对一、多对多的交互通信，不可靠（快、实时性好） DNS、TFTP TCP：面向连接，可靠交付，有流量控制、拥塞控制，全双工通信，面向字节流，只能点对点（一对一） HTTP、FTP、TELENT、SMTP TCP三次握手 防止失效的连接请求到达服务器，导致服务器打开无用的连接 TCP四次挥手 TIME_WAIT&#x3D;2MSL 确保最后一个确认报文能到达，因为如果丢失会重传 让本次连接产生的所有报文都从网络中消失 TCP可靠传输 超时重传RTT TCP滑动窗口 TCP流量控制 控制发送方速率，保证接收方来得及接收（通过确认报文的窗口字段控制发送方窗口大小） TCP拥塞控制 慢启动、拥塞避免、快重传、快恢复 应用层 DNS UDP+TCP DHCP 动态主机配置 Web页面请求过程 DHCP配置主机信息 ARP解析MAC地址 DNS解析域名 HTTP请求页面 三次握手建立连接 开始通信 Socket阻塞式I&#x2F;O 直到数据从内核缓冲区复制到应用进程缓冲区才返回（cpu并不会阻塞，其他进程还可以执行，cpu利用率较高） 非阻塞式I&#x2F;O 应用进程执行系统调用后内核返回一个错误码，需要轮询来获知IO操作是否完成（CPU利用率低） I&#x2F;O多路复用 select、poll等待数据，当监听的某个套接字可读，再使用recvfrom把数据从内核复制到进程中 select 会修改fd，默认只能监听少于1024个，轮询 poll 提供了更多的事件类型，对fd的重复利用更高 epoll 比上述两种更加灵活，对多线程更友好 epoll_create 创建一个epoll句柄 epoll_ctl 为fd注册事件并绑定一个回调函数，当设备就绪callback把fd加入就绪队列（列表） epoll_wait 轮询就绪队列（schedule_timeout()） 信号驱动I&#x2F;O sigaction系统调用，当数据到达时内核会向进程发送SIGIO信号，收到信号后调用recvfrom（相比轮询的非阻塞I&#x2F;O模型CPU利用率更高） 异步I&#x2F;O aio_read系统调用，内核会在数据复制完成后向应用进程发送信号（注意和信号驱动I&#x2F;O的区别） HTTPHTTP状态码 1xx：信息性 2xx：成功 3xx：重定向 301：永久重定向，会缓存 302：临时重定向，不缓存，有url劫持问题 4xx：客户端错误，服务端无法处理的请求 5xx：服务器错误 Cookie 客户端保存状态 Session 服务器保存状态 HTTPS HTTP+SSL 使用非对称加密协商对称加密使用的Secretkey 使用Secretkey对称加密数据 使用数字证书保证公钥的正确性 HTTP2.0 二进制分帧层 服务端推送 首部压缩 【参考文章】GitHub-CyC2018&#x2F;CS-Notes","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://harryzhang.cn/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"Linux 系统 I/O 模型及 select/poll/epoll 详解","slug":"Linux-系统-I-O-模型及-select-poll-epoll-详解","date":"2023-03-19T14:06:15.000Z","updated":"2026-02-26T06:21:08.411Z","comments":true,"path":"2023/03/19/Linux-系统-I-O-模型及-select-poll-epoll-详解/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/Linux-%E7%B3%BB%E7%BB%9F-I-O-%E6%A8%A1%E5%9E%8B%E5%8F%8A-select-poll-epoll-%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"基本概念说明理解Linux的IO模型之前，首先要了解一些基本概念，才能理解这些IO模型设计的依据 用户空间和内核空间操作系统使用虚拟内存来映射物理内存，对于32位的操作系统来说，虚拟地址空间为4G（2^32）。操作系统的核心是内核，为了保护用户进程不能直接操作内核，保证内核安全，操作系统将虚拟地址空间划分为内核空间和用户空间。内核可以访问全部的地址空间，拥有访问底层硬件设备的权限，普通的应用程序需要访问硬件设备必须通过系统调用来实现。 对于Linux系统来说，将虚拟内存的最高1G字节的空间作为内核空间仅供内核使用，低3G字节的空间供用户进程使用，称为用户空间。 进程的状态 就绪 阻塞 运行 进程切换文件描述符fd缓存I&#x2F;O又被称为标准I&#x2F;O，大多数文件系统的默认I&#x2F;O都是缓存I&#x2F;O。在Linux系统的缓存I&#x2F;O机制中，操作系统会将I&#x2F;O的数据缓存在页缓存（内存）中，也就是数据先被拷贝到内核的缓冲区（内核地址空间），然后才会从内核缓冲区拷贝到应用程序的缓冲区（用户地址空间）。 这种方式很明显的缺点就是数据传输过程中需要再应用程序地址空间和内核空间进行多次数据拷贝操作，这些操作带来的CPU以及内存的开销是非常大的。 二I&#x2F;O模式由于Linux系统采用的缓存I&#x2F;O模式，对于一次I&#x2F;O访问，以读操作举例，数据先会被拷贝到内核缓冲区，然后才会从内核缓冲区拷贝到应用程序的缓存区，当一个read系统调用发生的时候，会经历两个阶段： 等待数据到来，进程处于阻塞状态 当数据准备就绪后，将数据从内核拷贝到用户进程，进程处于运行状态 正是因为这两个状态，Linux系统才产生了多种不同的网络I&#x2F;O模式的方案 Linux系统I&#x2F;O模型阻塞IO（blocking IO）Linux系统默认情况下所有socke都是blocking的，一个读操作流程如下： 以UDP socket为例，当用户进程调用了recvfrom系统调用，如果数据还没准备好，应用进程被阻塞，内核直到数据到来且将数据从内核缓冲区拷贝到了应用进程缓冲区，然后向用户进程返回结果，用户进程才解除block状态，重新运行起来。 阻塞模行下只是阻塞了当前的应用进程，其他进程还可以执行，不消耗CPU时间，CPU的利用率较高。 非阻塞IO（nonblocking IO）Linux可以设置socket为非阻塞的，非阻塞模式下执行一个读操作流程如下： 当用户进程发出recvfrom系统调用时，如果kernel中的数据还没准备好，recvfrom会立即返回一个error结果，不会阻塞用户进程，用户进程收到error时知道数据还没准备好，\b过一会再调用recvfrom，直到kernel中的数据准备好了，内核就立即将数据拷贝到用户内存然后返回ok，这个过程需要用户进程去轮询内核数据是否准备好。 非阻塞模型下由于要处理更多的系统调用，因此CPU利用率比较低。 信号驱动IO应用进程使用sigaction系统调用，内核立即返回，等到kernel数据准备好时会给用户进程发送一个信号，告诉用户进程可以进行IO操作了，然后用户进程再调用IO系统调用如recvfrom，将数据从内核缓冲区拷贝到应用进程。流程如下： 相比于轮询的方式，不需要多次系统调用轮询，信号驱动IO的CPU利用率更高。 异步IO异步IO模型与其他模型最大的区别是，异步IO在系统调用返回的时候所有操作都已经完成，应用进程既不需要等待数据准备，也不需要在数据到来后等待数据从内核缓冲区拷贝到用户缓冲区，流程如下：在数据拷贝完成后，kernel会给用户进程发送一个信号告诉其read操作完成了。 IO多路复用是用select、poll等待数据，可以等待多个socket中的任一个变为可读，这一过程会被阻塞，当某个套接字数据到来时返回，之后再用recvfrom系统调用把数据从内核缓存区复制到用户进程，流程如下： 流程类似阻塞IO，甚至比阻塞IO更差，多使用了一个系统调用，但是IO多路复用最大的特点是让单个进程能同时处理多个IO事件的能力，又被称为事件驱动IO，相比于多线程模型，IO复用模型不需要线程的创建、切换、销毁，系统开销更小，适合高并发的场景。 selectselect是IO多路复用模型的一种实现，当select函数返回后可以通过轮询fdset来找到就绪的socket。 int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout) 优点是几乎所有平台都支持，缺点在于能够监听的fd数量有限，Linux系统上一般为1024，是写死在宏定义中的，要修改需要重新编译内核。而且每次都要把所有的fd在用户空间和内核空间拷贝，这个操作是比较耗时的。 pollpoll和select基本相同，不同的是poll没有最大fd数量限制（实际也会受到物理资源的限制，因为系统的fd数量是有限的），而且提供了更多的时间类型。 int poll(struct pollfd *fds, unsigned int nfds, int timeout) 总结：select和poll都需要在返回后通过轮询的方式检查就绪的socket，事实上同时连的大量socket在一个时刻只有很少的处于就绪状态，因此随着监视的描述符数量的变多，其性能也会逐渐下降。 epollepoll是select和poll的改进版本，更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 int epoll_create(int size) int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event) int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout) epoll_create()用来创建一个epoll句柄。epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I&#x2F;O 准备好的描述符加入到一个就绪链表中管理。 epoll_wait() 可以从就绪链表中得到事件完成的描述符，因此进程不需要通过轮询来获得事件完成的描述符。 LT模式（水平触发，默认）当epoll_wait检测到描述符IO事件发生并且通知给应用程序时，应用程序可以不立即处理该事件，下次调用epoll_wait还会再次通知该事件，支持block和nonblocking socket。 ET模式（边缘触发）当epoll_wait检测到描述符IO事件发生并且通知给应用程序时，应用程序需要立即处理该事件，如果不立即处理，下次调用epoll_wait不会再次通知该事件。 ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用nonblocking socket，以避免由于一个文件句柄的阻塞读&#x2F;阻塞写操作把处理多个文件描述符的任务饿死。 应用场景 select的timeout参数精度为微妙，而poll和epoll都是毫秒，会因此select更加适合对实时性要求比较高的场景 poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 epoll适合高并发的场景，有大量描述符需要同时监听，并且最好是长连接。不适合监控的描述符状态变化频繁且短暂，因为epoll的描述符都存在内核中，每次对其状态修改都要通过epoll_ctl系统调用来实现，频繁的系统调用导致频繁在内核态和用户态切换，会大大降低性能。 参考【segmentfault】Linux IO模式及 select、poll、epoll详解【GitHub】CyC2018&#x2F;CS-Notes","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://harryzhang.cn/blog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://harryzhang.cn/blog/tags/Linux/"},{"name":"I/O模型","slug":"I-O模型","permalink":"https://harryzhang.cn/blog/tags/I-O%E6%A8%A1%E5%9E%8B/"},{"name":"select/poll/epoll","slug":"select-poll-epoll","permalink":"https://harryzhang.cn/blog/tags/select-poll-epoll/"}]},{"title":"算法(8): LRU 策略","slug":"算法-8-LRU-策略","date":"2023-03-19T13:58:05.000Z","updated":"2026-02-26T06:21:08.416Z","comments":true,"path":"2023/03/19/算法-8-LRU-策略/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E7%AE%97%E6%B3%95-8-LRU-%E7%AD%96%E7%95%A5/","excerpt":"","text":"LeetCode No.146 LRU缓存机制 LRU（Least Recent Used）策略：优先淘汰最近最少使用的数据，常用于缓存淘汰机制，如Linux系统的内存淘汰、Redis的缓存淘汰等。 基于哈希表和双向链表实现LRU核心思路是，利用双向链表存储键值对，哈希表存储键在链表中对应的节点指针，如下图所示 这样的好处是使访问和更新操作时间复杂度都在O(1)。 PUT操作 判断哈希表中key是否已存在，如果存在为修改操作： 将链表节点修改为新的键值对 将节点移到头部 如果不存在为新增操作，此时如果容量已满，需要淘汰数据 取出链表尾节点，删除哈希表中对应key 删除链表尾节点 在链表头部添加新的节点 将新的链表头节点加到哈希表 如果容量没有满，直接添加节点，执行上述步骤3、4即可 GET操作 判断哈希表中key是否存在，如果存在将节点移动到链表头部，返回对应的值 如果不存在直接返回nil值 Go语言实现使用Go内建map类型和container包的list（双向链表） import ( &quot;container/list&quot; ) type Pair struct &#123; key int val int &#125; type LRUCache struct &#123; cap int list *list.List kv map[int]*list.Element &#125; func Constructor(capacity int) LRUCache &#123; return LRUCache&#123; cap: capacity, list: list.New(), kv: make(map[int]*list.Element), &#125; &#125; func (this *LRUCache) Get(key int) int &#123; if v, ok := this.kv[key]; ok == true &#123; this.list.MoveToFront(v) return v.Value.(Pair).val &#125; else &#123; return -1 &#125; &#125; func (this *LRUCache) Put(key int, value int) &#123; if elem, ok := this.kv[key]; ok == true &#123; elem.Value = Pair&#123;key: key, val: value&#125; this.list.MoveToFront(elem) return &#125; if this.list.Len() &gt;= this.cap &#123; delete(this.kv, this.list.Back().Value.(Pair).key) this.list.Remove(this.list.Back()) &#125; this.list.PushFront(Pair&#123;key: key, val: value&#125;) this.kv[key] = this.list.Front() &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"LRU","slug":"LRU","permalink":"https://harryzhang.cn/blog/tags/LRU/"},{"name":"缓存","slug":"缓存","permalink":"https://harryzhang.cn/blog/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"算法(7): 动态规划","slug":"算法-7-动态规划","date":"2023-03-19T13:56:37.000Z","updated":"2026-02-26T06:21:08.416Z","comments":true,"path":"2023/03/19/算法-7-动态规划/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E7%AE%97%E6%B3%95-7-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","excerpt":"","text":"动态规划的关键思想在于将问题转换成较小的子问题，然后根据子问题的结果总结出一个状态转移方程，最后得到整个问题的解 7.1 打家劫舍LeetCode No.198 问题描述：你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。输入：[1,2,3,1]输出：4解释：偷窃 1 号房屋 (金额 &#x3D; 1) ，然后偷窃 3 号房屋 (金额 &#x3D; 3)。 偷窃到的最高金额 &#x3D; 1 + 3 &#x3D; 4 。 思路：当设选第i个房屋，则不能选i-1，假设dp[i]表示前i个房屋能偷到的最高金额，则有 dp[i] &#x3D; max(dp[i - 1], dp[i - 2] + nums[i]) 示例代码： func rob(nums []int) int &#123; n := len(nums) if n == 0 &#123; return 0 &#125; if n == 1 &#123; return nums[0] &#125; dp := make([]int, n) dp[0], dp[1] = nums[0], max(nums[0], nums[1]) ans := dp[1] for i := 2; i &lt; n; i++ &#123; dp[i] = max(dp[i - 2] + nums[i], dp[i - 1]) if ans &lt; dp[i] &#123; ans = dp[i] &#125; &#125; return ans &#125; 7.1-1 打家劫舍2LeetCode No.213 问题描述：房屋变成了环形排列，其他和7.1相同 思路：环形排列后，第一个和最后一个不能同时偷，可以转化为[0, n-1]和[1, n]两个单排街道较大值。同时，可以看到第i个问题的最大值只和第i-1和i-2有关，可以只用两个值来保存前两个结果，降低空间复杂度。 示例代码： func rob(nums []int) int &#123; n := len(nums) if n == 1 &#123; return nums[0] &#125; return max(dorob(nums[1:]), dorob(nums[:n-1])) &#125; func dorob(nums []int) int &#123; n := len(nums) if n == 1 &#123; return nums[0] &#125; fisrt, second := nums[0], max(nums[0], nums[1]) ans := second for i := 2; i &lt; n; i++ &#123; fisrt, second = second, max(fisrt + nums[i], second) if second &gt; ans &#123; ans = second &#125; &#125; return ans &#125; 7.2 分割等和子集LeetCode No.416 问题描述：给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。输入: [1, 5, 11, 5]输出: true解释: 数组可以分割成 [1, 5, 5] 和 [11] 思路：如果数组大小为奇数，结果必为false。然后该问题可以转化为背包大小为sum&#x2F;2的0-1背包问题，如果恰好能装满则结果为true。 示例代码： func canPartition(nums []int) bool &#123; sum := 0 for _, n := range nums &#123; sum += n &#125; if sum % 2 != 0 &#123; return false &#125; W := sum &gt;&gt; 1 dp := make(map[int]bool) dp[0] = true for _, n := range nums &#123; // 这里进行了空间优化，需要从后向前算，否则计算后面的时候前面的值已经改过，不是上一层的值了。 // dp[i][w] = dp[i - 1][w] || dp[i-1][w-v] for i := W; i &gt;= n; i-- &#123; dp[i] = dp[i] || dp[i - n] &#125; &#125; return dp[W] &#125; 7.3 青蛙过河LeetCode No.403 题目描述：一只青蛙想要过河。 假定河流被等分为 x 个单元格，并且在每一个单元格内都有可能放有一石子（也有可能没有）。 青蛙可以跳上石头，但是不可以跳入水中。给定石子的位置列表（用单元格序号升序表示）， 请判定青蛙能否成功过河（即能否在最后一步跳至最后一个石子上）。 开始时， 青蛙默认已站在第一个石子上，并可以假定它第一步只能跳跃一个单位（即只能从单元格1跳至单元格2）。如果青蛙上一步跳跃了 k 个单位，那么它接下来的跳跃距离只能选择为 k - 1、k 或 k + 1个单位。 另请注意，青蛙只能向前方（终点的方向）跳跃。输入：[0,1,3,5,6,8,12,17]总共有8个石子。第一个石子处于序号为0的单元格的位置, 第二个石子处于序号为1的单元格的位置,第三个石子在序号为3的单元格的位置， 以此定义整个数组…最后一个石子处于序号为17的单元格的位置。输出： true。即青蛙可以成功过河，按照如下方案跳跃：跳1个单位到第2块石子, 然后跳2个单位到第3块石子, 接着跳2个单位到第4块石子, 然后跳3个单位到第6块石子,跳4个单位到第7块石子, 最后，跳5个单位到第8个石子（即最后一块石子）。 思路：参考官方题解动态规划的方法，使用dmap[curpos] &#x3D; {jumps}表示到达当前curpos可以由jumps集合的任意一个步长一次到达当前位置，对于dmap[0] &#x3D; {0}，依次遍历每个石头的位置，对每个位置pos遍历jumps集合，对每个jump遍历k &#x3D; [jump-1，jump+1]，如果当前位置跳k补可以到达某个石头的位置（dmap中的存在key&#x3D;curpos+k），则将k添加到dmap[curpos+k]的集合。 示例代码： func canCross(stones []int) bool &#123; // 用集合模拟set，只需要键值当做集合的元素，value设为空结构 dmap := make(map[int]map[int]struct&#123;&#125;, 0) dmap[0] = map[int]struct&#123;&#125;&#123;0: &#123;&#125;&#125; for i := 1; i &lt; len(stones); i++ &#123; dmap[stones[i]] = map[int]struct&#123;&#125;&#123;&#125; &#125; for _, cur_pos := range stones &#123; steps := dmap[cur_pos] for step, _ := range steps &#123; for k := step - 1; k &lt;= step + 1; k++ &#123; if _, ok := dmap[cur_pos + k]; ok == true &amp;&amp; k &gt; 0 &#123; dmap[cur_pos + k][k] = struct&#123;&#125;&#123;&#125; &#125; &#125; &#125; &#125; return len(dmap[stones[len(stones) - 1]]) != 0 &#125; 7.4 编辑距离LeetCode No.72 题目描述：给你两个单词 word1 和 word2，请你计算出将 word1 转换成 word2 所使用的最少操作数 。你可以对一个单词进行如下三种操作：插入一个字符、删除一个字符、替换一个字符。 思路：使用dp[i][j]表示从word1[:i]转换为word2[:j]需要的最少次数，对于任意一个单词为空，所需次数为另一个单词的长度，只能通过增或删来达到相同。对于dp[i][j]，dp[i-1][j]表示从word2中删除一个字符得到，dp[i][j - 1]表示从word1中增加一个字符得到，dp[i-1][j-1]表示从word1中修改一个字符得到，对于word1[i] &#x3D;&#x3D; word2[j]则不需要修改。那么dp[i][j]只能为上述三种情况的最小值。所以有状态转移方程： 当word1[i] &#x3D;&#x3D; word2[j]时 dp[i][j] &#x3D; min(dp[i - 1][j - 1], min(dp[i - 1][j], dp[i][j - 1]) + 1) 当word1[i] !&#x3D; word2[j]时 dp[i][j] &#x3D; min(dp[i - 1][j - 1], min(dp[i - 1][j], dp[i][j - 1])) + 1 示例代码： func min(x, y int) int &#123; if x &lt; y &#123; return x &#125; return y &#125; func minDistance(word1 string, word2 string) int &#123; LFROM, LTO := len(word1), len(word2) dp := make([][]int, LFROM + 1) for i := 0; i &lt;= LFROM; i++ &#123; dp[i] = make([]int, LTO + 1) dp[i][0] = i &#125; for j := 0; j &lt;= LTO; j++ &#123; dp[0][j] = j &#125; for i := 1; i &lt;= LFROM; i++ &#123; for j := 1; j &lt;= LTO; j++ &#123; if word1[i - 1] == word2[j - 1] &#123; dp[i][j] = min(dp[i - 1][j - 1], min(dp[i - 1][j], dp[i][j - 1]) + 1) &#125; else &#123; dp[i][j] = min(dp[i - 1][j - 1], min(dp[i - 1][j], dp[i][j - 1])) + 1 &#125; &#125; &#125; return dp[LFROM][LTO] &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"动态规划","slug":"动态规划","permalink":"https://harryzhang.cn/blog/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]},{"title":"算法(6): 贪心算法","slug":"算法-6-贪心算法","date":"2023-03-19T13:55:40.000Z","updated":"2026-02-26T06:21:08.415Z","comments":true,"path":"2023/03/19/算法-6-贪心算法/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E7%AE%97%E6%B3%95-6-%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/","excerpt":"","text":"分治的思想为将大问题分解为子问题，子问题再分解为更小的子问题，直到不能再拆分，然后再合并子问题的结果，通常需要用到递归。关键是要找对如何拆解问题。 5.1 不同的二叉搜索树LeetCode No.95 问题描述：给定一个整数 n，生成所有由 1 … n 为节点所组成的 二叉搜索树 。 思路：根据二叉搜索树的特点，左子树的所有节点值均小于根节点，右子树的所有节点值均大于根节点，同时对于每一个子树也要满足以上条件。1…n有序序列，假设对于每一个值i作为根节点，可以先求的[1，i - 1]构成的二叉搜索左子树，[i + 1, n]构成的二叉搜索右子树，然后从左右子树中各选一个作为当前根节点的左右子树。 示例代码： func generateTrees(n int) []*TreeNode &#123; return _generateTrees(1, n) &#125; func _generateTrees(start, end int) []*TreeNode &#123; if start &gt; end &#123; return []*TreeNode&#123;nil&#125; &#125; res := []*TreeNode&#123;&#125; for i := start; i &lt;= end; i++ &#123; left := _generateTrees(start, i - 1) right := _generateTrees(i + 1, end) for _, l := range left &#123; for _, r := range right &#123; tmp := &amp;TreeNode&#123; Val: i, Left: l, Right: r, &#125; res = append(res, tmp) &#125; &#125; &#125; return res &#125; 5.2 为运算表达式设计优先级LeetCode No.241 题目描述：给定一个含有数字和运算符的字符串，为表达式添加括号，改变其运算优先级以求出不同的结果。你需要给出所有可能的组合的结果。有效的运算符号包含 +, - 以及 * 。 思路：对于每个预算式形如x op y，其左右表达式也可以看做一个形如x op y的运算式，对左右两边的运算式的所有结果进行计算，就可以得到最终的结果。 示例代码： func diffWaysToCompute(expression string) []int &#123; num, err := strconv.Atoi(expression) // 如果为纯数字，直接返回数字 if err == nil &#123; return []int&#123;num&#125; &#125; res := []int&#123;&#125; for i, ch := range expression &#123; // 跳过非运算符 if ch != &#39;+&#39; &amp;&amp; ch != &#39;-&#39; &amp;&amp; ch != &#39;*&#39; &#123; continue &#125; // 计算运算符左右两边子表达式的结果 left := diffWaysToCompute(expression[ : i]) right := diffWaysToCompute(expression[i + 1 : ]) for _, l := range left &#123; for _, r := range right &#123; var tmp int switch ch &#123; case &#39;+&#39;: tmp = l + r case &#39;-&#39;: tmp = l - r case &#39;*&#39;: tmp = l * r &#125; res = append(res, tmp) &#125; &#125; &#125; return res &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"贪心","slug":"贪心","permalink":"https://harryzhang.cn/blog/tags/%E8%B4%AA%E5%BF%83/"}]},{"title":"算法(5): 分治/归并","slug":"算法-5-分治-归并","date":"2023-03-19T13:54:37.000Z","updated":"2026-02-26T06:21:08.415Z","comments":true,"path":"2023/03/19/算法-5-分治-归并/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E7%AE%97%E6%B3%95-5-%E5%88%86%E6%B2%BB-%E5%BD%92%E5%B9%B6/","excerpt":"","text":"分治的思想为将大问题分解为子问题，子问题再分解为更小的子问题，直到不能再拆分，然后再合并子问题的结果，通常需要用到递归。关键是要找对如何拆解问题。 5.1 不同的二叉搜索树LeetCode No.95 问题描述：给定一个整数 n，生成所有由 1 … n 为节点所组成的 二叉搜索树 。 思路：根据二叉搜索树的特点，左子树的所有节点值均小于根节点，右子树的所有节点值均大于根节点，同时对于每一个子树也要满足以上条件。1…n有序序列，假设对于每一个值i作为根节点，可以先求的[1，i - 1]构成的二叉搜索左子树，[i + 1, n]构成的二叉搜索右子树，然后从左右子树中各选一个作为当前根节点的左右子树。 示例代码： func generateTrees(n int) []*TreeNode &#123; return _generateTrees(1, n) &#125; func _generateTrees(start, end int) []*TreeNode &#123; if start &gt; end &#123; return []*TreeNode&#123;nil&#125; &#125; res := []*TreeNode&#123;&#125; for i := start; i &lt;= end; i++ &#123; left := _generateTrees(start, i - 1) right := _generateTrees(i + 1, end) for _, l := range left &#123; for _, r := range right &#123; tmp := &amp;TreeNode&#123; Val: i, Left: l, Right: r, &#125; res = append(res, tmp) &#125; &#125; &#125; return res &#125; 5.2 为运算表达式设计优先级LeetCode No.241 题目描述：给定一个含有数字和运算符的字符串，为表达式添加括号，改变其运算优先级以求出不同的结果。你需要给出所有可能的组合的结果。有效的运算符号包含 +, - 以及 * 。 思路：对于每个预算式形如x op y，其左右表达式也可以看做一个形如x op y的运算式，对左右两边的运算式的所有结果进行计算，就可以得到最终的结果。 示例代码： func diffWaysToCompute(expression string) []int &#123; num, err := strconv.Atoi(expression) // 如果为纯数字，直接返回数字 if err == nil &#123; return []int&#123;num&#125; &#125; res := []int&#123;&#125; for i, ch := range expression &#123; // 跳过非运算符 if ch != &#39;+&#39; &amp;&amp; ch != &#39;-&#39; &amp;&amp; ch != &#39;*&#39; &#123; continue &#125; // 计算运算符左右两边子表达式的结果 left := diffWaysToCompute(expression[ : i]) right := diffWaysToCompute(expression[i + 1 : ]) for _, l := range left &#123; for _, r := range right &#123; var tmp int switch ch &#123; case &#39;+&#39;: tmp = l + r case &#39;-&#39;: tmp = l - r case &#39;*&#39;: tmp = l * r &#125; res = append(res, tmp) &#125; &#125; &#125; return res &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"二叉搜索树","slug":"二叉搜索树","permalink":"https://harryzhang.cn/blog/tags/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"}]},{"title":"算法(4): 搜索","slug":"算法-4-搜索","date":"2023-03-19T13:52:31.000Z","updated":"2026-02-26T06:21:08.414Z","comments":true,"path":"2023/03/19/算法-4-搜索/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E7%AE%97%E6%B3%95-4-%E6%90%9C%E7%B4%A2/","excerpt":"","text":"3.1 深度优先DFS 问题1：给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。Input: “23”Output: [“ad”, “ae”, “af”, “bd”, “be”, “bf”, “cd”, “ce”, “cf”] 思路：深度优先搜索，从根节点到每个叶子节点的所有路径即结果，深度为子串的长度 示例代码: var ( letterMap = []string&#123; &quot; &quot;, //0 &quot;&quot;, //1 &quot;abc&quot;, //2 &quot;def&quot;, //3 &quot;ghi&quot;, //4 &quot;jkl&quot;, //5 &quot;mno&quot;, //6 &quot;pqrs&quot;, //7 &quot;tuv&quot;, //8 &quot;wxyz&quot;, //9 &#125; res = []string&#123;&#125; ) func letterCombinations(digits string) []string &#123; if digits == &quot;&quot; &#123; return []string&#123;&#125; &#125; res = []string&#123;&#125; dfs(digits, 0, &quot;&quot;) return res &#125; func dfs(digits string, i int, s string) &#123; if i == len(digits) &#123; res = append(res, s) return &#125; curs := letterMap[digits[i] - &#39;0&#39;] for _, ch := range curs &#123; dfs(digits, i+1, s + string(ch)) &#125; &#125; 问题2：给定一个数组，要求在这个数组中找出 k 个数之和为 target 的所有组合。Input: nums &#x3D; [1, 0, -1, 0, -2, 2], and target &#x3D; 0.Output: [ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2] ] 思路：深度优先搜索，层数为k。注意去重的处理。 示例代码: import &quot;sort&quot; var res = [][]int&#123;&#125; func fourSum(nums []int, target int) [][]int &#123; if len(nums) == 0 &#123; return [][]int&#123;&#125; &#125; sort.Ints(nums) res = [][]int&#123;&#125; r := []int&#123;&#125; dfs_sum(nums, 0, r, target) return res &#125; func dfs_sum(nums []int, i int, r []int, target int) &#123; if i == 4 || 0 == len(nums) &#123; if len(r) &gt;= 4 &amp;&amp; r[0] + r[1] + r[2] + r[3] == target &#123; res = append(res, []int&#123;r[0], r[1], r[2], r[3]&#125;) &#125; return &#125; for j := 0; j &lt; len(nums); j++ &#123; if j &gt; 0 &amp;&amp; nums[j] == nums[j-1] &#123; continue &#125; r = append(r, nums[j]) dfs_sum(nums[j+1:], i + 1, r, target) if len(r) &gt;= 1 &#123; r = r[:len(r)-1] &#125; &#125; &#125; 3.2 宽度优先搜索 BFS宽度优先搜索通常用在求最短路径，按层遍历，第一次满足要求的层数就是最短的路径。BFS需要借助队列来保存每一层的节点，访问过的节点要做标记避免重复访问。 3.2.1 二进制矩阵中的最短路径LeetCode No.1091 题目描述：给你一个 n x n 的二进制矩阵 grid 中，返回矩阵中最短 畅通路径 的长度。如果不存在这样的路径，返回 -1 。二进制矩阵中的 畅通路径 是一条从 左上角 单元格（即，(0, 0)）到 右下角 单元格（即，(n - 1, n - 1)）的路径，该路径同时满足下述要求：1 路径途经的所有单元格都的值都是 0 。2 路径中所有相邻的单元格应当在 8 个方向之一 上连通（即，相邻两单元之间彼此不同且共享一条边或者一个角）。畅通路径的长度 是该路径途经的单元格总数。 思路：从左上角开始，遍历所有可以走的方向，BFS方式求到达右下角的最小层数。 示例代码： type Pos struct &#123; x, y int &#125; func shortestPathBinaryMatrix(grid [][]int) int &#123; if len(grid) == 0 || len(grid[0]) == 0 &#123; return -1 &#125; M, N := len(grid), len(grid[0]) direction := []Pos&#123;&#123;1, -1&#125;, &#123;1, 0&#125;, &#123;1, 1&#125;, &#123;0, -1&#125;, &#123;0, 1&#125;, &#123;-1, -1&#125;, &#123;-1, 0&#125;, &#123;-1, 1&#125;&#125; Q := list.New() // 根节点入队 Q.PushBack(Pos&#123;0, 0&#125;) path_len := 0 for Q.Len() != 0 &#123; // 保存当前层的长度 level_size := Q.Len() path_len++ // 依次处理当前层的所有节点 for i := 0; i &lt; level_size; i++ &#123; cur_pos := Q.Front().Value.(Pos) Q.Remove(Q.Front()) if grid[cur_pos.x][cur_pos.y] == 1 &#123; continue &#125; // 如果到达右下角返回结果 if cur_pos.x == (M - 1) &amp;&amp; cur_pos.y == (N - 1) &#123; return path_len &#125; // 访问过的位置标记为1 grid[cur_pos.x][cur_pos.y] = 1 // 遍历所有能走的方向，加入队列 for _, dr := range direction &#123; nx, ny := cur_pos.x + dr.x, cur_pos.y + dr.y if nx &lt; 0 || nx &gt;= M || ny &lt; 0 || ny &gt;= N &#123; continue &#125; Q.PushBack(Pos&#123;nx, ny&#125;) &#125; &#125; &#125; return -1 &#125; 3.2.2 完全平方数LeetCode No.279 题目描述：给定正整数 n，找到若干个完全平方数（比如 1, 4, 9, 16, …）使得它们的和等于 n。你需要让组成和的完全平方数的个数最少。给你一个整数 n ，返回和为 n 的完全平方数的 最少数量 。完全平方数 是一个整数，其值等于另一个整数的平方；换句话说，其值等于一个整数自乘的积。例如，1、4、9 和 16 都是完全平方数，而 3 和 11 不是。 思路：转化为BFS问题模型，从1到根号n的所有平方数（1，4，9…）为每次所有可能的路径。从n开始遍历，当n&#x3D;0时即为结果。 示例代码： func numSquares(n int) int &#123; numsqs := []int&#123;&#125; for i, ii := 1, 1; ii &lt;= n; i, ii = i + 1, (i + 1) * (i + 1)&#123; numsqs = append(numsqs, ii) &#125; mark := map[int]bool&#123;&#125; Q := list.New() Q.PushBack(n) mark[n] = true ans := 0 for Q.Len() != 0 &#123; lv_size := Q.Len() ans++ for i := 0; i &lt; lv_size; i++ &#123; cur := Q.Front().Value.(int) Q.Remove(Q.Front()) for _, nq := range numsqs &#123; if cur == nq &#123; return ans &#125; if cur &lt; nq &#123; break &#125; if mark[cur - nq] &#123; continue &#125; mark[cur - nq] = true Q.PushBack(cur - nq) &#125; &#125; &#125; return n &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"https://harryzhang.cn/blog/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"https://harryzhang.cn/blog/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"}]},{"title":"算法(3): 二分查找","slug":"算法-3-二分查找","date":"2023-03-19T13:51:01.000Z","updated":"2026-02-26T06:21:08.414Z","comments":true,"path":"2023/03/19/算法-3-二分查找/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E7%AE%97%E6%B3%95-3-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/","excerpt":"","text":"二分查找是一种在有序列表中查找元素的高效方法，时间复杂度（logN），二分查找思路和时间都比较简单，但是实际问题中的细节不可忽视。 3.1 搜索插入位置LeetCode No.35 问题描述：给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置，你可以假设数组中无重复元素。 思路：按照二分查找法，定义low，high两个指针，结束条件为low &gt; high，如果目标值不存在返回low的位置就是要插入的位置。 示例代码： func searchInsert(nums []int, target int) int &#123; l, h := 0, len(nums) - 1 var m int for l &lt;= h &#123; m = h + l &gt;&gt; 1 if nums[m] == target &#123; return m &#125; if nums[m] &gt; target &#123; h = m - 1 &#125; else &#123; l = m + 1 &#125; &#125; return l &#125; 3.2 搜索旋转排序数组LeetCode No.33 问题描述：整数数组 nums 按升序排列，数组中的值 互不相同 。在传递给函数之前，nums 在预先未知的某个下标 k（0 &lt;&#x3D; k &lt; nums.length）上进行了 旋转，使数组变为 [nums[k], nums[k+1], …, nums[n-1], nums[0], nums[1], …, nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变为 [4,5,6,7,0,1,2] 。给你 旋转后 的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 target ，则返回它的索引，否则返回 -1 思路：进行二分之后的mid位置元素位置可能有两种情况：左边元素的所有元素是有序的，或右边的所有元素是有序的。 如果是左边有序，则nums[mid] &gt; nums[low]，反之是右边有序 在知道是那边有序后即可根据边界和target来选择去左半区还是右半区搜索 示例代码： func search(nums []int, target int) int &#123; low, high := 0, len(nums) - 1 for low &lt;= high &#123; mid := (low + high) / 2 if nums[mid] == target &#123; return mid &#125; if nums[mid] &gt;= nums[low] &#123; if target &lt; nums[mid] &amp;&amp; target &gt;= nums[low] &#123; high = mid - 1 &#125; else &#123; low = mid + 1 &#125; &#125; else &#123; if target &gt; nums[mid] &amp;&amp; target &lt;= nums[high] &#123; low = mid + 1 &#125; else &#123; high = mid - 1 &#125; &#125; &#125; return -1 &#125; 3.3 排序数组中查找元素的第一个和最后一个位置（有重复元素）LeetCode No.34 问题描述：给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置，如果数组中不存在目标值 target，返回 [-1, -1]。 思路：找到最左边的target位置和target+1最左边的位置-1，要找最左边的target，那么当nums[mid] &gt;&#x3D; target时都要继续往左半区搜索。 示例代码： func searchRange(nums []int, target int) []int &#123; ledge := search(nums, target) if ledge == len(nums) || nums[ledge] != target &#123; return []int&#123;-1, -1&#125; &#125; redge := search(nums, target + 1) - 1 return []int&#123;ledge, redge&#125; &#125; func search(nums []int, target int) int &#123; l, r := 0, len(nums) - 1 for l &lt;= r &#123; mid := (l + r) / 2 if nums[mid] &gt;= target &#123; r = mid - 1 if l &gt; r &amp;&amp; nums[mid] == target &#123; return mid &#125; &#125; else &#123; l = mid + 1 &#125; &#125; return l &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"二分查找","slug":"二分查找","permalink":"https://harryzhang.cn/blog/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"}]},{"title":"算法(2): 排序","slug":"算法-2-排序","date":"2023-03-19T13:43:50.000Z","updated":"2026-02-26T06:21:08.414Z","comments":true,"path":"2023/03/19/算法-2-排序/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E7%AE%97%E6%B3%95-2-%E6%8E%92%E5%BA%8F/","excerpt":"","text":"2.1 快速排序 题目描述：实现快速排序 思路：采用交换法，选第一个数为基准数pivot，在pl &lt;&#x3D; pr的前提下，指针pl从基准数+1的位置向右走，直到碰到比pivot大的数，指针pr从最右边向左走，直到碰到比pivot小的数，交换arr[pl], arr[pr]，循环结束时pr &#x3D; pl - 1，将基准数和pr交换。递归调用对基准数位置两边的区间调整。 示例代码： func partition(arr []int, left, right int) int &#123; pivot := arr[left] pl, pr := left + 1, right for pl &lt;= pr &#123; for ; pl &lt;= pr &amp;&amp; arr[pl] &lt; pivot; pl++ &#123;&#125; for ; pl &lt;= pr &amp;&amp; arr[pr] &gt; pivot; pr-- &#123;&#125; if pl &lt; pr &#123; arr[pl], arr[pr] = arr[pr], arr[pl] &#125; &#125; // 结束时pr = pl -1 arr[left], arr[pr] = arr[pr], arr[left] return pr &#125; func recursive(arr []int, left, right int) &#123; if left &gt;= right &#123; return &#125; mid := partition(arr, left, right) recursive(arr, left, mid - 1) recursive(arr, mid + 1, right) &#125; func QuickSort(arr []int) []int &#123; recursive(arr, 0, len(arr) - 1) return arr &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"快速排序","slug":"快速排序","permalink":"https://harryzhang.cn/blog/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"}]},{"title":"算法(1): 双指针","slug":"算法-1-双指针","date":"2023-03-19T13:41:00.000Z","updated":"2026-02-26T06:21:08.413Z","comments":true,"path":"2023/03/19/算法-1-双指针/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E7%AE%97%E6%B3%95-1-%E5%8F%8C%E6%8C%87%E9%92%88/","excerpt":"","text":"双指针通常用在有序数组，链表的数据结构上，根据题目条件移动对应的指针。比如判断子串、链表是否有环的问题。 1.1 最长子串LeetCode No.524 题目描述：给定一个字符串和一个字符串字典，找到字典里面最长的字符串，该字符串可以通过删除给定字符串的某些字符来得到。如果答案不止一个，返回长度最长且字典顺序最小的字符串。如果答案不存在，则返回空字符串输入:s &#x3D; “abpcplea”, d &#x3D; [“ale”,”apple”,”monkey”,”plea”]输出:“apple” 思路：本题主要思路是要将删除s中某些字符后和target匹配转化为判断是target是否为s的子串判断是否为子串：使用双指针，如果当前字符相等，两个指针同时+1，否则只有母字符串的指针+1，最后判断目标字符传的指针是否等于其长度即可。参考原文 示例代码： func is_substr(s, target string) bool &#123; j := 0 for i := 0; i &lt; len(s) &amp;&amp; j &lt; len(target); i++ &#123; if s[i] == target[j] &#123; j++ &#125; &#125; return j == len(target) &#125; func findLongestWord(s string, dictionary []string) string &#123; var longest string for _, cur := range dictionary &#123; // 如果当前字符串是s的子串，当当前字符串长度大于目前结果 或 长度相等但是当前串字典序排在前面时更新目前结果 if is_substr(s, cur) &amp;&amp; (len(cur) &gt; len(longest) || len(cur) == len(longest) &amp;&amp; cur &lt; longest) &#123; longest = cur &#125; &#125; return longest &#125; 1.2 两数之和LeetCode No.167 题目描述：给定一个已按照 升序排列 的整数数组 numbers ，请你从数组中找出两个数满足相加之和等于目标数 target 。输入：numbers &#x3D; [2,7,11,15], target &#x3D; 9输出：[1,2] 思路：因为输入数组有序，那么可以用左右两个指针，初始位于两端，判断当前两数和如果大于target，那么right指针减一，如果小于target，left加一，如果等于就返回。 示例代码: func twoSum(numbers []int, target int) []int &#123; for left, right := 0, len(numbers) - 1; left &lt; right; &#123; cur := numbers[left] + numbers[right] if cur == target &#123; return []int&#123;left+1, right+1&#125; &#125; if cur &lt; target &#123; left++ &#125; else &#123; right-- &#125; &#125; return []int&#123;&#125; &#125; 1.3 判断链表是否存在环LeetCode No.141 题目描述：给定一个链表，判断链表中是否有环。 思路：经典解法使用快慢指针，如果存在环两个指针一定会相遇，注意指针空的判断，避免出现野指针。 示例代码： func hasCycle(head *ListNode) bool &#123; if head == nil || head.Next == nil &#123; return false &#125; faster, slower := head.Next.Next, head.Next for faster != nil &amp;&amp; faster.Next != nil &amp;&amp; slower != nil &#123; if faster == slower &#123; return true &#125; faster = faster.Next.Next slower = slower.Next &#125; return false &#125; 1.4 接雨水LeetCode No.42 题目描述：给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。 思路：当前柱子能接的雨水数为其左右最高的柱子的较小值减当前柱子的高度 方法1：先求出每个柱子i左边的最大高度left_max[i]，右边最大高度right_max[i]，然后遍历一次计算。时间复杂度T &#x3D; O(3n) 示例代码： func trap(height []int) int &#123; res, n := 0, len(height) if n == 0 &#123; return res &#125; left_max, right_max := make([]int, n), make([]int, n) left_max[0], right_max[n - 1] = height[0], height[n - 1] for i := 1; i &lt; n; i++ &#123; left_max[i] = max(left_max[i - 1], height[i]) &#125; for i := n - 2; i &gt;= 0; i-- &#123; right_max[i] = max(right_max[i + 1], height[i]) &#125; for i := 0; i &lt; n; i++ &#123; res += min(right_max[i], left_max[i]) - height[i] &#125; return res &#125; 方法2：只需遍历一次的双指针解法，两个指针最终在最高点相遇。 示例代码： func trap(height []int) int &#123; res, left, right := 0, 0, len(height) - 1 if right &lt; 0 &#123; return res &#125; left_max, right_max := 0, 0 for left &lt; right &#123; if height[left] &gt; height[right] &#123; right_max = max(right_max, height[right]) res += right_max - height[right] right-- &#125; else &#123; left_max = max(left_max, height[left]) res += left_max - height[left] left++ &#125; &#125; return res &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"}]},{"title":"数据结构(5): 栈|队列|堆","slug":"数据结构-5-栈-队列-堆","date":"2023-03-19T13:39:14.000Z","updated":"2026-02-26T06:21:08.413Z","comments":true,"path":"2023/03/19/数据结构-5-栈-队列-堆/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-5-%E6%A0%88-%E9%98%9F%E5%88%97-%E5%A0%86/","excerpt":"","text":"6.1 栈6.1.1用两个栈实现一个队列LeetCode No.232 题目描述：请你仅使用两个栈实现先入先出队列。队列应当支持一般队列的支持的所有操作（push、pop、peek、empty）： 思路： 两个栈一个栈做队头（出元素），另一个栈做队尾（入元素） 每次push只需要push到尾栈 pop时如果头栈为空则将尾栈全部“倒入”头栈，如果头栈不为空取出栈顶元素返回，否则返回失败（此时队列为空）。 示例代码： type MyQueue struct &#123; stack_head []int stack_tail []int &#125; /** Initialize your data structure here. */ func Constructor() MyQueue &#123; return MyQueue&#123; stack_head: make([]int, 0), stack_tail: make([]int, 0), &#125; &#125; /** Push element x to the back of queue. */ func (this *MyQueue) Push(x int) &#123; this.stack_tail = append(this.stack_tail, x) &#125; func(this *MyQueue) tail2head() &#123; for i := len(this.stack_tail) - 1; i &gt;= 0; i-- &#123; this.stack_head = append(this.stack_head, this.stack_tail[i]) this.stack_tail = this.stack_tail[:len(this.stack_tail) - 1] &#125; &#125; /** Removes the element from in front of queue and returns that element. */ func (this *MyQueue) Pop() int &#123; if len(this.stack_head) == 0 &#123; this.tail2head() &#125; if len(this.stack_head) &gt; 0 &#123; r := this.stack_head[len(this.stack_head) - 1] this.stack_head = this.stack_head[:len(this.stack_head) - 1] return r &#125; return -1 &#125; /** Get the front element. */ func (this *MyQueue) Peek() int &#123; if len(this.stack_head) == 0 &#123; this.tail2head() &#125; if len(this.stack_head) &gt; 0 &#123; return this.stack_head[len(this.stack_head) - 1] &#125; return -1 &#125; /** Returns whether the queue is empty. */ func (this *MyQueue) Empty() bool &#123; return len(this.stack_head) == 0 &amp;&amp; len(this.stack_tail) == 0 &#125; 6.1.2 逆波兰表达式求值LeetCode No.150 问题描述：根据 逆波兰表示法，求表达式的值。有效的运算符包括 +, -, *, / 。每个运算对象可以是整数，也可以是另一个逆波兰表达式。输入: [“2”, “1”, “+”, “3”, “*”]输出: 9解释: 该算式转化为常见的中缀算术表达式为：((2 + 1) * 3) &#x3D; 9 思路：借助一个栈，如果是数值就入栈，如果是运算符就从栈顶取出两个元素计算，然后将结果入栈，最后栈中只剩一个元素就是结果。 示例代码： func operate(x, y int, op string) int &#123; switch op &#123; case &quot;+&quot;: return x + y case &quot;-&quot;: return x - y case &quot;*&quot;: return x * y case &quot;/&quot;: return x / y default: return 0 &#125; &#125; func evalRPN(tokens []string) int &#123; stack := []int&#123;&#125; for i := 0; i &lt; len(tokens); i++ &#123; switch tokens[i] &#123; case &quot;+&quot;, &quot;-&quot;, &quot;*&quot;, &quot;/&quot;: cur := operate(stack[len(stack) - 2], stack[len(stack) - 1], tokens[i]) stack = stack[:len(stack) - 1] stack[len(stack) - 1] = cur default: num, _ := strconv.Atoi(tokens[i]) stack = append(stack, num) &#125; &#125; return stack[0] &#125; 6.1.3 中缀表达式生成逆波兰表达式 借助一个符号栈和结果队列，具体过程见代码注释 示例代码： func is_operation(b byte) bool &#123; return b == &#39;+&#39; || b == &#39;-&#39; || b == &#39;*&#39; || b == &#39;/&#39; &#125; func compare_priority(a, b byte) int &#123; if (a == &#39;+&#39; || a == &#39;-&#39;) &amp;&amp; (b == &#39;*&#39; || b == &#39;/&#39;) &#123; return -1 &#125; else if (b == &#39;+&#39; || b == &#39;-&#39;) &amp;&amp; (a == &#39;*&#39; || a == &#39;/&#39;) &#123; return 1 &#125; else &#123; return 0 &#125; &#125; func toRPN(s string) []string &#123; // 运算符栈 ops_stack := []byte&#123;&#125; // 结果队列 res_queue := []string&#123;&#125; n := len(s) for i := 0; i &lt; n; i++ &#123; if s[i] == &#39;(&#39; &#123; // 遇到左括号直接入栈 ops_stack = append(ops_stack, s[i]) &#125; else if s[i] == &#39;)&#39; &#123; // 遇到右括号，则将栈中的运算符依次弹出加入到结果队列，直到碰到左括号，然后将这对括号丢弃 for ops_stack[len(ops_stack) - 1] != &#39;(&#39; &#123; res_queue = append(res_queue, string(ops_stack[len(ops_stack) - 1])) ops_stack = ops_stack[:len(ops_stack) - 1] &#125; ops_stack = ops_stack[:len(ops_stack) - 1] &#125; else if is_operation(s[i]) &#123; // 遇到运算符，当前运算符的优先级小于等于栈顶运算符的优先级，则依次将栈顶弹出加入到结果队列 for len(ops_stack) &gt; 0 &amp;&amp; is_operation(ops_stack[len(ops_stack) - 1]) &amp;&amp; compare_priority(s[i], ops_stack[len(ops_stack) - 1]) &lt;= 0 &#123; res_queue = append(res_queue, string(ops_stack[len(ops_stack) - 1])) ops_stack = ops_stack[:len(ops_stack) - 1] &#125; ops_stack = append(ops_stack, s[i]) &#125; else if s[i] == &#39; &#39; &#123; // 跳过空字符 continue &#125; else &#123; // 遇到数字加入到结果队列 num := 0 for ; i &lt; n &amp;&amp; s[i] &gt;= &#39;0&#39; &amp;&amp; s[i] &lt;= &#39;9&#39;; i++ &#123; num = num * 10 + int(s[i] - &#39;0&#39;) &#125; i-- res_queue = append(res_queue, strconv.Itoa(num)) &#125; &#125; // 运算符栈中剩余的元素弹出添加到结果队列 for len(ops_stack) &gt; 0 &#123; res_queue = append(res_queue, string(ops_stack[len(ops_stack) - 1])) ops_stack = ops_stack[:len(ops_stack) - 1] &#125; return res_queue &#125; 6.2 堆定义：最大堆的堆顶为最大元素，最小堆同理 6.2.1 Golang实现堆类型因为go本身没有实现堆类型，只提供了接口，使用时必须实现堆接口才能使用对应的堆方法，所以自己用golang的container&#x2F;heap接口实现一个通用的堆类型，创建堆需要一个比较函数作为参数实现代码： // 比较函数类型 type Comparator func(a, b interface&#123;&#125;) bool // 堆元素类型 type Elements struct &#123; es []interface&#123;&#125; cmp Comparator &#125; // 堆类型 type Heap struct &#123; elements *Elements &#125; // 创建堆 func NewHeap(cmp Comparator) *Heap &#123; return &amp;Heap&#123; elements: &amp;Elements&#123; es: make([]interface&#123;&#125;, 0), cmp: cmp, &#125;, &#125; &#125; // 堆元素实现了container/heap接口 func (e Elements) Len() int &#123; return len(e.es) &#125; func (e Elements) Less(i, j int) bool &#123; return e.cmp(e.es[i], e.es[j]) &#125; func (e Elements) Swap(i, j int) &#123; e.es[i], e.es[j] = e.es[j], e.es[i] &#125; func (e *Elements) Push(item interface&#123;&#125;) &#123; e.es = append(e.es, item) &#125; func (e *Elements) Pop() interface&#123;&#125; &#123; length := len(e.es) if length == 0 &#123; return nil &#125; top := e.es[length - 1] e.es = e.es[:length - 1] return top &#125; // 入堆 func (h *Heap) Push(i interface&#123;&#125;) &#123; heap.Push(h.elements, i) &#125; // 堆顶元素出堆 func (h *Heap) Pop() interface&#123;&#125; &#123; return heap.Pop(h.elements) &#125; // 查看堆顶元素 func (h Heap) Top() interface&#123;&#125; &#123; if len(h.elements.es) == 0 &#123; return nil &#125; return h.elements.es[0] &#125; // 获取堆大小 func (h Heap) Len() int &#123; return h.elements.Len() &#125; func CompareInt(a, b interface&#123;&#125;) bool &#123; if a.(int) &gt; b.(int) &#123; return true &#125; return false &#125; 6.2.2 数组中的第K个最大元素LeetCode No.215 问题描述：在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素输入: [3,2,1,5,6,4] 和 k &#x3D; 2输出: 5 思路：使用最小堆，首先将前k个元素加入堆作为目前的最大的k个元素，然后遍历剩下的n-k个元素，如果堆顶元素比当前元素小，取出堆顶，将当前元素加入堆。最后堆顶的元素即为第k大的元素。时间复杂度：O(n*log(n))空间复杂度：O(k) 示例代码： func findKthLargest(nums []int, k int) int &#123; heap1:= NewHeap(CompareInt) // 前k个元素建立大小为k的小顶堆 for i := 0; i &lt; k; i++ &#123; heap1.Push(nums[i]) &#125; // 遍历剩余的元素更新堆 for i := k; i &lt; len(nums); i++ &#123; top := heap1.Top().(int) if top &gt; nums[i] &#123; heap1.Pop() heap1.Push(nums[i]) &#125; &#125; return heap1.Top().(int) &#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"栈","slug":"栈","permalink":"https://harryzhang.cn/blog/tags/%E6%A0%88/"},{"name":"队列","slug":"队列","permalink":"https://harryzhang.cn/blog/tags/%E9%98%9F%E5%88%97/"},{"name":"堆","slug":"堆","permalink":"https://harryzhang.cn/blog/tags/%E5%A0%86/"}]},{"title":"数据结构(4): 树","slug":"数据结构-4-树","date":"2023-03-19T13:36:55.000Z","updated":"2026-02-26T06:21:08.412Z","comments":true,"path":"2023/03/19/数据结构-4-树/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-4-%E6%A0%91/","excerpt":"","text":"4.1 根据前序与中序序列构造二叉树LeetCode No.105 问题描述：根据一棵树的前序遍历与中序遍历构造二叉树。 思路：根据二叉树的前序和中序（或后序和中序）的序列可唯一构造一棵二叉树，必须要有中序。前序遍历的第一个为根节点，找到根节点在中序中的位置，中序左边的节点都是根节点的左子树，右边的同理，然后可以用递归的方式求解。 示例代码： type TreeNode struct &#123; Val int Left *TreeNode Right *TreeNode &#125; func index(nums []int, val int) int &#123; for i, v := range nums &#123; if v == val &#123; return i &#125; &#125; return -1 &#125; func buildTree(preorder []int, inorder []int) *TreeNode &#123; if len(preorder) == 0 || len(inorder) == 0 &#123; return nil &#125; if len(preorder) == 1 || len(inorder) == 1 &#123; return &amp;TreeNode&#123; Val: preorder[0], Left: nil, Right: nil, &#125; &#125; val := preorder[0] pos := index(inorder, val) root := &amp;TreeNode&#123; Val: val, Left: buildTree(preorder[1 : pos + 1], inorder[ : pos]), Right: buildTree(preorder[pos + 1 : ], inorder[pos + 1:]), &#125; return root &#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"树","slug":"树","permalink":"https://harryzhang.cn/blog/tags/%E6%A0%91/"},{"name":"二叉树","slug":"二叉树","permalink":"https://harryzhang.cn/blog/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"数据结构(3): 链表","slug":"数据结构-3-链表","date":"2023-03-19T13:35:07.000Z","updated":"2026-02-26T06:21:08.412Z","comments":true,"path":"2023/03/19/数据结构-3-链表/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-3-%E9%93%BE%E8%A1%A8/","excerpt":"","text":"3.1 删除单向链表倒数第n个节点LeetCode No.19 问题描述：删除单向链表倒数第n个节点（只遍历一次）Input: head &#x3D; [1,2,3,4,5], n &#x3D; 2Output: [1,2,3,5] 思路：两个指针，p1先走n步，然后p1和p2再一起走，当p1到链表结尾，p2就是要删除的节点。注意处理可能删除的是头结点（n&#x3D;length）或者不需要删除（n&gt;length）的情况。可以通过增加一个虚拟的头节点，避免对头节点的特殊处理。 示例代码 /** * Definition for singly-linked list. * type ListNode struct &#123; * Val int * Next *ListNode * &#125; */ func removeNthFromEnd(head *ListNode, n int) *ListNode &#123; p1, p2 := head, head i := 0 for ; i &lt; n &amp;&amp; p1 != nil ; i++ &#123; p1 = p1.Next &#125; if p1 == nil &#123; if i &lt; n &#123; // 不需要删除 return head &#125; else &#123; // 删除头节点 return head.Next &#125; &#125; for p1.Next != nil &#123; p1 = p1.Next p2 = p2.Next &#125; t := p2.Next if t != nil &#123; p2.Next = t.Next &#125; return head &#125; 3.2 K个一组翻转链表LeetCode No.25 题目描述：给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。进阶：你可以设计一个只使用常数额外空间的算法来解决此问题吗？你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。 思路： 先遍历一遍求出链表长度n，则需要翻转n&#x2F;k组。使用一个虚拟头节点保存结果，每一轮翻转完将尾节保存，下一轮翻转结束后将上一轮的为节点的Next节点指向当前轮的头结点。 示例代码： func reverseKGroup(head *ListNode, k int) *ListNode &#123; n := 0 for p := head; p != nil; p = p.Next &#123; n++ &#125; reshead := &amp;ListNode&#123;&#125; var lasttail *ListNode for i, p := 0, head; i &lt;= n/k; i++ &#123; if i == n / k &#123; lasttail.Next = p break &#125; curhead, curtail := p, p for j := 0; j &lt; k; j++ &#123; tmp := p p = p.Next tmp.Next = curhead curhead = tmp &#125; if i == 0 &#123; reshead.Next = curhead &#125; else &#123; lasttail.Next = curhead &#125; lasttail = curtail &#125; return reshead.Next &#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"链表","slug":"链表","permalink":"https://harryzhang.cn/blog/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"数据结构(2): 数组","slug":"数据结构-2-数组","date":"2023-03-19T13:31:25.000Z","updated":"2026-02-26T06:21:08.412Z","comments":true,"path":"2023/03/19/数据结构-2-数组/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-2-%E6%95%B0%E7%BB%84/","excerpt":"","text":"2.1 大于n&#x2F;k次的元素LeetCode No.229 题目描述：给一个整数数组，找出所有出现次数大于n&#x2F;3的元素。Input: nums &#x3D; [3,2,3]Output: [3] 摩尔投票法： 一般情况一个大小为 n 的整数数组，找出其中所有出现超过 ⌊ n&#x2F;k ⌋ 次的元素。n&#x2F;k的众数最多只有k - 1个，原因：假设有k个众数，则 出现次数（⌊ n&#x2F;k ⌋ +1） × \\times× 众数个数 k &gt; n。 思路：此题为例 k &#x3D; 3, 则最多有2个出现次数大于n&#x2F;3的元素，把此情景想像成在大会中投票选出两个候选者， 则有两个候选 n1 和n2。 如果投n1（当前元素等于n1），则n1的票数 c1++; 如果投n2（当前元素等于n2），则n2的票数c2++; 如果n1,n2都不投（即当前值与n1，n2都不相等）,那么检查此时n1或n2的票数是否为0： 如果为0,则当前元素成为新的候选人替代掉票数为0的人； 如果n1,n2两个人的票数都不为0，那么n1,n2两个候选人的票数均减一； 最后会有这么几种可能：有2个大于n&#x2F;3，有1个大于n&#x2F;3，有0个大于n&#x2F;3，遍历结束后选出了两个候选人，但是这两个候选人是否满足&gt; n&#x2F;3，还需要再遍历一遍数组，找出两个候选人的具体票数，因为不一定有。参考原文 示例代码： func majorityElement(nums []int) []int &#123; v1, c1, v2, c2 := 0, 0, 0, 0 for _, n := range nums &#123; if n == v1 &#123; c1++ &#125; else if n == v2 &#123; c2++ &#125; else &#123; if c1 == 0 &#123; v1 = n c1++ &#125; else if c2 == 0 &#123; v2 = n c2++ &#125; else &#123; c1-- c2-- &#125; &#125; &#125; r := make([]int, 0) c1, c2 = 0, 0 for _, n := range nums &#123; if n == v1 &#123; c1++ &#125; if n == v2 &amp;&amp; v2 != v1 &#123; c2++ &#125; &#125; if c1 &gt; len(nums) / 3 &#123; r = append(r, v1) &#125; if c2 &gt; len(nums) / 3 &#123; r = append(r, v2) &#125; return r &#125; 2.2 缺失的第一个正数LeetCode No.41 题目描述：给你一个未排序的整数数组 nums ，请你找出其中没有出现的最小的正整数。进阶：实现时间复杂度为 O(n) 并且只使用常数级别额外空间的解决方案 思路：长度为N的整数数组，没有出现的最小正整数一定在[1, N + 1]。 方法1：最容易的做法用一个额外的哈希表记录出现的数字，然后从1遍历到N+1，根据hash表如果出现缺失就返回。但是该方法空间复杂度为O(n)。 示例代码： func firstMissingPositive(nums []int) int &#123; m := map[int]bool&#123;&#125; for _, n := range nums &#123; m[n] = true &#125; for i := 1; i &lt;= len(nums); i++ &#123; if m[i] == false &#123; return i &#125; &#125; return len(nums) + 1 &#125; 方法2：在原数组上建哈希表，因为结果只需要判断[1, N]的数，因此可以以负数当做标记（参考LeetCode官方题解）。 将数组中所有小于等于 0 的数修改为 N+1 遍历每一个数x，可能已经打过标记，因此原值为|x|，如果|x|在[1, N]范围，则给数组nums[|x| - 1]元素加上负号，已加过的不能再加。 遍历数组检查，如果值非负数返回i + 1，全为负数返回N+1 示例代码: func IntAbs(x int) int &#123; if x &lt; 0 &#123; return -x &#125; return x &#125; // 只关注正整数，用&quot;-&quot;号做标记 func firstMissingPositive(nums []int) int &#123; n := len(nums) // 预处理，将元素全部变为整数 for i, v := range nums &#123; if v &lt;= 0 &#123; nums[i] = n + 1 &#125; &#125; // 打标记 for i := 0; i &lt; n; i++ &#123; x := IntAbs(nums[i]) if x &lt;= n &amp;&amp; nums[x - 1] &gt; 0 &#123; nums[x - 1] *= -1 &#125; &#125; // 检查标记 for i := 0; i &lt; n; i++ &#123; if nums[i] &gt; 0 &#123; return i + 1 &#125; &#125; return n + 1 &#125; 方法3：置换，将数组恢复成形如[1, 2, … , N]的形式，即nums[i-1]&#x3D;i（参考LeetCode官方题解）。 设v &#x3D; nums[i], 如果nums[i] &#x3D;&#x3D; nums [v-1]，则不需要置换，否则将nums[v-1]设为v，此时要先把nums[v-1]的值保存到nums[i]，此时v-1已经是正确的位置，但是i不一定是正确的位置，需要继续置换。 检查每个位置的值是否正确，全部正确返回N+1，否则返回i+1 示例代码: func firstMissingPositive(nums []int) int &#123; n := len(nums) for i, v := range nums &#123; for v &gt; 0 &amp;&amp; v &lt; n + 1 &amp;&amp; nums[i] != nums[v - 1] &#123; nums[v - 1], nums[i] = v, nums[v - 1] v = nums[i] &#125; &#125; for i, v := range nums &#123; if v != i + 1 &#123; return i + 1 &#125; &#125; return n + 1 &#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"数组","slug":"数组","permalink":"https://harryzhang.cn/blog/tags/%E6%95%B0%E7%BB%84/"}]},{"title":"数据结构(1): 字符串","slug":"数据结构-1-字符串","date":"2023-03-19T13:04:01.000Z","updated":"2026-02-26T06:21:08.411Z","comments":true,"path":"2023/03/19/数据结构-1-字符串/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-1-%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"","text":"1.1 字符串移位 问题：将字符的前k个字符移到字符串结尾。Input：“abcde”，2Output：“cdeab” 三步翻转法： 将字符串分为前k位和后（n-k）位两部分，将两部分分别翻转，最后再整体翻转即可。时间复杂度：T &#x3D; O(n)参考原文 示例代码： // 反转字符串 func reverse(s string) string &#123; runes := []rune(s) for l, r := 0, len(runes) - 1; l &lt; r; l, r = l + 1, r - 1 &#123; runes[l], runes[r] = runes[r], runes[l] &#125; return string(runes) &#125; // 三步反转法对字符串进行循环移位 func shift_string(s string, k int) string &#123; runes := []rune(s) ls, rs := runes[:k], runes[k:] rls := reverse(string(ls)) rrs := reverse(string(rs)) return reverse(rls + rrs) &#125; 1.2 最长回文子串LeetCode No.5 问题：找出一个子串包含的最长回文子串。Input: s &#x3D; “babad”Output: “bab”Note: “aba” is also a valid answer. 解法1：从某个子串向两边扩展，遍历找出最长的一个（需要考虑偶数个、奇数个字符的回文子串） 示例代码 func LongestPalindrome(s string) string &#123; rs := []rune(s) mx, st := 0, 0 i, j, c := 0, 0, 0 for i = 0; i &lt; len(rs); i++ &#123; // 奇数个字符的回文子串 for j = 0; i - j &gt;= 0 &amp;&amp; i + j &lt; len(rs); j++ &#123; if rs[i - j] != rs[i + j] &#123; break &#125; c = 2 * j + 1 &#125; if c &gt; mx &#123; mx = c st = i - j + 1 &#125; // 偶数个字符的回文子串 for j = 0; (i - j) &gt;= 0 &amp;&amp; (i + j + 1) &lt; len(rs); j++ &#123; if rs[i - j] != rs[i + j + 1] &#123; break &#125; c = j * 2 + 2 &#125; if c &gt; mx &#123; mx = c st = i - j + 1 &#125; &#125; return string(rs[st: st + mx]) &#125; 解法2：马拉车算法具体思路参考原文 示例代码： func min(x, y int) int &#123; if x &lt; y &#123; return x &#125; return y &#125; func LongestPalindrome1(s string) string &#123; if len(s) &lt; 2 &#123; return s &#125; news := make([]rune, len(s)) news[0] = &#39;#&#39; for _, r := range s &#123; news = append(news, r) news = append(news, &#39;#&#39;) &#125; dp := make([]int, len(news)) mx, center, maxlen, maxst := 0, 0, 1, 0 for i := 0; i &lt; len(news); i++ &#123; // 算法核心转移方程 if i &lt; mx &#123; dp[i] = min(mx - i, dp[2*center - i]) &#125; // 以i为中心，只接从距离i为d[i] + 1的位置扩散 left, right := i - (1 + dp[i]), i + (1+ dp[i]) for left &gt;= 0 &amp;&amp; right &lt; len(news) &amp;&amp; news[left] == news[right] &#123; dp[i]++ left++ right-- &#125; // 更新mx if i + dp[i] &gt; mx &#123; mx = i + dp[i] center = i &#125; // 更新最大长度和对应在源字符串的起始位置 if dp[i] &gt; maxlen &#123; maxlen = dp[i] maxst = (i - maxlen) / 2 &#125; &#125; return s[maxst : maxst + maxlen] &#125; 1.3 字符串的全排列 问题描述：输入一个字符串，打印出该字符串中字符的所有排列。例如输入字符串abc，则输出由字符a、b、c 所能排列出来的所有字符串abc、acb、bac、bca、cab 和 cba。 解法1：递归方法DFS搜索，想象成树 示例代码: var res = []string&#123;&#125; func dfs_search(s string, lv int, cur string) &#123; if lv == 0 &#123; res = append(res, cur) &#125; for i := 0; i &lt; len(s); i++ &#123; // 去掉当前字符，下一层在剩下的字符中挑 dfs_search(s[:i] + s[i+1:], lv - 1, cur + string(s[i])) &#125; &#125; func FullPermutation(s string) []string &#123; res = []string&#123;&#125; dfs_search(s, len(s), &quot;&quot;) return res &#125; 解法2：字典序排列，从当前字符串s生成刚好比他大的下一个字符串排列参考原文 找到排列中最后一个升序的位置i 找到i后面最后一个比s[i]大的位置j 交换s[i]和s[j] 将i+1之后的字符串反转 示例代码: // 字典序排列算法 func next_permutation(s string) (bool, string) &#123; rs := []rune(s) i, j := 0, 0 // 找到最后一个升序的位置i for i = len(rs) - 2; i &gt;= 0 &amp;&amp; rs[i] &gt;= rs[i+1]; i-- &#123;&#125; if i &lt; 0 &#123; return false, &quot;&quot; &#125; // 找到i后面最后一个比rs[i]大的位置j for j = len(rs) - 1; j &gt; i &amp;&amp; rs[j] &lt;= rs[i]; j-- &#123;&#125; // 交换rs[i], s[j] rs[i], rs[j] = rs[j], rs[i] // 反转rs[i+1:] rev := reverse(string(rs[i + 1:])) return true, string(rs[:i+1]) + rev &#125; func DictOrderFullPermutation(s string) []string &#123; res := []string&#123;&#125; for ok, next_str := true, s; ok; ok, next_str = next_permutation(next_str) &#123; res = append(res, next_str) &#125; return res &#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"字符串","slug":"字符串","permalink":"https://harryzhang.cn/blog/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"Linux进程管理:supervisor和nohup原理及使用","slug":"Linux进程管理-supervisor和nohup原理及使用","date":"2023-03-13T00:49:37.000Z","updated":"2026-02-26T06:21:08.411Z","comments":true,"path":"2023/03/13/Linux进程管理-supervisor和nohup原理及使用/","link":"","permalink":"https://harryzhang.cn/blog/2023/03/13/Linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86-supervisor%E5%92%8Cnohup%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/","excerpt":"","text":"原理守护进程（daemon）守护进程是一类在后台运行的特殊进程，用于执行特定的系统任务。他独立于控制终端并且周期性的执行某种任务或等待处理某些发生的事件。Linux系统的大多数服务器就是通过守护进程实现的。常见的守护进程包括： 系统日志进程syslogd Web服务器httpd 邮件服务器sendmail 数据库服务器mysqld等 守护进程一般在系统启动时开始运行，除非强行终止，否则会持续运行知道系统关机，通常以超级用户（root）权限运行。 前台任务与后台任务假如有个简单的go的web服务器程序，使用如下方式启动，称为前台任务。独占了命令窗口，只有运行完了或手动终止（Ctrl+C），才能执行其他命令。 如果以如下方式，在命令结尾加上符号&amp;，启动的进程就会称为后台任务。后台任务又如下特点： 继承当前session的标准输出(stdout)和标准错误(stderr)，因此如上图所示，后台任务的所有输出仍会同步的在命令行显示 不再继承当前session的标准输入(stdin)，无法向这个任务输入指令，如果它试图读取标准输入，就会暂停执行（halt） SIGHUP信号变为后台任务并不代表进程成为了守护进程，因为当session关闭后，后台任务就会终止。Linux系统终端session退出流程如下： 用户准备退出session 系统向改session发送SIGHUP信号 session将SIGHUP信号发送给所有子进程 子进程收到SIGHUP信号后会自动退出 nohupnohup 是后台作业的意思， nohup运行的进程将会忽略终端信号运行。即后台运行一个命令。nohup COMMAND &amp; 用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，例如我们断开SSH连接都不会影响它的运行。 使用nohup命令的方式可以启动一个守护进程，如下图所示： nohup命令对进程做了如下操作： 忽略SIGHUP信号，因此当session关闭进程就不会退出 关闭标准输入，该进程不再接收任何输入，即使运行在前台 重定向标准输出和标准错误到文件nohup.out（默认情况，可以指定输出的文件） nohup不会自动把进程变为后台任务，所以必须加上&amp;。 supervisorsupervisor是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。supervisor管理进程是通过fork&#x2F;exec的方式把被管理的进程当做子进程来启动，用户只需要在配置文件中将要管理的进程进行配置。 结构supervisor主要由Supervisord、Supervisorctl、Web server和XML-RPC interface组成： supervisord：主进程，负责管理进程的server，它会根据配置文件创建指定数量的应用程序的子进程，管理子进程的整个生命周期，对crash的进程重启，对进程变化发送事件通知等。同时通过内置web server和XML-RPC Interface可以轻松实现进程管理。 supervisorctl：管理client，用户通过命令行发送消息给supervisord，可以查看进程状态，加载配置文件，启停进程，查看进程标准输出和错误输出，远程操作等。 Web server：superviosr提供了web server功能，可通过web控制进程。 XML-RPC interface： XML-RPC接口，提供XML-RPC服务来对子进程进行管理和监控。 macOS环境安装使用安装并启动$ brew install supervisor $ brew services start supervisor 创建配置目录和配置文件默认的配置文件路径为/usr/local/etc/supervisord.conf，查看该文件可以看到如下内容： $ tail -n2 /usr/local/etc/supervisord.conf [include] files = /usr/local/etc/supervisor.d/*.ini 可以看到include了/usr/local/etc/supervisor.d/目录下的.ini文件，因此我们需要创建改目录，然后对要管理的进程或进程组创建对应的.ini格式的配置文件 $ mkdir -pv /usr/local/etc/supervisor.d $ vim /usr/local/etc/supervisor.d/myserver.ini 编辑配置文件内容如下： [program:server] process_name=%(program_name)s_%(process_num)02d command=/usr/local/go/bin/go run /Users/harryzhang/go/src/server/server.go # 要执行的命令 autostart=true # 系统开机自动启动 autorestart=true # 进程终止自动重启 user=harryzhang # 用户 numprocs=1 # 启动进程数 redirect_stderr=true # 是否将标准错误重定向到标准输出 stdout_logfile=/Users/harryzhang/go/src/server/server.log # 指定标准输出保存的文件路径 重启supervisor编辑好配置文件后重启supervisor就可以生效，可以使用supervisorctl命令查看和管理进程状态。 $ brew services restart supervisor Stopping `supervisor`... (might take a while) ==&gt; Successfully stopped `supervisor` (label: homebrew.mxcl.supervisor) ==&gt; Successfully started `supervisor` (label: homebrew.mxcl.supervisor) $ supervisorctl status server:server_00 RUNNING pid 41382, uptime 0:00:04 如果指定的命令执行没有异常，会看到进程已处于运行状态，如果没有处于运行状态，可以查看日志文件，可能为命令执行出错直接退出了。 参考【1】Linux 守护进程的启动方法 【2】进程管理工具supervisor 和 nohup","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://harryzhang.cn/blog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://harryzhang.cn/blog/tags/Linux/"},{"name":"守护进程","slug":"守护进程","permalink":"https://harryzhang.cn/blog/tags/%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/"}]}],"categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://harryzhang.cn/blog/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"name":"工具","slug":"工具","permalink":"https://harryzhang.cn/blog/categories/%E5%B7%A5%E5%85%B7/"},{"name":"Golang","slug":"Golang","permalink":"https://harryzhang.cn/blog/categories/Golang/"},{"name":"数据结构","slug":"数据结构","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"分布式系统","slug":"分布式系统","permalink":"https://harryzhang.cn/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"微服务","slug":"微服务","permalink":"https://harryzhang.cn/blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"数据库","slug":"数据库","permalink":"https://harryzhang.cn/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"缓存","slug":"缓存","permalink":"https://harryzhang.cn/blog/categories/%E7%BC%93%E5%AD%98/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://harryzhang.cn/blog/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"操作系统","slug":"操作系统","permalink":"https://harryzhang.cn/blog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"算法","slug":"算法","permalink":"https://harryzhang.cn/blog/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"VSCode","slug":"VSCode","permalink":"https://harryzhang.cn/blog/tags/VSCode/"},{"name":"Go","slug":"Go","permalink":"https://harryzhang.cn/blog/tags/Go/"},{"name":"单调栈","slug":"单调栈","permalink":"https://harryzhang.cn/blog/tags/%E5%8D%95%E8%B0%83%E6%A0%88/"},{"name":"leetcode","slug":"leetcode","permalink":"https://harryzhang.cn/blog/tags/leetcode/"},{"name":"Goroutine","slug":"Goroutine","permalink":"https://harryzhang.cn/blog/tags/Goroutine/"},{"name":"GMP","slug":"GMP","permalink":"https://harryzhang.cn/blog/tags/GMP/"},{"name":"Thrift","slug":"Thrift","permalink":"https://harryzhang.cn/blog/tags/Thrift/"},{"name":"RPC","slug":"RPC","permalink":"https://harryzhang.cn/blog/tags/RPC/"},{"name":"Socket","slug":"Socket","permalink":"https://harryzhang.cn/blog/tags/Socket/"},{"name":"一致性哈希","slug":"一致性哈希","permalink":"https://harryzhang.cn/blog/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"},{"name":"一致性","slug":"一致性","permalink":"https://harryzhang.cn/blog/tags/%E4%B8%80%E8%87%B4%E6%80%A7/"},{"name":"Cache-Aside","slug":"Cache-Aside","permalink":"https://harryzhang.cn/blog/tags/Cache-Aside/"},{"name":"限流","slug":"限流","permalink":"https://harryzhang.cn/blog/tags/%E9%99%90%E6%B5%81/"},{"name":"漏桶","slug":"漏桶","permalink":"https://harryzhang.cn/blog/tags/%E6%BC%8F%E6%A1%B6/"},{"name":"令牌桶","slug":"令牌桶","permalink":"https://harryzhang.cn/blog/tags/%E4%BB%A4%E7%89%8C%E6%A1%B6/"},{"name":"唯一ID","slug":"唯一ID","permalink":"https://harryzhang.cn/blog/tags/%E5%94%AF%E4%B8%80ID/"},{"name":"snowflake","slug":"snowflake","permalink":"https://harryzhang.cn/blog/tags/snowflake/"},{"name":"leaf","slug":"leaf","permalink":"https://harryzhang.cn/blog/tags/leaf/"},{"name":"消息队列","slug":"消息队列","permalink":"https://harryzhang.cn/blog/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"MQ","slug":"MQ","permalink":"https://harryzhang.cn/blog/tags/MQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://harryzhang.cn/blog/tags/RabbitMQ/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://harryzhang.cn/blog/tags/RocketMQ/"},{"name":"Kafka","slug":"Kafka","permalink":"https://harryzhang.cn/blog/tags/Kafka/"},{"name":"微服务","slug":"微服务","permalink":"https://harryzhang.cn/blog/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"分布式","slug":"分布式","permalink":"https://harryzhang.cn/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"CAP","slug":"CAP","permalink":"https://harryzhang.cn/blog/tags/CAP/"},{"name":"BASE","slug":"BASE","permalink":"https://harryzhang.cn/blog/tags/BASE/"},{"name":"MySQL","slug":"MySQL","permalink":"https://harryzhang.cn/blog/tags/MySQL/"},{"name":"排序","slug":"排序","permalink":"https://harryzhang.cn/blog/tags/%E6%8E%92%E5%BA%8F/"},{"name":"脏页","slug":"脏页","permalink":"https://harryzhang.cn/blog/tags/%E8%84%8F%E9%A1%B5/"},{"name":"索引","slug":"索引","permalink":"https://harryzhang.cn/blog/tags/%E7%B4%A2%E5%BC%95/"},{"name":"SQL语句","slug":"SQL语句","permalink":"https://harryzhang.cn/blog/tags/SQL%E8%AF%AD%E5%8F%A5/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://harryzhang.cn/blog/tags/NoSQL/"},{"name":"Redis","slug":"Redis","permalink":"https://harryzhang.cn/blog/tags/Redis/"},{"name":"Redis 集群","slug":"Redis-集群","permalink":"https://harryzhang.cn/blog/tags/Redis-%E9%9B%86%E7%BE%A4/"},{"name":"热点 key","slug":"热点-key","permalink":"https://harryzhang.cn/blog/tags/%E7%83%AD%E7%82%B9-key/"},{"name":"TCP","slug":"TCP","permalink":"https://harryzhang.cn/blog/tags/TCP/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://harryzhang.cn/blog/tags/HTTPS/"},{"name":"Session","slug":"Session","permalink":"https://harryzhang.cn/blog/tags/Session/"},{"name":"Cookie","slug":"Cookie","permalink":"https://harryzhang.cn/blog/tags/Cookie/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://harryzhang.cn/blog/tags/WebSocket/"},{"name":"Linux","slug":"Linux","permalink":"https://harryzhang.cn/blog/tags/Linux/"},{"name":"I/O模型","slug":"I-O模型","permalink":"https://harryzhang.cn/blog/tags/I-O%E6%A8%A1%E5%9E%8B/"},{"name":"select/poll/epoll","slug":"select-poll-epoll","permalink":"https://harryzhang.cn/blog/tags/select-poll-epoll/"},{"name":"LRU","slug":"LRU","permalink":"https://harryzhang.cn/blog/tags/LRU/"},{"name":"缓存","slug":"缓存","permalink":"https://harryzhang.cn/blog/tags/%E7%BC%93%E5%AD%98/"},{"name":"动态规划","slug":"动态规划","permalink":"https://harryzhang.cn/blog/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"贪心","slug":"贪心","permalink":"https://harryzhang.cn/blog/tags/%E8%B4%AA%E5%BF%83/"},{"name":"二叉搜索树","slug":"二叉搜索树","permalink":"https://harryzhang.cn/blog/tags/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"name":"深度优先搜索","slug":"深度优先搜索","permalink":"https://harryzhang.cn/blog/tags/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"广度优先搜索","slug":"广度优先搜索","permalink":"https://harryzhang.cn/blog/tags/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"name":"二分查找","slug":"二分查找","permalink":"https://harryzhang.cn/blog/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"name":"快速排序","slug":"快速排序","permalink":"https://harryzhang.cn/blog/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"name":"栈","slug":"栈","permalink":"https://harryzhang.cn/blog/tags/%E6%A0%88/"},{"name":"队列","slug":"队列","permalink":"https://harryzhang.cn/blog/tags/%E9%98%9F%E5%88%97/"},{"name":"堆","slug":"堆","permalink":"https://harryzhang.cn/blog/tags/%E5%A0%86/"},{"name":"树","slug":"树","permalink":"https://harryzhang.cn/blog/tags/%E6%A0%91/"},{"name":"二叉树","slug":"二叉树","permalink":"https://harryzhang.cn/blog/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"链表","slug":"链表","permalink":"https://harryzhang.cn/blog/tags/%E9%93%BE%E8%A1%A8/"},{"name":"数组","slug":"数组","permalink":"https://harryzhang.cn/blog/tags/%E6%95%B0%E7%BB%84/"},{"name":"字符串","slug":"字符串","permalink":"https://harryzhang.cn/blog/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"守护进程","slug":"守护进程","permalink":"https://harryzhang.cn/blog/tags/%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/"}]}